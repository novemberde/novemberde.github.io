[{"content":"The word \u0026ldquo;burnout\u0026rdquo; is being heard from all directions. It is being expressed as a reason for quitting, changing jobs, taking vacations, and as a way to express difficulties in life. I think everyone has heard it at least once, and I believe there have been times when you\u0026rsquo;ve wondered if you are experiencing burnout.\nWhen I hear people talking about burnout, I often feel a deep sense of sympathy, but I also feel that there is little I can do to help. I can suggest various things to try, but those who are experiencing burnout often don\u0026rsquo;t seem to hear those suggestions. So, while contemplating what to do, I decided to write this.\n\u0026ldquo;I have never experienced burnout.\u0026rdquo;\nWhen I say this, people look at me with skeptical eyes and ask if I\u0026rsquo;m serious. But it\u0026rsquo;s true, I have never experienced burnout. To be clear once again, I have never experienced burnout, and I believe I know how to deal with similar phenomena to burnout and overcome them.\nI usually prefer brevity, but for this story, I will write in a more elaborate manner. I hope that instead of reading this like a subject to memorize, you will understand burnout and hope that everyone can overcome it.\nFirst, let\u0026rsquo;s talk about the time before the internet developed significantly. I remember the news from the 1990s and 2000s. There was a phrase that circulated among numerous sports players, artists, and professionals like a trend. It was called a \u0026ldquo;slump\u0026rdquo; or \u0026ldquo;mannerism.\u0026rdquo;\nWhat I remember from the news is the stories of professional players like Park Chan-ho who fell into a slump where their skills didn\u0026rsquo;t improve. I also heard about the reason why the Air Force had more vacation days as they approached their military service. It was said that they fell into mannerism because they repeated the same tasks, and to bring vitality to their daily lives, they introduced more frequent vacations.\nBut now, the word \u0026ldquo;burnout\u0026rdquo; is mentioned even more frequently. Why is that? What is different between then and now, and is it possible that there are no longer slumps and mannerisms?\nIn the days of slumps and mannerism, the opportunities and teachings available in the surrounding were considered the limits of what a person could learn. It involved going to a good school, meeting good teachers, encountering good seniors, having a good mentor, and learning through the time spent with that person. You would learn what you needed from the one person you met during your journey. In other words, if you were in an environment where you couldn\u0026rsquo;t meet such people or if you didn\u0026rsquo;t have the means to learn (books, videos), you would remain stagnant. It was a time when even if you wanted to learn, there were no viable means to do so. Therefore, until a fortunate enlightenment came, you had to repeat similar actions in the same place.\nBut let\u0026rsquo;s think about the present. Now, if we want to learn something, we can find ways to learn it immediately. Through the internet, smartphones, or laptops, we can quickly find and learn what we desire. Just by watching courses on YouTube, we can attend classes at Stanford University, and through Coursera, we can acquire specialized knowledge that we want to learn. We can even earn degrees.\n[Generated image from DALL-E-3]\nI believe that\u0026rsquo;s where the problem arises. Even though there is a lot of information, it\u0026rsquo;s too much. My time, my space, and the knowledge I can acquire are limited. My brain capacity cannot keep up with the computing power available worldwide. It doesn\u0026rsquo;t even have the processing speed to handle it. There are numerous inputs, but my output is limited. I am aware of the existence of things in the world, but my brain cannot keep up with processing them.\nIf the previous era was about generating more output from smaller inputs, the current era is about producing optimized outputs from larger inputs.\nModern individuals, when they don\u0026rsquo;t produce greater output at work, blame themselves for not being able to handle the overwhelming inputs and strive tirelessly day and night. There are methods to improve at work and piles of tasks awaiting completion, but when they don\u0026rsquo;t achieve better results, they blame themselves for not being able to handle such workload.\nSo let\u0026rsquo;s think rationally again. Do we really think we can handle the inputs we have to deal with now? Of course, there are tasks such as automation and process improvement. However, let\u0026rsquo;s not forget that this is still a form of work. We seek improvement, we have an overflow of work, and if we want to perform it, we can continue relentlessly.\nBut what happens if we keep going without rest? I believe that\u0026rsquo;s when burnout occurs. Immersed individuals sometimes run without taking a break. They haven\u0026rsquo;t learned how to control it, and they haven\u0026rsquo;t learned that it\u0026rsquo;s important. They are in a daily rush.\nPersonally, I participate in ultramarathons and ride bicycles. These are exercises that maintain a strenuous state for hours. The best way to go the furthest for several hours is to run steadily before becoming breathless. If you sprint in the middle, you\u0026rsquo;ll immediately need to rest, and then you resume running when your breath returns.\nI believe that the methods to overcome burnout and regulate a state where burnout doesn\u0026rsquo;t occur are similar. I study and work every day with an appropriate level of tension. I do it just enough to slightly catch my breath. If I become too exhausted and cannot continue the next day, the distance I can cover in two days becomes shorter. And if the state of burnout persists and I try to run in that breathless state, I will soon collapse.\nThe solution to the state of being unable to concentrate due to being immersed in burnout is simple. Rest or daydream. Organize your thoughts, and when your mind is overflowing with thoughts, try putting them into words. Most of the things that seem significant are actually trivial. This is how I transition from a breathless state to a normal breathing state. Only then can I have better thoughts, make better choices, and live a better life.\nI also need to control the input I receive. If input exceeds my capacity to handle it, I end up overwhelmed, and my performance suffers. You can think of it like a CPU. When the CPU throttles, the processing speed of the tasks it used to handle also slows down. This is because there\u0026rsquo;s time spent on scheduling, marking, and processing the incoming input before it needs to be scheduled again. In the end, it requires a reboot. If I go beyond the available capacity I can handle, my existing performance also deteriorates. It\u0026rsquo;s crucial to control the incoming input while keeping in mind the level I can handle.\nYou may agree or have different opinions. However, I have often thought and pondered over how I managed to overcome and handle numerous tasks while feeling the pressure.\nSome people have already heard such stories from me. I remember the people who received help, and I wanted to leave these words as a message. I sincerely hope that many people can overcome burnout instead of being consumed by it.\n","permalink":"https://novemberde.github.io/post/2024/02/18/throttle-input-to-prevent-burning-out-en/","summary":"The word \u0026ldquo;burnout\u0026rdquo; is being heard from all directions. It is being expressed as a reason for quitting, changing jobs, taking vacations, and as a way to express difficulties in life. I think everyone has heard it at least once, and I believe there have been times when you\u0026rsquo;ve wondered if you are experiencing burnout.\nWhen I hear people talking about burnout, I often feel a deep sense of sympathy, but I also feel that there is little I can do to help.","title":"Managing and Overcoming Burnout (feat. Mannerism, Slump)"},{"content":"번아웃이라는 말이 사방에서 들리고 있다. 퇴사 사유로, 이직 사유로, 휴가 사유로, 인생에 대한 어려움을 표현하는 방법으로 표현되고 있다. 다들 한 번씩은 들어봤을 거라 생각한다. 그리고 내가 번아웃인 상태가 아닌지 생각해본 적이 있을 거라 생각한다. 옆에서 번아웃 이야기를 들을 때, 정말 안타까운 마음이 들면서도 크게 도와줄 방법이 없다고 느낀 적도 많다. 여러가지 시도해볼 수 있는 이야기를 하지만 번아웃에 빠진 사람은 이야기가 들리지 않는다. 어떻게 해야할까 고민을 하다가 이렇게 글을 써본다.\n\u0026ldquo;나는 번아웃이 온 적이 없다.\u0026rdquo;\n이렇게 말하면 다들 의심어린 눈초리로 쳐다보고 진짜냐고 물어본다. 실제로 그렇고, 나는 번아웃이 온 적이 없다. 명확하게 다시 한 번 표현하자면, 번아웃이 온 적이 없고, 번아웃과 비슷한 현상이 나오는 것을 해결하는 방법을 안다고 생각하고, 이를 이겨낼 수 있다고 생각한다.\n두괄식을 선호하지만 이 이야기만큼은 미괄식으로 써본다. 차근차근 글을 읽으면서 암기과목처럼 받아들이는 것 대신에 번아웃에 대해서 이해하고 이를 다들 이겨내길 바란다.\n먼저 인터넷이 크게 발달하기 이전 시대의 이야기를 해보려고 한다. 90년대, 2000년대의 뉴스를 기억한다. 수많은 스포츠 선수, 예술가, 그리고 직장인들 사이에 유행처럼 돌던 말이 있다. 슬럼프, 매너리즘이다.\n뉴스에서 기억나는 건 박찬호와 같은 프로선수들이 중간중간 실력이 늘지 않는 슬럼프에 빠졌다는 이야기였다. 또한 공군 군입대를 앞두고, 공군이 휴가가 많은 이유에 대해서 들었다. 동일 업무를 반복하기 때문에 매너리즘에 빠진다는 이야기였다. 같은 공간 같은 일을 반복할 때 매너리즘에 빠지기 때문에 더 잦은 휴가로 변화를 주어 일상에 활력을 주기 위함이었다.\n그런데 지금은 번아웃이라는 말이 더욱 많이 나오고 있다. 왜 그럴까? 그때와 지금은 도대체 무엇이 다르고, 그리고 더이상 슬럼프와 매너리즘은 없는 것일까?\n슬럼프와 매너리즘의 시절에는 주변에 존재하는 기회와 가르침이 그사람이 배울 수 있는 한계였다고 생각한다. 좋은 학교를 가고, 좋은 선생님을 만나고, 좋은 선배를 만나고, 좋은 사수를 만나고, 그리고 그 한사람을 통해 배우는 시간을 갖는다. 내가 움직이는 시간에 만난 1명에게 필요한 것들을 배우게 된다. 이는 다시 표현하면 이런 사람들을 만나지 못하는 환경에 있던가, 배울 만한 수단(책, 비디오)이 없다면 제자리에 머무르게 되는 것이었다. 배우고 싶어도 배울만한 방법이 없던 시절이었다. 그렇다면 운좋은 깨달음이 올때까지 그 자리에서 비슷한 행동을 반복하며 있어야했다.\n그런데 지금은 어떤가 생각해보자. 지금은 배우고자하면 배울 수 있는 것을 바로 찾을 수 있다. 인터넷을 통해서, 스마트폰을 통해서, 랩탑을 통해서 빠르게 내가 원하는 걸 찾고 배울 수 있다. 유튜브를 통한 강좌만 보더라도 스탠포드 대학의 수업을 들을 수 있고, Cousera를 통해 내가 배우고 싶은 전문 지식을 쌓을 수 있다. 심지어 학위도 받을 수 있다.\n[Generated image from DALL-E-3]\n문제는 여기서 찾아온다고 생각한다. 정보가 많아도 너무 많다. 나의 시간, 나의 공간, 내가 습득할 수 있는 지식은 한정적이다. 나의 뇌 용량은 전세계에 있는 컴퓨팅 용량을 따라갈 수 없다. 그만한 프로세싱 속도도 나오지 않는다. 수많은 input은 존재하지만 나의 output은 제한적이다. 세상에 있는 것들이 있다는 사실은 인지하고 있는데, 그걸 처리하기 위한 나의 뇌가 따라오질 못할 뿐이다.\n이전에는 작은 input으로 output을 더 만들어내기 위한 시대였다면, 지금은 큰 input에서 적절하게 최적화된 output을 내는 시대이다.\n지금의 현대인들은 회사에서 더 큰 output을 나지 않을 때, 탓할 것은 자신이 처리하지 못하는 input에 신경쓰고, 밤낮없이 치열하게 살아가고 있다. 회사에서도 더 잘하기 위한 방법과, 해야할 일들을 산더미같이 쌓여있는데, 더 잘되지 않을 때는 이만한 업무를 처리하지 못하는 자신을 탓하고 있다.\n그럼 다시 냉정하게 생각해보자. 지금 우리가 처리해야하는 input은 우리가 정말 처리할 수 있다고 생각되는지? 물론 업무 자동화나, 프로세스 개선등의 일이 있다. 그러나 이 또한 일의 한 형태라는 것을 잊지 말자. 우린 개선하고, 일해야하는 게 넘쳐나고, 이를 수행하고자 한다면 끊임없이 계속 할 수 있다.\n그럼 다시 끊임없이 계속 쉬지 않고 달려나가면 어떻게 될까? 이때 번아웃이 온다고 생각한다. 몰입에 빠진 사람들은 때때로 재충전없이 달려가고 있다. 이를 통제하는 법을 배워본 적이 없고, 이게 중요하다고 학습한 적도 없다. 매일매일 전력질주를 하고 있는 셈이다.\n개인적으로는 울트라마라톤을 하기도, 자전거를 타기도 한다. 몇시간동안 힘든 상태를 유지하는 운동이다. 몇시간 동안 가장 멀리 가는 방법은 숨이 가쁘기 전 상태로 꾸준하게 달리는 것이다. 중간에 전력질주를 하면 바로 쉬어야하는 상황이 찾아올거고, 이땐 쉬었다가 다시 호흡이 찾아왔을 때 달려간다.\n번아웃을 이겨내는 방법, 그리고 번아웃이 오지 않는 상태를 조절하는 방법도 같다고 생각한다. 매일 적절한 텐션으로 계속 공부하고 일을 한다. 딱 살짝 숨찰 정도로 한다. 너무 피곤한 상태가 된다면 다음날에 오늘 보다 더 멀리 나아갈 수 없게 되고 갈 수 있는 거리가 짧아진다. 그리고 번아웃 상태가 지속된다면, 이를 다시 표현하여 숨찬 상태에서 달리기를 한다면, 얼마못가서 쓰러지고 만다.\n숨차오른 상태처럼 번아웃에 빠져서 집중이 되지 않을 때를 해결하는 방법은 단순하다. 쉰다, 혹은 멍때린다. 그리고 생각을 정리하고, 머릿속에 생각이 넘쳐날때는 글로 옮겨본다. 알고보면 대수롭지 않은 일들이 대부분이다. 이렇게 내가 숨찬 상태에서 다시 평상시 호흡을 가진 상태로 만들어주어야한다. 그래야만 더 좋은 생각, 더 좋은 선택, 더 나은 삶은 살아갈 수 있다.\n그리고 나에게 들어오는 input을 제어해야한다. 나의 처리할 수 있는 용량을 넘어서는 input이 들어오게 되면 나는 과부하에 빠져서 오히려 기존의 퍼포먼스도 안나오게된다. CPU라고 생각해도 좋다. CPU 쓰로틀링이 걸리면 오히려 기존에 처리하던 속도도 느려진다. 이유는 들어오는 input에 대해서 스케쥴링하고, 마킹하고, 처리하다가 다시 스케쥴링하려 가야하는 시간도 있기 때문이다. 결국엔 재부팅이 필요한 상태로 가는 것이다. 내가 처리할 수 있는 가용영역을 넘어서면 오히려 기존의 성능도 안나오는 상태가 된다. 내가 처리할 수 있는 수준을 계속 인지하면서 들어오는 input을 제어하는 게 중요한 시점이다.\n위와 같은 내용에 동의할 수도 있고, 다른 의견이 있을 수도 있다. 그런데 여태까지 수없이 주어지는 일을하면서 압박감을 가지기도 하고, 고민도 하면서 어떻게 이겨냈는지 여러번 생각하고 곱씹어 보았다.\n몇몇은 이미 내게 이런 이야기들 듣기도 했다. 도움을 받은 사람이 기억에 남아 이렇게 글로 남겨보았다. 부디 많은 사람들이 번아웃에 매몰되지 않고 이겨내길 바란다.\n","permalink":"https://novemberde.github.io/post/2024/02/18/throttle-input-to-prevent-burning-out/","summary":"번아웃이라는 말이 사방에서 들리고 있다. 퇴사 사유로, 이직 사유로, 휴가 사유로, 인생에 대한 어려움을 표현하는 방법으로 표현되고 있다. 다들 한 번씩은 들어봤을 거라 생각한다. 그리고 내가 번아웃인 상태가 아닌지 생각해본 적이 있을 거라 생각한다. 옆에서 번아웃 이야기를 들을 때, 정말 안타까운 마음이 들면서도 크게 도와줄 방법이 없다고 느낀 적도 많다. 여러가지 시도해볼 수 있는 이야기를 하지만 번아웃에 빠진 사람은 이야기가 들리지 않는다. 어떻게 해야할까 고민을 하다가 이렇게 글을 써본다.\n\u0026ldquo;나는 번아웃이 온 적이 없다.","title":"번아웃을 통제하고 이겨내는 방법(feat. 매너리즘, 슬럼프)"},{"content":"배경 AWS re:Invent 2023에서 \u0026ldquo;A career journey for serverless and container cloud developers\u0026rdquo; 라는 공통주제로 발표를 준비했다. 여기서 중요하게 다루고자 했던 것은 소프트웨어 엔지니어가 이전의 프로그래머 시대와 어떤 부분에서 노력할 지에 대한 방향이었다.\n\u0026ldquo;소프트웨어 엔지니어의 덕목\u0026rdquo; 이라는 주제로 시장이 변화해감에 따라 엔지니어의 다른 역량들을 더욱 필요로 한다는 점을 표현하고 싶었고, 이런 관점을 공유함으로써 다양한 엔지니어의 성장에 조금이나마 기여하려 하였다.\n발표 자료 및 영상 References https://youtu.be/gdqgk17T2Xw?si=sPEVjrg7rIFmeI4S ","permalink":"https://novemberde.github.io/post/2023/11/29/career-journey/","summary":"배경 AWS re:Invent 2023에서 \u0026ldquo;A career journey for serverless and container cloud developers\u0026rdquo; 라는 공통주제로 발표를 준비했다. 여기서 중요하게 다루고자 했던 것은 소프트웨어 엔지니어가 이전의 프로그래머 시대와 어떤 부분에서 노력할 지에 대한 방향이었다.\n\u0026ldquo;소프트웨어 엔지니어의 덕목\u0026rdquo; 이라는 주제로 시장이 변화해감에 따라 엔지니어의 다른 역량들을 더욱 필요로 한다는 점을 표현하고 싶었고, 이런 관점을 공유함으로써 다양한 엔지니어의 성장에 조금이나마 기여하려 하였다.\n발표 자료 및 영상 References https://youtu.be/gdqgk17T2Xw?si=sPEVjrg7rIFmeI4S ","title":"A career journey for serverless and container cloud developers: 소프트웨어 엔지니어의 덕목"},{"content":"배경 아우쓱콘(https://festa.io/events/3504)에서 발표 요청이 왔고, 주니어 엔지니어에게 하고 싶은 이야기를 해달라고 하였다. 덕분에 지난 시간을 되돌아볼 수 있었고, 작게나마 이야기를 정리할 수 있었다.\n무슨 이야기를 하면 도움이 될까 고민을 했다. 주니어 때 가졌던 고민을 무엇이었나. 이런 상황들이 있었다.\n쏟아지는 상황에 지쳐있었다. 앞이 보이지 않는 상황에 지쳐있었다 새로운 지식을 미친듯이 공부하고 있었다. 찍먹하면서 다양한 지식을 습득하고 있었다. 무작정 해보고 잘 안된다고 생각하고 있었다. 이런 상황에서 다양한 선택들을 해보고 방법을 찾아보았다. 그중에서 배운 방법들이 있었고, 잘 동작한다고 느꼈다. 이를 공유하는 것을 목표로 삼고, 이를 본 많은 사람들 중 한 명이라도 도움이 되었으면 하면서 발표를 준비하였다.\n발표 자료 질문과 답변 모음 조금이라도 팔팔할 때 경험이 적을 때, 어디가 내 천장인지 혹은 내가 한 번에 어디까지 뛰어볼 수 있는지 가늠해보는 것도 중요한 경험이라고 생각하는데 어떻게 생각하시나요? 바꿔 말하자면, 규현님은 처음 코딩을 시작하셨을 때부터 혹은 처음 입사하셨을 때부터 마라톤 하듯이 일을 하셨나요?\n격하게 동의합니다. 말씀하신 방향은 한계를 계속 시험하고 성장한다는 관점인데 동의해요. 다만 이번에 공유했던 내용은 지속가능한 성장에 대한 관점이에요. 한 두 번 시도하고 접는 사람들이 주변에 보면 많을거에요. 새해마다 헬스장에가서 무리하고 그다음부터 운동안하는 사람들이 많은 것 처럼요. 그런데 작은 목표를 세우고 꾸준히 하면 1년 후에 크게 달라진 모습이 되어있어요. 공부도 계속하고 꾸준히 성장해야 더 멀리갈 수 있는데, 단기적으로 과몰입하여 지쳐서 장기적인 성장의 원동력을 잃는 경우를 목격했던 것 같아요. 개인의 관찰 경험이라 설득력이 부족하긴 하지만변 지속적인 성장이 된다면 한 번에 성장하는 것보다 더 크게 성장할 수 있다고 이야기하고 싶었어요.\n시작했을 때부터 하루도 빠짐없이 공부하고, 일하고 고민하며 성장해왔는데요, 하루에 8~10시간을 넘기진 않았어요. 간혹 급한 일에는 시간을 많이 투자하긴 했지만 극히 드문케이스이고, 꾸준히 지속적으로하는 것에 초점을 맞춰왔어요. 오래 성과를 내기 위해선 지치지 않는 체력이 중요하고, 꾸준히 성과를 내야 지속적인 성장의 근거가 뒷받침되는 것 같아요. 체력관리를 위해 아직도 일주일에 몇회이상 자전거 유도 등 운동해서 체력관리도 하고, 공부를 위해 투자하는 시간 또한 지속적으로 할애하고 있어요.\n\u0026ldquo;너무 급하게 뛰지 마라\u0026quot;와 같이 왜 주니어에게 마라톤하듯이 나아가라는 조언을 하시게 된 건가요?\n요즘 번아웃 증후군이라는 말을 주니어한테 더 많이 듣는 것 같았어요. 심심찮게 힘들다는 말을하고, 쉽게 포기하는 상황도 봤던 것 같고요. 시장에서 계속 이겨내고 성장하는 사람들은 순간에 만들어지지 않았어요. 지속적인 피드백을 받고 꾸준히 성장했어요. 지치는 타이밍엔 쉴 줄도 알고, TIL과 같이 하루하루 배운 것을 작게나마 정리하고요. 제가 일하며 느낀점은 하루에 크게 이룰 수 있는 건 극히 드물다는 거에요. 프로젝트 하나를 시작하면 짧게는 한달 길게는 1년을 하는데, 성공하는 프로젝트는 만들고 끝나는 게 아니라 만들고 지켜보면서 계속 하나씩 개선해나가는 프로덕트였어요. 이건 이야기하자면 너무 긴데\u0026hellip; 짧게 설명하자면 이렇습니다.\n","permalink":"https://novemberde.github.io/post/2023/06/07/junior-engineer-growth-guide/","summary":"배경 아우쓱콘(https://festa.io/events/3504)에서 발표 요청이 왔고, 주니어 엔지니어에게 하고 싶은 이야기를 해달라고 하였다. 덕분에 지난 시간을 되돌아볼 수 있었고, 작게나마 이야기를 정리할 수 있었다.\n무슨 이야기를 하면 도움이 될까 고민을 했다. 주니어 때 가졌던 고민을 무엇이었나. 이런 상황들이 있었다.\n쏟아지는 상황에 지쳐있었다. 앞이 보이지 않는 상황에 지쳐있었다 새로운 지식을 미친듯이 공부하고 있었다. 찍먹하면서 다양한 지식을 습득하고 있었다. 무작정 해보고 잘 안된다고 생각하고 있었다. 이런 상황에서 다양한 선택들을 해보고 방법을 찾아보았다. 그중에서 배운 방법들이 있었고, 잘 동작한다고 느꼈다.","title":"성장하는 엔지니어가 되는 법: 주니어편"},{"content":"Background 최근 많이 했던 고민이 있다. 하고 싶은 대로 하는 게 정말 좋은 것인지, 아니면 해야 할 일을 하는 게 좋은 것인지 답을 내리지 못했다. 다만 이전까지의 생각은 있었다.\n\u0026ldquo;하고 싶은 대로 하는 게 좋은 것이야.\u0026rdquo;\n그런데도 마음 한 켠에는 불안감이 있었다. 왜냐하면 하고 싶은 대로 했을 때 주변에서의 시선과 업무에서의 성과가 좋지 않은 경우가 여러 번 관찰되었다. 하고 싶은 대로 했을 때 모두가 임팩트가 있다고 느끼는 결과를 보기 어려웠다. 결과가 나왔을 때, 실제로 서비스에 긍정적인 영향을 주지 못했고, 장기적인 관점에서 서비스를 개선하거나, 고도화하는 데 어려움을 느꼈다.\n점차 하고 싶은 것을 하는 것보다 중요한 건 해야할 것들을 하나씩 해결해나가는 게 중요하다고 느끼는데, 논리적으로 설명이 어려웠다. 누군가에게 내 생각을 강요하는 것 같기도 했고, 이를 좀 더 이해할 수 있게 설명하고 싶었다.\n이번에 미국을 다녀오면서 이 고민에 대해서 팀원들과 이야기했고, 이 안에서 현재 하고 싶은 대로 하는 것이 왜 문제가 되는지 정리해보았다.\nWhy? 왜 하고 싶은대로 하는 게 문제이고, 어떻게 하면 더 나은 제품을 만들 수 있을까?\n스포츠에서 힌트를 얻을 수 있었다. 일반인이 싸우는 것과 UFC에서 프로들이 경기를 하는 것을 비교했을 때 무엇이 다를까?\n먼저, 일반인의 경기에서 보통 이기는 사람은 누구일까? 보통은 힘이 더 좋은 사람, 혹은 운동을 배워서 기술이 더 뛰어난 사람이 이긴다. 일반인 세계에서는 역량차이가 명확하게 드러난다.\n그러나 프로세계는 다르다. 힘이 세거나 기술이 뛰어나거나 이런 걸로 이길 수 없다. 전부 수준급의 역량을 지니고 있고 그 격차는 정말 작은 차이이다.\n그럼 프로세계에서 이기기 위해서는 어떻게 해야할까?\nHow to 우린 IT Industry의 프로 세계에 있다.\nUFC나 프로복싱 경기에서 선수들의 눈을 본 적이 있는가?\n눈빛은 차갑고 냉정하다. 끊임없이 상대를 관찰하고 흥분하지 않는다. 만약 흥분했다면?\n카운터 펀치를 맞고 바로 KO패를 당한다. 하고싶은 대로 했으니까 후회가 없을까? 당연히 아니다. 이기지 못하면 아쉬움이 남는다. 경기에 임하고 이기지 못한다면 후회는 반드시 남는다. 후회하지 않으려면 그 과정에서 최선을 다해야 한다.\n우린 지금 프로세계에 있다. 하고싶은 대로 게임을 하면 이길 확률이 줄어든다. 게임을 이기기 위해선 정확한 전략이 있어야하고, 각 스텝마다 이뤄야하는 정확한 목표가 있어야한다. 그리고 목표를 이루기 위해 코치/감독의 말에 귀를 기울이고 끊임없이 개선하고 대응하면서 게임을 해야한다. 그래야만 긴 라운드 끝에 승리를 거머쥘 수 있다.\n프로선수는 어느 분야이건 본인이 하고 싶은대로 게임을 진행하지 않는다. 전체 게임에서 내가 제일 잘할 수 있는 점을 시의적절하게 코칭해주는 사람의 이야기를 듣고 역량을 발휘해야한다. 그런다면 승리에 좀 더 가까운 선택을 매순간 할 것이다.\n순간에 하고 싶은대로 한다면 그 순간에는 만족할지 몰라도, 마지막 결과를 받고 후회를 한다. 우린 이기는 게임을 위해 최선의 노력을 해야 후회가 덜 남는다.\n이기는 게임을 만들기 위해 주변 사람들과 함께 끊임없이 노력해야한다. 그리고 이걸 잘 해내야만 프로 세계에서 이길 수 있다.\n이번에 월드컵을 보고도 비슷한 점을 느꼈다. 손흥민이 개인기를 하고 본인이 골을 넣으려고 하던가? 손흥민은 팀의 승리를 원한다. 본인이 골을 넣으려는 시도를 할 수 있지만 골을 넣을 가능성이 더 높은 곳에 패스를 하고, 공통의 목표에 도달하는 데 기여하고, 이에 주저함이 없었다.\n프로 세계에서 이기려면 침착하고, 냉정하게 상황을 분석하고, 때로는 코칭에 맞춰서 움직이며 이기는 결과를 만들기 위해 최선을 다해야한다. 그래야 후회가 남지 않는다.\nConclusion 순간 순간 하고 싶은대로 살아도 괜찮다. 다만 그렇게 한다면 목표를 이룰 수 없다.\n목표를 이루고 싶고, 정확한 그림이 있다면 우린 거기에 도달하기 위해 최적 경로를 찾아 움직여야한다.\n최선의 선택을 빠르게 내리고, 중간중간 도움을 받기도 도움을 주기도 하면서 팀으로써 결과를 내야한다. 내가 가진 생각을 전체를 위해 녹여내기도 하고, 가끔은 반성도 하면서 더 나은 결과를 내기 위해 노력해야한다.\n큰 목표가 있다면, 이룰 수 있도록 거기에 맞는 최선을 다해야 한다.\n","permalink":"https://novemberde.github.io/post/2022/12/13/professional-player/","summary":"Background 최근 많이 했던 고민이 있다. 하고 싶은 대로 하는 게 정말 좋은 것인지, 아니면 해야 할 일을 하는 게 좋은 것인지 답을 내리지 못했다. 다만 이전까지의 생각은 있었다.\n\u0026ldquo;하고 싶은 대로 하는 게 좋은 것이야.\u0026rdquo;\n그런데도 마음 한 켠에는 불안감이 있었다. 왜냐하면 하고 싶은 대로 했을 때 주변에서의 시선과 업무에서의 성과가 좋지 않은 경우가 여러 번 관찰되었다. 하고 싶은 대로 했을 때 모두가 임팩트가 있다고 느끼는 결과를 보기 어려웠다. 결과가 나왔을 때, 실제로 서비스에 긍정적인 영향을 주지 못했고, 장기적인 관점에서 서비스를 개선하거나, 고도화하는 데 어려움을 느꼈다.","title":"스포츠를 통해 배운 프로처럼 일하는 방법"},{"content":"채팅은 맨 처음 입사하고 나서 맡은 프로젝트였고, 지금까지도 운영하고 개선하는 서비스이다. 처음에 Ruby on rails 로 개발하던 환경에서 처음으로 시작한 마이크로서비스다. 시작할 때의 고민과 그리고 지금까지의 달려온 여정에서 어떠한 결정을 했는지 고민이 담긴 발표였다.\n영상 References https://youtu.be/lCxgddyxDyg https://summits-korea.virtual.awsevents.com/media/01.%202200%EB%A7%8C%20%EC%82%AC%EC%9A%A9%EC%9E%90%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EC%B1%84%ED%8C%85%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/1_ybuscua9 2200만_사용자를_위한_채팅_시스템_아키텍처.pdf https://byline.network/2022/05/0512-2/ ","permalink":"https://novemberde.github.io/post/2022/05/12/karrot-chat-system/","summary":"채팅은 맨 처음 입사하고 나서 맡은 프로젝트였고, 지금까지도 운영하고 개선하는 서비스이다. 처음에 Ruby on rails 로 개발하던 환경에서 처음으로 시작한 마이크로서비스다. 시작할 때의 고민과 그리고 지금까지의 달려온 여정에서 어떠한 결정을 했는지 고민이 담긴 발표였다.\n영상 References https://youtu.be/lCxgddyxDyg https://summits-korea.virtual.awsevents.com/media/01.%202200%EB%A7%8C%20%EC%82%AC%EC%9A%A9%EC%9E%90%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EC%B1%84%ED%8C%85%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/1_ybuscua9 2200만_사용자를_위한_채팅_시스템_아키텍처.pdf https://byline.network/2022/05/0512-2/ ","title":"2200만 사용자를 위한 채팅 시스템 아키텍처"},{"content":"보통 Airflow 와 EMR 조합으로 통계 파이프라인을 관리하곤 한다. 사내에서 빠르게 통계를 구축하고 관리하기 위해 불필요한 인프라 관리를 제외하고 pipeline에 대해서만 집중할 수 있도록 step functions를 도입하고, 이 경험에 대해서 공유해보았다.\nYoutube Slides Athena \u0026amp; Step Function 으로 통계 파이프라인 구축하기 - 변규현 (당근마켓) :: AWS Community Day Online 2021 from AWSKRUG - AWS한국사용자모임 References https://youtu.be/MS7CulWSc2g https://www.slideshare.net/awskr/athena-step-function-aws-community-day-online-2021 ","permalink":"https://novemberde.github.io/post/2021/10/25/athena-step-function/","summary":"보통 Airflow 와 EMR 조합으로 통계 파이프라인을 관리하곤 한다. 사내에서 빠르게 통계를 구축하고 관리하기 위해 불필요한 인프라 관리를 제외하고 pipeline에 대해서만 집중할 수 있도록 step functions를 도입하고, 이 경험에 대해서 공유해보았다.\nYoutube Slides Athena \u0026amp; Step Function 으로 통계 파이프라인 구축하기 - 변규현 (당근마켓) :: AWS Community Day Online 2021 from AWSKRUG - AWS한국사용자모임 References https://youtu.be/MS7CulWSc2g https://www.slideshare.net/awskr/athena-step-function-aws-community-day-online-2021 ","title":"Athena \u0026 Step Functions 로 통계 파이프라인 구축하기"},{"content":"Byun Kyuhyun? 유도와 주짓수를 하며 로드바이크를 즐기는 개발자.\nThe developer who enjoy riding a bicycle and playing judo \u0026amp; jiu-jitsu.\nCurrently working at Karrot🥕. AWS Serverless HERO Links Github Linkedin ","permalink":"https://novemberde.github.io/about/","summary":"Byun Kyuhyun? 유도와 주짓수를 하며 로드바이크를 즐기는 개발자.\nThe developer who enjoy riding a bicycle and playing judo \u0026amp; jiu-jitsu.\nCurrently working at Karrot🥕. AWS Serverless HERO Links Github Linkedin ","title":"About"},{"content":"Docker desktop이 유료로 전환된다는 소식이 있다. (링크)\n이 소식을 들은 많은 개발자들은 당황했을거라 생각하는데 언제나 그랬듯이 대안은 있다. 사내에 이미 이런 내용에 대해서 대응하신 분이 있고, 그걸 글로 녹여보려고 한다.(Ian 감사해요) 아래 내용은 Mac에만 해당되며, Window는 별도의 방법을 찾아야할지도 모른다.\nDocker Desktop 삭제하기 이건 어렵지 않다. 다음 그림과 같이 docker desktop \u0026gt; Preferences \u0026gt; troubleshootings \u0026gt; uninstall 을 눌러 삭제한다.(그림참고)\n그리고 말끔하게 Applications(응용프로그램)에 있는 docker desktop도 삭제한다.\nminikube 설치하기 m1 mac인 경우에는 \u0026ldquo;Disable all drivers except \u0026ldquo;docker\u0026rdquo; and \u0026ldquo;ssh\u0026rdquo; on darwin/arm64\u0026rdquo; PR의 내용을 요약하자면, minikube에서는 m1 mac을 사용할 수 없다는 내용이다. docker를 사용하던지 아니면 ssh로 remote host를 써야한다. 로컬에 virtualbox나 vmware로 띄우고 ssh를 써도 사용은 되겠지만, localhost에서 사용하기 위한 다른 설정을 하는 건 조금 수고스럽다고 생각된다.\n당장은 방법이 없으니 조금만 더 docker desktop을 사용하면 된다.\n만약 podman이 apple silicon을 지원하게 된다면 그때 이 문서를 다시 업데이트할 것이다.\n설치하기 $ brew install hyperkit $ brew install minikube $ minikube start --driver=hyperkit 확인하기 $ kubectl get po -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-558bd4d5db-fb4qn 1/1 Running 0 3m37s kube-system etcd-minikube 1/1 Running 0 3m48s kube-system kube-apiserver-minikube 1/1 Running 0 3m48s kube-system kube-controller-manager-minikube 1/1 Running 0 3m48s kube-system kube-proxy-9k4vr 1/1 Running 0 3m37s kube-system kube-scheduler-minikube 1/1 Running 0 3m48s kube-system storage-provisioner 1/1 Running 0 3m50s Kompose로 docker-compose.yml을 minikube에 올리기 Kompose 설치하기 $ brew install kompose docker-compose.yml을 kompose convert하고 배포하기 docker.compose.yml 파일\nversion: \u0026#34;2\u0026#34; services: redis-master: image: k8s.gcr.io/redis:e2e ports: - \u0026#34;6379\u0026#34; redis-slave: image: gcr.io/google_samples/gb-redisslave:v3 ports: - \u0026#34;6379\u0026#34; environment: - GET_HOSTS_FROM=dns frontend: image: gcr.io/google-samples/gb-frontend:v4 ports: - \u0026#34;80:80\u0026#34; environment: - GET_HOSTS_FROM=dns labels: kompose.service.type: LoadBalancer Convert 하기 $ kompose convert -f docker-compose.yml --out converted.yml 배포하기 $ kubectl apply -f converted.yml # 확인해보기 $ kubectl get po -A NAMESPACE NAME READY STATUS RESTARTS AGE default frontend-69f6f756d8-4kmpk 1/1 Running 0 47s default redis-master-db85b98bc-4kzlm 0/1 ContainerCreating 0 47s default redis-slave-69bf546647-8499k 1/1 Running 0 47s kube-system coredns-558bd4d5db-fb4qn 1/1 Running 0 25m kube-system etcd-minikube 1/1 Running 0 25m kube-system kube-apiserver-minikube 1/1 Running 0 25m kube-system kube-controller-manager-minikube 1/1 Running 0 25m kube-system kube-proxy-9k4vr 1/1 Running 0 25m kube-system kube-scheduler-minikube 1/1 Running 0 25m kube-system storage-provisioner 1/1 Running 0 25m 후기 docker cli의 명령어들이 익숙한 상황에서 kubectl이 조금 불편하긴 하지만 이미 컨테이너를 사용하는 환경에서는 k8s가 지배하고 있기 때문에 이참에 적응하는 것도 참 좋을 것 같다. minikube가 워낙 가볍기도 하고 연습하기 좋아서 장기적으로는 이번에 갈아타는 게 좋지 않을까 조심스레 추천해본다.\nReferences https://minikube.sigs.k8s.io/docs/start/ https://kubernetes.io/docs/tasks/configure-pod-container/translate-compose-kubernetes/ ","permalink":"https://novemberde.github.io/post/2021/09/02/podman-minikube/","summary":"Docker desktop이 유료로 전환된다는 소식이 있다. (링크)\n이 소식을 들은 많은 개발자들은 당황했을거라 생각하는데 언제나 그랬듯이 대안은 있다. 사내에 이미 이런 내용에 대해서 대응하신 분이 있고, 그걸 글로 녹여보려고 한다.(Ian 감사해요) 아래 내용은 Mac에만 해당되며, Window는 별도의 방법을 찾아야할지도 모른다.\nDocker Desktop 삭제하기 이건 어렵지 않다. 다음 그림과 같이 docker desktop \u0026gt; Preferences \u0026gt; troubleshootings \u0026gt; uninstall 을 눌러 삭제한다.(그림참고)\n그리고 말끔하게 Applications(응용프로그램)에 있는 docker desktop도 삭제한다.\nminikube 설치하기 m1 mac인 경우에는 \u0026ldquo;Disable all drivers except \u0026ldquo;docker\u0026rdquo; and \u0026ldquo;ssh\u0026rdquo; on darwin/arm64\u0026rdquo; PR의 내용을 요약하자면, minikube에서는 m1 mac을 사용할 수 없다는 내용이다.","title":"minikube로 docker와 docker-compose를 대체하기"},{"content":"Jandi라는 업무메신저를 개발하는 토스랩에서 어떻게 일하는지 공유할 수 있냐고 요청이 왔다. 이번에 번아웃, One-on-one Meeting, 그리고 회의등에 대해서 고민을 많이 했는데, 마침 적절한 기회라 생각해서 참여했다.\n역시 전문적인 사람들이라 인터뷰 내용을 블로그에 깔끔하게 정리해주셨는데, 강조한 내용들을 그림으로 넣어주어 이해를 도왔다.\n자세한 내용은 Youtube 영상 및 블로그 글을 참고하길 바란다.\nYoutube Jandi Blogs http://blog.jandi.com/ko/2021/08/31/how_to_work_carrot_interview/ References http://blog.jandi.com/ko/2021/08/31/how_to_work_carrot_interview/ https://www.youtube.com/watch?v=5I94tQJUrh8 ","permalink":"https://novemberde.github.io/post/2021/08/31/Jandi-monthly/","summary":"Jandi라는 업무메신저를 개발하는 토스랩에서 어떻게 일하는지 공유할 수 있냐고 요청이 왔다. 이번에 번아웃, One-on-one Meeting, 그리고 회의등에 대해서 고민을 많이 했는데, 마침 적절한 기회라 생각해서 참여했다.\n역시 전문적인 사람들이라 인터뷰 내용을 블로그에 깔끔하게 정리해주셨는데, 강조한 내용들을 그림으로 넣어주어 이해를 도왔다.\n자세한 내용은 Youtube 영상 및 블로그 글을 참고하길 바란다.\nYoutube Jandi Blogs http://blog.jandi.com/ko/2021/08/31/how_to_work_carrot_interview/ References http://blog.jandi.com/ko/2021/08/31/how_to_work_carrot_interview/ https://www.youtube.com/watch?v=5I94tQJUrh8 ","title":"잔디 월간일잘러: 빠르게 성장하는 당근마켓에서 효율적으로 일하는 방법"},{"content":"여태까지 서버개발자로 성장하며 생각했던 바를 정리해보았다. 모두 똑같이 성장할 수는 없다. 이렇게 성장한 사람도 있다는 관점에서 봐주었으면 한다. 영상은 원티드 구독을 해야만 볼 수 있다.\n발표를 아티클화하였는데, 다음 글을 보는게 제일 빠르게 영상을 이해할 수 있다. 5분도 안걸리니 읽는 것을 추천한다. https://www.wanted.co.kr/events/22_02_s01_b06\n참고로, 이때 들었던 분의 요약본도 있는데 이 블로그를 읽어봐도 좋다.\nSlides 성장하는 서버 개발자 되기 - Wanted Livetalk from Kyuhyun Byun References https://www.wanted.co.kr/events/22_02_s01_b06 요약정리: https://covenant.tistory.com/248 https://www.wanted.co.kr/events/livetalk28 https://www.wanted.co.kr/wantedplus/video/K7txZeA2?category=518 ","permalink":"https://novemberde.github.io/post/2021/06/27/Wanted-server-developer/","summary":"여태까지 서버개발자로 성장하며 생각했던 바를 정리해보았다. 모두 똑같이 성장할 수는 없다. 이렇게 성장한 사람도 있다는 관점에서 봐주었으면 한다. 영상은 원티드 구독을 해야만 볼 수 있다.\n발표를 아티클화하였는데, 다음 글을 보는게 제일 빠르게 영상을 이해할 수 있다. 5분도 안걸리니 읽는 것을 추천한다. https://www.wanted.co.kr/events/22_02_s01_b06\n참고로, 이때 들었던 분의 요약본도 있는데 이 블로그를 읽어봐도 좋다.\nSlides 성장하는 서버 개발자 되기 - Wanted Livetalk from Kyuhyun Byun References https://www.wanted.co.kr/events/22_02_s01_b06 요약정리: https://covenant.tistory.com/248 https://www.wanted.co.kr/events/livetalk28 https://www.wanted.co.kr/wantedplus/video/K7txZeA2?category=518 ","title":"Wanted livetalk: 성장하는 서버개발자 되기"},{"content":"Golang은 Open source project 이며 모든 개발 내역이 Github에 코드로 구현되어 있다. 하나하나의 구현 내용을 이해하고 싶다면 각 패키지를 읽어보며 이해할 수 있다. 그렇지만 방대한 양이기 때문에 처음에 접하는 경우에는 어디서부터 읽어야할지, 그리고 기본적인 구조를 어떻게 잡아야하는지 어렵기만 하다.\n그렇다면 Golang의 기본적인 구조에 대해서 이해하고 싶다면 어떻게 시작해야할까? 다행히도 고언어 개발자들은 HANKING.md에 기본적인 내용을 정리해두었다. 고언어의 런타임이 어떤 구조로 이뤄져 있는지, 그리고 동시성 처리를 위한 방식이나 메모리 관리 측면에서는 어떻게 하고 있는지 등 다양한 내용이 정리되어 있다.\n이번에는 HAKING.md를 번역하며 고언어에 대해서 더 깊은 이해를 해보려 한다.\n원문을 읽고 싶다면 https://golang.org/src/runtime/HACKING.md 여기를 참고 바란다.\nhttps://golang.org/src/runtime/HACKING.md 이것은 지속적으로 업데이트되고 있는 문서이며, 때때로 업데이트 시기를 놓칠 수도 있다. 일반적인 고언어를 사용하는 것과 달리 고런타임이 얼마나 프로그래밍에서 다른지 명료하게 설명한다. 특정 인터페이스의 디테일보다 광범위한 관점에 집중에서 설명하려고 한다.\nScheduler structures 스케쥴러는 런타임에 걸쳐서 세 가지 유형의 리소스로 운영한다: G, M, 그리고 P. 직접 스케쥴러를 통한 로직을 돌리지 않더라도, 이것을 이해하는 것은 중요하다.\nGs, Ms, Ps \u0026ldquo;G\u0026rdquo; 는 간단하게 고루틴이다. type을 g 로 표현한다. 고루틴이 존재할 때, g 객체는 사용가능한 g 풀에 반환되고, 이것은 다른 고루틴에 의해 재사용될 수 있다.\n\u0026ldquo;M\u0026rdquo; 은 OS Thread 인데, 유저의 Go code, 런타인 코드, 시스템 콜을 실행할 수 있으며, idle 상태로 있을 수 있다. type을 m 으로 표현한다. 시스템 콜에서 쓰레드 수가 블록될 수도 있기 때문에 한 번에 임의의 수로 M이 있을 수 있다.\n마지막으로, \u0026ldquo;P\u0026rdquo; 는 스케쥴러 및 메모리 할당하는 것과 같이 유저의 Go code를 설행하기 위해 요구되는 리소스를 나타낸다. type을 p 로 표현한다. GOMAXPROCS가 Ps와 동일하다. P는 OS 스케쥴러에 있는 CPU와 같다고 생각할 수 있고, p type이 가지고 있는 내용은 각 CPU State 와 같다. 효율성을 위해 샤딩이 필요하지만, 쓰레드당 또는 고루틴일 필요없는 상태를 두기에 적절한 곳이다.\n스케쥴러의 역할은 G(코드 실행), M(실행할 곳), 그리고 P(실행권한과 리소스)를 매칭하는 것이다. Go code를 실행하는 것을 M이 멈출 때, 예를 들어 시스템콜이 들어온다고 가정하면, 이 P는 Idele P로 반환된다. 그리고 Go code를 재실행하기 위해선, 시스템 콜에서 반환되면, idle pool에서 P를 획득해야만 한다.\n모든 g, m, 그리고 p 객체는 Heap에 할당되고, 절대 해제되지는 않는다. 따라서 안정적인 상태로 메모리에서 유지된다. 결론적으로 런타임은 스케쥴러 단에서 쓰기장벽(Write barriers)를 피할 수 있다.\nUser stacks and system stacks 모든 non-dead G는 Go code가 실행되는 User stack과 연결되어 있다. User stack은 2K와 같이 작은 값으로 시작하고, 동적으로 증가 및 축소된다.\n모든 M은 연결된 시스템 스택(Stub G로 구현되기 때문에 M의 \u0026ldquo;g0\u0026rdquo; stack이라고 알려짐)이 있고, 유닉스 플랫폼에서의 Signal stack이 있다(M의 \u0026ldquo;gsignal\u0026rdquo; stack 이라고 알려짐). System 및 Signal stack 모두 증가될 수 없지만, 런타임에 실행되고 cgo code를 실행하기에 충분히 크다(순수 Go binary에서는 8K; cgo binary에서 시스템할당됨).\n런타임 코드는 systemstack, mcall, 또는 asmcgocall을 사용하여 종종 일시적으로 System stack으로 전환하여 선점되지 않아야만 하는 task를 수행하는데, 이는 User stack을 증가하지 말아야 하는 task나, user goroutine을 전환하는 작업이 있다. System stack에서 실행되는 코드는 암묵적으로 비선점이고, Garbage collector는 System stack을 스캔하지 않는다. System stack이 실행되고 있는 동안, 현재의 user stack은 실행에 사용되지 않는다.\ngetg() and getg().m.curg 현재 유저의 g 를 획득하기 위해서 getg().m.curg 를 사용한다.\ngetg() 는 단독으로 현재의 g 를 반환하지만, system 또는 signal stack에서 실행될 때, 이는 현재의 m의 \u0026ldquo;g0\u0026rdquo; 또는 \u0026ldquo;gsignal\u0026rdquo; 을 각각 반환한다. 이것은 일반적으로 원하는 방식은 아니다.\nUser stack 또는 System stack에서 실행되고 있는지 확인하고 싶다면 getg() == getg().m.curg 인지 확인한다.\nError handling and reporting user code 로 합리적인 방식으로 recover 될 수 있는 에러는 일반적으로 panic을 사용해야 한다. 하지만, mallocgc 동안 system stack에서 호출되는경우와 같이 panic이 즉시 fatal error를 일으키는 경우도 있다.\n대부분의 런타임 에러는 recover가 가능하지 않다. 이런 경우에는 throw를 사용한다. throw는 traceback을 덤프하고 즉시 process를 종료한다. 일반적으로 throw는 위험한 상황에서 할당하는 것을 피하기 위해 string constant를 전달해야한다. 관례적으로, 추가적인 디테일은 print 또는 println으로 출력되고 \u0026ldquo;runtime: \u0026quot; 이라는 prefix 메시지가 붙는다.\n런타임 error 디버깅을 위해, GOTRACEBACK=system 또는 GOTRACEBACK=crash fmf 함께 실행하는 것이 유용하다.\nSynchronization 런타임은 여러 동기화 메커니즘이 있다. 의미론 적으로 다른 것이 있는데, 특히 Goroutine scheduler 또는 OS scheduler와 상호작용하는 여부에 따라 다르다.\n가장 단순하게 생각해보면 mutex가 있다. lock과 unlock을 사용하여 조작한다. 이것은 짧은 기간동안 공유된 structure를 보호하는데 사용된다. mutex에서의 블로킹은 Go scheduler와 상호작용하지 않는다면, 직접적으로 M을 블록한다. 이는 런타임에서 가장 낮은 레벨에서 사용되어 안전하다는 것을 의미한다. 뿐만 아니라, reschedule되는 것으로 부터 G와 P와 연관된 어떠한 것도 안전하게 처리한다. rwmutex 와 비슷하다.\none-shot notification을 위해 note 를 사용한다. note 는 notesleep 과 notewakeup 과 같은 함수를 제공한다. 전통적인 UNIX에서의 sleep/wakeup 과 달리, note는 race-free 이다. 그래서 notesleep은 notewakeup이 일어나자마자 즉시 반환된다. note는 sleep하거나 wakeup와 절대 race하지 않는 noteclear 와 함께 리셋될 수 있다. Mutex와 같이 note에서 블로킹하고 있다면 M을 블록한다. 하지만 note에서 sleep하는 다른 방식도 있다: notesleep은 G와 P와 연관된 어떤 것도 rescheduling을 예방하는 반면에, notesleepg는 System call을 블로킹하는 것처럼 작동하는데 다른 G를 재사용하는 P를 허용한다. 이것은 M을 소비하기 때문에 G를 직접적으로 블로킹 하는 것보다 덜 효율적이다.\nGooutine scheduler와 직접적으로 소통하기 위해, gopark 와 goready 를 사용한다. gopark는 현재의 goroutine을 \u0026ldquo;waiting\u0026rdquo; 상태에 두고 스케쥴러의 run queue에서 제거한다. 그리고 다른 goroutine을 현재의 M/P에 할당한다. goready는 parked goroutine을 다시 \u0026ldquo;runnable\u0026rdquo; 상태로 돌리고, run queue에 추가한다.\n요약하자면 다음과 같다.\nBlocks InterfaceGMP (rw)mutexYYY noteYYY/N parkYNN Atomics 런타임 패키지에서는 runtime/internal/atomic 에 있는 것으로 런타임만을 위한 원자성 패키지를 사용한다. 이것은 sync/atomic 과 일치하지만 역사적인 이유로 다른 이름의 함수명을 갖고 있고 런타임에 필요한 몇가지 추가 함수들이 있다.\n일반적으로 우리는 불필요한 atomic operation을 피하기 위해 노력하고, 런타임에서 atomic하게 사용하는 것을 힘들게 생각한다. 변수 접근이 동기화 메커니즘에 보호되는 경우에, 이미 보호된 접근은 일반적으로 atomic하지 않아도 된다. 몇가지 이유가 있다.\nnon-atomic 또는 atomic 접근을 사용하는 것은 코드가 자체적으로 문서화된다. 변수에 대한 atomic 접근은 이 변수가 어딘가에서 동시에 접근될지도 모른다는 것을 함축하고 있다. Non-atomic 접근은 자동으로 race detection에 대해서 혀용한다. 런타임은 현재 race detector를 가지고 있지 않다. 하지만 미래에는 필요할 수 있다. atomic 접근은 race detector를 무력화하는 반면, non-atomic 접근은 race detector가 추론할 수 있도록 한다. Non-atomic 접근은 성능을 향상시킬 수 있다. 물론, 공유된 변수에 대한 어떠한 non-atomic 접근은 어떻게 보호되고 있는지 설명이 문서화되어야만 한다.\n일반적으로 atomic과 non-atomic 접근이 섞여서 구현되는 패턴은 다음과 같다:\nlock으로 보호되는 업데이트인 경우의 변수를 읽는 경우. locked region에서, 읽기는 atomic할 필요가 없다. 하지만 쓰기는 atomic해야한다. locked region 밖에서는 읽기는 atomic해야한다. 읽기가 STW(Stop the world)가 일어나는 동안에만 일어나는 경우, STW 동안에는 쓰기가 일어나지 않는다. 이때는 stomic하지 않아도 된다. 즉, Go memory 모델 관점으로의 조언은 \u0026ldquo;Don\u0026rsquo;t be [too] clever.\u0026rdquo; 이다. 런타임에서 성능도 중요하지만 견고성이 더 중요하다.\nUnmanaged memory 일반적으로 런타임은 regular heap allocation을 사용한다. 하지만 경우에 따라 런타임은 관리되지 않는 메모리에서 GC된 힙 외부의 객체를 할당해야한다. 객체가 memory manager 자체의 일부이거나 caller가 P가 없을 수도 있는 상황에서 할당되어야만 하는 경우에 필요하다.\nUnmanaged memory가 할당되기 위해선 세 가지 메커니즘이 있다.\nsysAlloc은 OS에서 직접 메모리를 획득한다. 이것은 system의 page size의 배수로 제공되고 sysFree와 함께 해제될 수 있다. persistentalloc은 여러개의 작은 할당을 단일 sysAlloc으로 결합하여 fragmentation을 방지한다. 하지만 persistentalloced objects에 대해서 해제할 수 있는 방법은 없다. (이름이 persistentalloced object인 까닭임) fixalloc은 SLAB-style allocator인데, 고정된 크기로 객체를 할당한다. fixallocaed object는 해제될 수 있지만, 이 메모리는 같은 fixalloc pool에 의해 재사용될 수 있다. 그래서 같은 type의 객체에 대해서만 재사용될 수 있다. 일반적으로, 이들 중 하나를 사용하여 할당된 type은 아래와 같이 //go:notinheap 으로 표시된다.\nUnmanaged memory에 할당된 객체는 다음 규칙을 지키지 않는 한 heap pointer를 포함하지 않아야만 한다.\n힙으로의 Unmanaged memory로 부터 존재하는 pointer는 GC root이어야만 한다. 좀 더 구체적으로, 모든 포인터는 global variable을 통해 접근이 가능하거나 runtime.markroot 에서 명시적인 GC root로 추가되어야 한다. 메모리가 재사용된다면, heap pointer는 GC root로 부터 표시되기 전에 zero-initialize되어야만 한다. 그렇지 않으면, GC는 stable heap pointer를 관찰할 수 있다. \u0026ldquo;Zero-initialization versus zeroing\u0026quot;을 참고하길 바란다. Zero-initialization versus zeroing type-safe state에서 이미 초기화 되었는지에 따라 런타임에서 zeroing하는 두가지 방법이 있다.\n메모리가 type-safe state에 있지 않다면, 그건 \u0026ldquo;garbage\u0026quot;를 포함하고 있다는 것을 잠재적으로 의미하고 있다. 할당되고 첫사용을 위해 초기화중이기 때문에, 그리고 memclrNoHeapPointers 나 non-pointer 쓰기를 사용해서 zero-initialized 되어야만 한다. 이것은 write barrier를 수행하지 않는다.\n이미 type-safe state에 있고 단순히 zero value로 세팅되어 있다면, 이는 regular writes, typedmemclr , 또는 memclrHasPointers 를 사용해서 수행되어야 한다. 이는 write barrier를 수행한다.\nRuntime-only compiler directives \u0026ldquo;go doc compile\u0026quot;에 문서화된 \u0026ldquo;// go:\u0026rdquo; directive 외에, 컴파일러는 런타임에서만 추가적인 directives를 지원한다.\ngo:systemstack go:systemstack 은 함수가 system stack에서 실행되어야 함을 나타낸다. 이것은 special function prologue를 통해 동적으로 확인된다.\ngo:nowritebarrier go:nowritebarrier 는 해당 함수가 어떠한 write barrier를 포함하고 있는지에 따라 컴파일러가 error를 내도록 한다.(이것은 write barrier의 생성을 억제하지 않음. 단순히 assertion임)\n일반적으로, go:nowritebarrierrec 를 원한다. go:nowritebarrier 는 우선적으로 write barrier가 없는 것이 좋을 때 유용하지만, 바로잡는 것에는 사용되지 않는다.\ngo:nowritebarrierrec and go:yeswritebarrierrec go:nowritebarrierrec 는 go:yeswritebarrierrec 까지 해당 함수 또는 반복적으로 호출하는 함수가 write barrier가 포함된 경우 컴파일러가 오류가 내도록 한다.\n논리적으로, 컴파일러는 각 go:nowritebarrierrec 함수에서 시작되는 호출 그래프를 플러딩하고, write barrier를 포함하는 함르를 만났을 때 error를 생성한다. 이 플러딩은 go:yeswritebarrierrec 함수에서 멈추게 된다.\ngo:nowritebarrierrec 는 무한 루프를 방지하기 위한 write barrier를 구현하는 데 사용된다.\n이 두 directive는 스케쥴러에서 사용된다. write barrier는 활성 P(getg().m.p != nil)가 요구되며, 스케쥴러는 활성 P가 없이 종종 실행되기도 한다. 이런 경우에, go:nowritebarrierrec 는 P를 릴리즈하거나 P가 없이 실행되거나 하는 함수에 사용되고, go:yeswritebarrierrec 는 활성 P를 다시 획득할 때 사용된다. 이것들은 funtion-level annotation이기 때문에, P를 해제하거나 획득하는 코드를 두 함수로 분할해야할 수 있다.\ngo:notinheap go:notinheap 은 type 선언에 적용된다. GC된 heap이나 stack으로 부터 할당되지 않아야함을 가리킨다. 특히, 이 type의 pointer는 runtime.inheap 체크에서 실패한다. 이 type은 global variable로 사용될 수도 있고, unmanaged memory에 있는 객체에 사용될 수 있다. (e.g., sysAlloc , persistentalloc , fixalloc 또는 manually-managed span)\n특히:\nnew(T), make([]T), append([]T, \u0026hellip;) 와 T의 implicit heaap 할당은 허용하지 않는다. (implicit 할당은 런타임 때 허용되지 않음) unsafe.Pointer 이외의 regular type 의 pointer는 기본 타입이 동일하더라도 go:notinheap type의 pointer로 변환될 수 없다. go:notinheap 을 포함하고 있는 type은 그 자체로 go:notinheap 이다. struct와 array는 element가 있는 경우 go:notinheap 이다. map과 channel은 go:notinheap 이 허용되지 않는다. 이를 명시적으로 하기 위해, go:notinheap 을 함축하는 모든 type의 선언이 go:notinheap 으로 표시되어야한다. go:notinheap type의 pointer에서 write barrier는 생략될 수 있다. 마지막으로 go:notinheap 의 진정한 이점을 말하자면, 런타임은 low-level internal structure에서 memory barrier를 피하기 위해, 단순히 원치않거나 비효율적인 memory allocator를 피하기 위해 go:notinheap 을 사용한다. 이 메커니즘은 안정적이고, 런타임의 가독성을 손상시키지 않는다.\n작성일: 2021-04-05\n후기 Golang을 메인 언어로 사용한지 어느정도 시간이 흘렀다. 프로덕션에서 운영하며 다양한 use case를 만났는데, runtime panic을 만나는 경우도 있었고, 프로젝트의 소스코드 레벨에서 해석하기 어려운 상황도 발생했었다.\n사내에서 Gopher들의 모임을 진행하며 고언어를 이해하는 방식이 달라졌는데, 이게 문제를 해결하는데 큰 도움을 줬다. 고언어의 구현체는 go code로 구현되어 있으며, 각 구현체의 디테일은 주석에 정리되어 있고 코드를 따라가면 동작원리를 이해할 수 있다는 점이었다.\n언어를 공부할 때 언어를 구현한 코드를 보며 공부한다는 생각은 안했던 것 같은데, 고언어는 구현체를 직접 보고 이해하면서 습득하는 게 더 좋은 경험으로 동작했다. 이번에는 정리하지 않았지만 GC life cycle에서 어떤 동작을 하는지 찾아보다가, HACKING.md 파일에 이끌려 번역까지 하게 되었다.\n다양한 공부방법이 존재하지만, 고언어를 이해한다고 한다면 가장 확실한 공부방법은 소스코드를 보고 구현체를 이해하는 것이라 생각한다. HACKING.md를 읽고 고언어 구현에 대해서 가볍게 시작하고 필요에 따라 각 요소에 따라서 코드를 직접보고 이해하는 것을 추천한다. 가장 단순한 언어 중에 하나이기 때문에 다들 어렵지 않게 이해할 것이라 생각한다.\nReferences https://golang.org/src/runtime/HACKING.md https://github.com/golang/go ","permalink":"https://novemberde.github.io/post/2021/04/05/Golang-HACKING/","summary":"Golang은 Open source project 이며 모든 개발 내역이 Github에 코드로 구현되어 있다. 하나하나의 구현 내용을 이해하고 싶다면 각 패키지를 읽어보며 이해할 수 있다. 그렇지만 방대한 양이기 때문에 처음에 접하는 경우에는 어디서부터 읽어야할지, 그리고 기본적인 구조를 어떻게 잡아야하는지 어렵기만 하다.\n그렇다면 Golang의 기본적인 구조에 대해서 이해하고 싶다면 어떻게 시작해야할까? 다행히도 고언어 개발자들은 HANKING.md에 기본적인 내용을 정리해두었다. 고언어의 런타임이 어떤 구조로 이뤄져 있는지, 그리고 동시성 처리를 위한 방식이나 메모리 관리 측면에서는 어떻게 하고 있는지 등 다양한 내용이 정리되어 있다.","title":"고언어(Golang) HACKING.md 내용 정리"},{"content":"AWS re:Invent 2020 에서 새로 출시한 AWS Glue DataBrew라는 서비스를 살펴보고, 기존의 Data engineer의 역할을 DataBrew로 어떻게 대체할 수 있는지 설명한다. 마지막으로 DataBrew를 통해 코드 한 줄 없이 ETL을 하는 과정을 데모로 확인한다.\nSlide Share 데이터 분석가를 위한 AWS 신규 서비스 소개 - 변규현 SW 엔지니어, 당근마켓 from Amazon Web Services Korea Youtube Reference AWS re:Invent recap 2020 행사 링크 https://pages.awscloud.com/aws-reinvent-recap-kr-reg.html ","permalink":"https://novemberde.github.io/post/2021/01/15/AWS-Glue-DataBrew/","summary":"AWS re:Invent 2020 에서 새로 출시한 AWS Glue DataBrew라는 서비스를 살펴보고, 기존의 Data engineer의 역할을 DataBrew로 어떻게 대체할 수 있는지 설명한다. 마지막으로 DataBrew를 통해 코드 한 줄 없이 ETL을 하는 과정을 데모로 확인한다.\nSlide Share 데이터 분석가를 위한 AWS 신규 서비스 소개 - 변규현 SW 엔지니어, 당근마켓 from Amazon Web Services Korea Youtube Reference AWS re:Invent recap 2020 행사 링크 https://pages.awscloud.com/aws-reinvent-recap-kr-reg.html ","title":"AWS re:Invent Recap For Data analyst"},{"content":"당근마켓에 들어와서 고언어를 어떻게 도입하고, 어떻게 활용했는지에 대해서 정리해보았다. 서비스가 성장함에 따라서 요구하는 조건은 달라지고 이에 최적화된 언어를 도입하고, 기존 서비스에서 필요한 곳만 하나씩 고언어를 통해 플랫폼화하는 방법을 정리했다.\nSlide Share 당근마켓 고언어 도입기, 그리고 활용법 from Kyuhyun Byun Youtube Reference 어쩌다 밋업 링크 https://www.facebook.com/1512494142177634/posts/3692166177543742/ ","permalink":"https://novemberde.github.io/post/2020/11/24/Golang-use-case-in-karrot/","summary":"당근마켓에 들어와서 고언어를 어떻게 도입하고, 어떻게 활용했는지에 대해서 정리해보았다. 서비스가 성장함에 따라서 요구하는 조건은 달라지고 이에 최적화된 언어를 도입하고, 기존 서비스에서 필요한 곳만 하나씩 고언어를 통해 플랫폼화하는 방법을 정리했다.\nSlide Share 당근마켓 고언어 도입기, 그리고 활용법 from Kyuhyun Byun Youtube Reference 어쩌다 밋업 링크 https://www.facebook.com/1512494142177634/posts/3692166177543742/ ","title":"당근마켓의 고언어 도입기, 그리고 활용법"},{"content":"RDS PostgreSQL에서 Aurora PostgreSQL을 도입한 후기\nPresentation RDS에서 Aurora PostgreSQL Migration한 후기 from Kyuhyun Byun Youtube Reference AWS Community Day 2020 소개 링크 https://pages.awscloud.com/aws-community-day-online-2020.html ","permalink":"https://novemberde.github.io/post/2020/10/17/RDS-to-aurora/","summary":"RDS PostgreSQL에서 Aurora PostgreSQL을 도입한 후기\nPresentation RDS에서 Aurora PostgreSQL Migration한 후기 from Kyuhyun Byun Youtube Reference AWS Community Day 2020 소개 링크 https://pages.awscloud.com/aws-community-day-online-2020.html ","title":"RDS PostgreSQL에서 Aurora PostgreSQL Migration 하기"},{"content":"The journey to adopt the serverless architecture from beginning to advanced.\nPresentation Handle massive traffic with serverless from Kyuhyun Byun ","permalink":"https://novemberde.github.io/post/2020/07/10/Handle-massive-traffic-with-serverless/","summary":"The journey to adopt the serverless architecture from beginning to advanced.\nPresentation Handle massive traffic with serverless from Kyuhyun Byun ","title":"Handle massive traffic with serverless"},{"content":"AWS에서 서버리스로 구현하는 앱은 보통 Javascript 또는 Python으로 작성된다. 그렇지만 AWS Lambda에서는 거의 모든 언어를 지원하고 있다. 더욱이 인프라 및 서버사이드에서 이뤄지는 프로젝트는 대부분 고언어로 작성되고 있다. 생산성 뿐만 아니라 배포시에도 이점을 가져가고 있기 때문이다. Serverless의 장단점에 대해서 이야기하고, Go 언어를 통해 서버리스 Todo 앱을 작성하고 배포하는 예제를 Golang Korea Meetup에서 발표하였다. 다음은 발표 때 사용했던 슬라이드 및 참고한 자료들이다.\nPresentation Start Serverless with Golang! from Kyuhyun Byun References https://github.com/awslabs/aws-lambda-go-api-proxy https://echo.labstack.com/guide https://serverless.com/ https://github.com/novemberde/go-serverless-demo https://novemberde.github.io/ppts/svelte/ https://github.com/spf13/cobra ","permalink":"https://novemberde.github.io/post/2019/12/22/Go-serverless/","summary":"AWS에서 서버리스로 구현하는 앱은 보통 Javascript 또는 Python으로 작성된다. 그렇지만 AWS Lambda에서는 거의 모든 언어를 지원하고 있다. 더욱이 인프라 및 서버사이드에서 이뤄지는 프로젝트는 대부분 고언어로 작성되고 있다. 생산성 뿐만 아니라 배포시에도 이점을 가져가고 있기 때문이다. Serverless의 장단점에 대해서 이야기하고, Go 언어를 통해 서버리스 Todo 앱을 작성하고 배포하는 예제를 Golang Korea Meetup에서 발표하였다. 다음은 발표 때 사용했던 슬라이드 및 참고한 자료들이다.\nPresentation Start Serverless with Golang! from Kyuhyun Byun References https://github.com/awslabs/aws-lambda-go-api-proxy https://echo.","title":"Go언어로 서버리스 서비스 시작하기"},{"content":"W3C Conference Korea 2019 View presentation on new tab References https://www.44bits.io/ko/post/direnv_for_managing_directory_environment ","permalink":"https://novemberde.github.io/post/2019/10/11/Svelte-revealjs/","summary":"W3C Conference Korea 2019 View presentation on new tab References https://www.44bits.io/ko/post/direnv_for_managing_directory_environment ","title":"Let's start SVELTE, goodbye React \u0026 Vue"},{"content":"현재 Amazon EKS위에 컨테이너를 배포하기 위한 환경을 구축중이다. 각 운영되는 서비스 또는 Repository마다 환경들이 다르고, 개인으로 운영하는 서비스도 가끔 확인해야하는데 Global로 AWS 또는 K8s 환경 설정을 하면 귀찮아지기 때문에 폴더별로 모든 환경을 관리하고 싶어졌다.\nDirenv를 활용하면 directory마다 환경을 따로 관리할 수 있는데, 매번 같은 키를 넣고 관리하기도 귀찮아서 Direnv에서 사용하는 변수들도 따로 관리하고 있다. 다음은 현재 사용하는 패턴이다.\nDirenv 설치하기 다음은 참고한 문서이다.\ndirenv로 디렉토리(프로젝트) 별 개발환경 구축하기\nAWS 설정 옮겨가며 편하게 사용하기 AWS CLI를 계정별로 관리하고 싶을 때 profile 옵션을 사용한다. 하지만 이는 매번 profile을 입력해야하는 번거로움이 있다. 위에 링크를 잘 살펴보면 \u0026ldquo;전역 설정 파일 .direnvrc\u0026quot;를 찾을 수 있다. 이걸 잘 활용하면 간편하게 디렉터리별 환경 설정을 한 곳에서 관리할 수 있다.\n아래는 내가 사용하는 기본적인 .direnvrc 파일이다.\nuse_ruby() { local ruby_root=$HOME/.rubies/$1 load_prefix \u0026#34;$ruby_root\u0026#34; layout_ruby } company_aws() { export AWS_ACCESS_KEY_ID=~~~ export AWS_SECRET_ACCESS_KEY=~~~ } my_private_aws() { export AWS_ACCESS_KEY_ID=~~~ export AWS_SECRET_ACCESS_KEY=~~~~ echo \u0026#34;load my_private_aws\u0026#34; } 이렇게 설정해 놓으면 다음부턴 해당 프로젝트 디렉토리에 .envrc 파일에서 다음과 같이 입력하면 해당 환경변수를 불러온다.\nmy_private_aws 위와같이 저장하고 다시 direnv allow를 해준다.\n$ direnv allow direnv: loading .envrc load my_private_aws direnv: export +AWS_ACCESS_KEY_ID +AWS_SECRET_ACCESS_KEY 간단하게 프로젝트 디렉터리 마다 설정을 불러올 수 있다.\nKubeconfig 따로 관리하기 Kubeconfig는 성격이 달라서 필요한 경우에만 주입해주는게 낫다. .direnvrc 포함시키는 건 전체적으로 설정되기 때문에 실수할 가능성이 많이 생긴다. 귀찮더라도 스테이징마다 kubeconfig를 설정하는데 관리하는 방식은 다음과 같다.\n$ tree -L 2 ~/.kube ├── cache │ └── discovery ├── my_private_cluster.yaml └── company_alpha_cluster.yaml 개발이 진행중인 프로젝트 디렉토리에서 다음과 같이 설정한다.\nexport KUBECONFIG=~/.kube/my_private_cluster.yaml 스테이징마다 별도로 디렉터리 구조를 잡고 있다면 클러스터에 잘못 배포되는 실수를 방지할 수 있다.\nReferences https://www.44bits.io/ko/post/direnv_for_managing_directory_environment ","permalink":"https://novemberde.github.io/post/2019/10/04/Direnv/","summary":"현재 Amazon EKS위에 컨테이너를 배포하기 위한 환경을 구축중이다. 각 운영되는 서비스 또는 Repository마다 환경들이 다르고, 개인으로 운영하는 서비스도 가끔 확인해야하는데 Global로 AWS 또는 K8s 환경 설정을 하면 귀찮아지기 때문에 폴더별로 모든 환경을 관리하고 싶어졌다.\nDirenv를 활용하면 directory마다 환경을 따로 관리할 수 있는데, 매번 같은 키를 넣고 관리하기도 귀찮아서 Direnv에서 사용하는 변수들도 따로 관리하고 있다. 다음은 현재 사용하는 패턴이다.\nDirenv 설치하기 다음은 참고한 문서이다.\ndirenv로 디렉토리(프로젝트) 별 개발환경 구축하기\nAWS 설정 옮겨가며 편하게 사용하기 AWS CLI를 계정별로 관리하고 싶을 때 profile 옵션을 사용한다.","title":"Direnv를 활용한 프로젝트 별 환경설정하기"},{"content":"신규프로젝트를 진행할 경우 디비 스키마를 설계를 해야한다. 데이터의 타입부터 외래키 설정등 신경써야하는 부분들이 생각보다 자잘하게 있다. 이 경우에 주의해야하는 점들을 정리해보았다. 이 문서는 지속적으로 수정될 예정이다.\nDatatype MySQL에서 사용하는 데이터 타입은 다음과 같다.\nNumeric Type BIT[(M)] - A bit-value type. M indicates the number of bits per value, from 1 to 64. The default is 1 if M is omitted. TINYINT[(M)] [UNSIGNED] [ZEROFILL] - A very small integer. The signed range is -128 to 127. The unsigned range is 0 to 255. BOOL, BOOLEAN - These types are synonyms for TINYINT(1). A value of zero is considered false. Nonzero values are considered true. However, the values TRUE and FALSE are merely aliases for 1 and 0, respectively, as shown here. SMALLINT[(M)] [UNSIGNED] [ZEROFILL] - A small integer. The signed range is -32768 to 32767. The unsigned range is 0 to 65535. MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL] - A medium-sized integer. The signed range is -8388608 to 8388607. The unsigned range is 0 to 16777215. INT[(M)] [UNSIGNED] [ZEROFILL] - A normal-size integer. The signed range is -2147483648 to 2147483647. The unsigned range is 0 to 4294967295. INTEGER[(M)] [UNSIGNED] [ZEROFILL] - This type is a synonym for INT. BIGINT[(M)] [UNSIGNED] [ZEROFILL] - A large integer. The signed range is -9223372036854775808 to 9223372036854775807. The unsigned range is 0 to 18446744073709551615. SERIAL is an alias for BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE. Some things you should be aware of with respect to BIGINT columns:\nAll arithmetic is done using signed BIGINT or DOUBLE values, so you should not use unsigned big integers larger than 9223372036854775807 (63 bits) except with bit functions! If you do that, some of the last digits in the result may be wrong because of rounding errors when converting a BIGINT value to a DOUBLE. MySQL can handle BIGINT in the following cases:\nWhen using integers to store large unsigned values in a BIGINT column.\nIn MIN(col_name) or MAX(col_name), where col_name refers to a BIGINT column.\nWhen using operators (+, -, *, and so on) where both operands are integers.\nYou can always store an exact integer value in a BIGINT column by storing it using a string. In this case, MySQL performs a string-to-number conversion that involves no intermediate double-precision representation.\nThe -, +, and * operators use BIGINT arithmetic when both operands are integer values. This means that if you multiply two big integers (or results from functions that return integers), you may get unexpected results when the result is larger than \u0026gt;9223372036854775807.\nDECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL] A packed “exact” fixed-point number. M is the total number of digits (the precision) and D is the number of digits after the decimal point (the scale). The decimal point and (for negative numbers) the - sign are not counted in M. If D is 0, values have no decimal point or fractional part. The maximum number of digits (M) for DECIMAL is 65. The maximum number of supported decimals (D) is 30. If D is omitted, the default is 0. If M is omitted, the default is 10.\nUNSIGNED, if specified, disallows negative values.\nAll basic calculations (+, -, *, /) with DECIMAL columns are done with a precision of 65 digits.\nDEC[(M[,D])] [UNSIGNED] [ZEROFILL], NUMERIC[(M[,D])] [UNSIGNED] [ZEROFILL], FIXED[(M[,D])] [UNSIGNED] [ZEROFILL] - These types are synonyms for DECIMAL. The FIXED synonym is available for compatibility with other database systems.\nFLOAT[(M,D)] [UNSIGNED] [ZEROFILL] - A small (single-precision) floating-point number. Permissible values are -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38. These are the theoretical limits, based on the IEEE standard. The actual range might be slightly smaller depending on your hardware or operating system.\nFLOAT(p) [UNSIGNED] [ZEROFILL] - A floating-point number. p represents the precision in bits, but MySQL uses this value only to determine whether to use FLOAT or DOUBLE for the resulting data type. If p is from 0 to 24, the data type becomes FLOAT with no M or D values. If p is from 25 to 53, the data type becomes DOUBLE with no M or D values. The range of the resulting column is the same as for the single-precision FLOAT or double-precision DOUBLE data types described earlier in this section.\nDOUBLE[(M,D)] [UNSIGNED] [ZEROFILL] - A normal-size (double-precision) floating-point number. Permissible values are -1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308. These are the theoretical limits, based on the IEEE standard. The actual range might be slightly smaller depending on your hardware or operating system.\nDOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL], REAL[(M,D)] [UNSIGNED] [ZEROFILL] - These types are synonyms for DOUBLE. Exception: If the REAL_AS_FLOAT SQL mode is enabled, REAL is a synonym for FLOAT rather than DOUBLE.\nDate and Time Type DATE - A date. The supported range is \u0026lsquo;1000-01-01\u0026rsquo; to \u0026lsquo;9999-12-31\u0026rsquo;. MySQL displays DATE values in \u0026lsquo;YYYY-MM-DD\u0026rsquo; format, but permits assignment of values to DATE columns using either strings or numbers.\nDATETIME[(fsp)]\nA date and time combination. The supported range is \u0026lsquo;1000-01-01 00:00:00.000000\u0026rsquo; to \u0026lsquo;9999-12-31 23:59:59.999999\u0026rsquo;. MySQL displays DATETIME values in \u0026lsquo;YYYY-MM-DD HH:MM:SS[.fraction]\u0026rsquo; format, but permits assignment of values to DATETIME columns using either strings or numbers. An optional fsp value in the range from 0 to 6 may be given to specify fractional seconds precision. A value of 0 signifies that there is no fractional part. If omitted, the default precision is 0. Automatic initialization and updating to the current date and time for DATETIME columns can be specified using DEFAULT and ON UPDATE column definition clauses, as described in Section 11.3.4, “Automatic Initialization and Updating for TIMESTAMP and DATETIME”. TIMESTAMP[(fsp)]\nA timestamp. The range is \u0026lsquo;1970-01-01 00:00:01.000000\u0026rsquo; UTC to \u0026lsquo;2038-01-19 03:14:07.999999\u0026rsquo; UTC. TIMESTAMP values are stored as the number of seconds since the epoch (\u0026lsquo;1970-01-01 00:00:00\u0026rsquo; UTC). A TIMESTAMP cannot represent the value \u0026lsquo;1970-01-01 00:00:00\u0026rsquo; because that is equivalent to 0 seconds from the epoch and the value 0 is reserved for representing \u0026lsquo;0000-00-00 00:00:00\u0026rsquo;, the “zero” TIMESTAMP value. An optional fsp value in the range from 0 to 6 may be given to specify fractional seconds precision. A value of 0 signifies that there is no fractional part. If omitted, the default precision is 0. The way the server handles TIMESTAMP definitions depends on the value of the explicit_defaults_for_timestamp system variable (see Section 5.1.8, “Server System Variables”). If explicit_defaults_for_timestamp is enabled, there is no automatic assignment of the DEFAULT CURRENT_TIMESTAMP or ON UPDATE CURRENT_TIMESTAMP attributes to any TIMESTAMP column. They must be included explicitly in the column definition. Also, any TIMESTAMP not explicitly declared as NOT NULL permits NULL values. If explicit_defaults_for_timestamp is disabled, the server handles TIMESTAMP as follows: Unless specified otherwise, the first TIMESTAMP column in a table is defined to be automatically set to the date and time of the most recent modification if not explicitly assigned a value. This makes TIMESTAMP useful for recording the timestamp of an INSERT or UPDATE operation. You can also set any TIMESTAMP column to the current date and time by assigning it a NULL value, unless it has been defined with the NULL attribute to permit NULL values. Automatic initialization and updating to the current date and time can be specified using DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP column definition clauses. By default, the first TIMESTAMP column has these properties, as previously noted. However, any TIMESTAMP column in a table can be defined to have these properties. TIME[(fsp)]\nA time. The range is \u0026lsquo;-838:59:59.000000\u0026rsquo; to \u0026lsquo;838:59:59.000000\u0026rsquo;. MySQL displays TIME values in \u0026lsquo;HH:MM:SS[.fraction]\u0026rsquo; format, but permits assignment of values to TIME columns using either strings or numbers. An optional fsp value in the range from 0 to 6 may be given to specify fractional seconds precision. A value of 0 signifies that there is no fractional part. If omitted, the default precision is 0. YEAR[(4)] - A year in four-digit format. MySQL displays YEAR values in YYYY format, but permits assignment of values to YEAR columns using either strings or numbers. Values display as 1901 to 2155, and 0000.\nThe SUM() and AVG() aggregate functions do not work with temporal values. (They convert the values to numbers, losing everything after the first nonnumeric character.) To work around this problem, convert to numeric units, perform the aggregate operation, and convert back to a temporal value.\nString Type CHARACTER SET specifies the character set. If desired, a collation for the character set can be specified with the COLLATE attribute, along with any other attributes.(latin1, utf-8\u0026hellip;etc). CHARSET is a synonym for CHARACTER SET. Specifying the CHARACTER SET binary attribute for a character string data type causes the column to be created as the corresponding binary string data type: CHAR becomes BINARY, VARCHAR becomes VARBINARY, and TEXT becomes BLOB. For the ENUM and SET data types, this does not occur; they are created as declared. The BINARY attribute is shorthand for specifying the table default character set and the binary (_bin) collation of that character set. In this case, comparison and sorting are based on numeric character code values. The ASCII attribute is shorthand for CHARACTER SET latin1. The UNICODE attribute is shorthand for CHARACTER SET ucs2. [NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name] - A fixed-length string that is always right-padded with spaces to the specified length when stored. M represents the column length in characters. The range of M is 0 to 255. If M is omitted, the length is 1. [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name] - A variable-length string. M represents the maximum column length in characters. The range of M is 0 to 65,535. The effective maximum length of a VARCHAR is subject to the maximum row size (65,535 bytes, which is shared among all columns) and the character set used. For example, utf8 characters can require up to three bytes per character, so a VARCHAR column that uses the utf8 character set can be declared to be a maximum of 21,844 characters. BINARY[(M)] - The BINARY type is similar to the CHAR type, but stores binary byte strings rather than nonbinary character strings. An optional length M represents the column length in bytes. If omitted, M defaults to 1. VARBINARY(M) - The VARBINARY type is similar to the VARCHAR type, but stores binary byte strings rather than nonbinary character strings. M represents the maximum column length in bytes. TINYBLOB - A BLOB column with a maximum length of 255 (28 − 1) bytes. Each TINYBLOB value is stored using a 1-byte length prefix that indicates the number of bytes in the value. TINYTEXT [CHARACTER SET charset_name] [COLLATE collation_name] - A TEXT column with a maximum length of 255 (28 − 1) characters. The effective maximum length is less if the value contains multibyte characters. Each TINYTEXT value is stored using a 1-byte length prefix that indicates the number of bytes in the value. BLOB[(M)] - A BLOB column with a maximum length of 65,535 (216 − 1) bytes. Each BLOB value is stored using a 2-byte length prefix that indicates the number of bytes in the value. An optional length M can be given for this type. If this is done, MySQL creates the column as the smallest BLOB type large enough to hold values M bytes long. TEXT[(M)] [CHARACTER SET charset_name] [COLLATE collation_name] - A TEXT column with a maximum length of 65,535 (216 − 1) characters. The effective maximum length is less if the value contains multibyte characters. Each TEXT value is stored using a 2-byte length prefix that indicates the number of bytes in the value. An optional length M can be given for this type. If this is done, MySQL creates the column as the smallest TEXT type large enough to hold values M characters long. MEDIUMBLOB - A BLOB column with a maximum length of 16,777,215 (224 − 1) bytes. Each MEDIUMBLOB value is stored using a 3-byte length prefix that indicates the number of bytes in the value. MEDIUMTEXT [CHARACTER SET charset_name] [COLLATE collation_name] - A TEXT column with a maximum length of 16,777,215 (224 − 1) characters. The effective maximum length is less if the value contains multibyte characters. Each MEDIUMTEXT value is stored using a 3-byte length prefix that indicates the number of bytes in the value. LONGBLOB - A BLOB column with a maximum length of 4,294,967,295 or 4GB (232 − 1) bytes. The effective maximum length of LONGBLOB columns depends on the configured maximum packet size in the client/server protocol and available memory. Each LONGBLOB value is stored using a 4-byte length prefix that indicates the number of bytes in the value. LONGTEXT [CHARACTER SET charset_name] [COLLATE collation_name] - A TEXT column with a maximum length of 4,294,967,295 or 4GB (232 − 1) characters. The effective maximum length is less if the value contains multibyte characters. The effective maximum length of LONGTEXT columns also depends on the configured maximum packet size in the client/server protocol and available memory. Each LONGTEXT value is stored using a 4-byte length prefix that indicates the number of bytes in the value. ENUM(\u0026lsquo;value1\u0026rsquo;,\u0026lsquo;value2\u0026rsquo;,\u0026hellip;) [CHARACTER SET charset_name] [COLLATE collation_name] An enumeration. A string object that can have only one value, chosen from the list of values \u0026lsquo;value1\u0026rsquo;, \u0026lsquo;value2\u0026rsquo;, \u0026hellip;, NULL or the special \u0026rsquo;\u0026rsquo; error value. ENUM values are represented internally as integers. An ENUM column can have a maximum of 65,535 distinct elements. The maximum supported length of an individual ENUM element is M \u0026lt;= 255 and (M x w) \u0026lt;= 1020, where M is the element literal length and w is the number of bytes required for the maximum-length character in the character set. SET(\u0026lsquo;value1\u0026rsquo;,\u0026lsquo;value2\u0026rsquo;,\u0026hellip;) [CHARACTER SET charset_name] [COLLATE collation_name] A set. A string object that can have zero or more values, each of which must be chosen from the list of values \u0026lsquo;value1\u0026rsquo;, \u0026lsquo;value2\u0026rsquo;, \u0026hellip; SET values are represented internally as integers. A SET column can have a maximum of 64 distinct members. The maximum supported length of an individual SET element is M \u0026lt;= 255 and (M x w) \u0026lt;= 1020, where M is the element literal length and w is the number of bytes required for the maximum-length character in the character set. Which is faster: char(1) or tinyint(1) ? Why? I think you should create column with ENUM(\u0026rsquo;n\u0026rsquo;,\u0026lsquo;y\u0026rsquo;). Mysql stores this type in optimal way. It also will help you to store only allowed values in the field.\n고려할 점들 현재 운영하는 데이터베이스의 기본 Character Collation을 알아두어야한다. 생성할 테이블이 데이터베이스의 기본 Charset을 사용하는 것으로 옵션이 설정되어 있을 수 있기 때문이다. 예를들어, Amazon Aurora MySQL의 Default collation은 latin1으로 되어있다. 하지만 보통 MySQL Workbench에서는 utf-8을 default로 옵션이 설정되어있기 때문에 나중에 프로덕션에서 한글로 입력이 안되는 경우가 있다. ID값은 BIGINT를 추천한다. 나중에 서비스가 커져 INT를 BIGINT로 바꾸는 경우도 생각보다 만만치 않다. 고려할 점이 생긴다. 마음 편히 BIGINT로 ID를 지정하여 추후에 있을지도 모를 업무를 줄여야 한다. ENUM을 적극 활용한다. yes 또는 no를 \u0026lsquo;y\u0026rsquo;와 \u0026rsquo;n\u0026rsquo;으로 CHAR(1)로 선언하여 사용하는 경우가 있다. 이는 스키마의 콘텍스트를 이해하는데 명확하지 않을 뿐만 아니라 \u0026lsquo;a\u0026rsquo;, \u0026lsquo;1\u0026rsquo; 등과 같은 다른 문자도 허용한다. 반면에 ENUM(\u0026lsquo;yes\u0026rsquo;, \u0026rsquo;no\u0026rsquo;)로 표현하면 명확하게 의미를 포함할 뿐만 아니라 코멘트가 없이 쉽게 컬럼이 가진 속성에 대해서 빠르게 이해할 수 있다. 테이블 명을 지을때는 복수형을 사용하지 않늗다. 가끔 orm에서 저절로 복수형으로 테이블을 생성해주는 경우가 있는데, 마지막 글자가 y이거나 s일 경우에 -ies나 -ses로 표현되어 상당히 골치아픈 경우가 있다. 명확하게 단수형으로 한다. 이모지를 지원하는 컬럼은 utf8-mb4로 charset을 설정하도록 한다. deleted_at과 같은 컬럼은 인덱스를 걸어줄 필요가 없다. 오히려 인덱스를 컬어주게되면 퍼포먼스에 영향을 끼친다. 인덱스를 걸어주는 컬럼을 선택하는 경우는 조회시 전체 데이터의 1%내로 WHERE절에서 조건을 걸어줄 때이다. 어지간한 데이터는 히스토리를 남기도록한다. UPDATE문 사용은 지양한다. 대신 INSERT를 하고 나중의 값을 불러올 때는 최신의 데이터만 가져온다. 테이블간의 외래키를 직접적으로 넣는 것에 대해서 고민을 해야한다. 1:N관계가 나은지 아니면 사이에 테이블을 하나 더 두어 N:M 관계의 테이블을 둘지 잘 생각한다. 1:N 관계의 테이블은 강한 결합이 되어 나중에 서비스 확장에 많은 난관에 봉착하게 된다. N:M 관계의 테이블을 하나 더 두게 된다면 후임자가 쉽게 이해못하는 경우도 있다. 쉬운 설계로 할 것인가 잘만들 것인가는 다른 문제이다. 한국식 영어를 쓰지 않도록 한다. 찾아보면 좋은 컬럼명들이 있다. 글로벌 서비스가 목표라면 대충짓지 않도록한다. Push service를 위한 토큰 저장테이블은 ad_id값과 함께 따로 두도록 한다. 여러 디바이스를 사용하는 사용자일 경우에 모든 디바이스에 알림을 던질 수 있다. 가끔 유저테이블에 두는 FCM 토큰값을 두는 경우가 있는데 이 때문에 추후에 코드를 수정하는게 굉장히 귀찮다. References https://dev.mysql.com/doc/refman/8.0/en/data-types.html https://stackoverflow.com/questions/2023476/which-is-faster-char1-or-tinyint1-why 이 문서는 지속적으로 업데이트 될 예정입니다.\n","permalink":"https://novemberde.github.io/post/2019/06/10/MySQL-Desgin-cheatsheet/","summary":"신규프로젝트를 진행할 경우 디비 스키마를 설계를 해야한다. 데이터의 타입부터 외래키 설정등 신경써야하는 부분들이 생각보다 자잘하게 있다. 이 경우에 주의해야하는 점들을 정리해보았다. 이 문서는 지속적으로 수정될 예정이다.\nDatatype MySQL에서 사용하는 데이터 타입은 다음과 같다.\nNumeric Type BIT[(M)] - A bit-value type. M indicates the number of bits per value, from 1 to 64. The default is 1 if M is omitted. TINYINT[(M)] [UNSIGNED] [ZEROFILL] - A very small integer. The signed range is -128 to 127.","title":"MySQL에서 DB스키마 작성시 주의할 점들"},{"content":"Summary CircleCI Korea User Group 첫번째 밋업에서 서버리스 앱을 배포하기 위해 CircleCI 상에서 어떻게 빌드하는지 알아보았다. 또한, CircleCI의 기본적인 기능 및 특징에 대해서 살펴본다.\n발표자료 발표 슬라이드 CircleCI로 Serverless API의 CI/CD 환경 구축하기 from Kyuhyun Byun ","permalink":"https://novemberde.github.io/post/2019/05/13/CircleCI-1st-Meetup/","summary":"Summary CircleCI Korea User Group 첫번째 밋업에서 서버리스 앱을 배포하기 위해 CircleCI 상에서 어떻게 빌드하는지 알아보았다. 또한, CircleCI의 기본적인 기능 및 특징에 대해서 살펴본다.\n발표자료 발표 슬라이드 CircleCI로 Serverless API의 CI/CD 환경 구축하기 from Kyuhyun Byun ","title":"Serverless Application CI/CD on CircleCI"},{"content":"Summary AWSKRUG 판교 밋업에서 서버리스 웹소켓에 대한 내용을 공유하였다.\n발표자료 DEMO 발표 슬라이드 Serverless websocket 톺아보기 from Kyuhyun Byun ","permalink":"https://novemberde.github.io/post/2019/04/10/Serverless-Websocket/","summary":"Summary AWSKRUG 판교 밋업에서 서버리스 웹소켓에 대한 내용을 공유하였다.\n발표자료 DEMO 발표 슬라이드 Serverless websocket 톺아보기 from Kyuhyun Byun ","title":"Serverless Websocket 톺아보기"},{"content":"AWSKRUG Serverless Group에서 발표한 자료입니다. C++로 빌드한 Native addon을 Serverless 환경에서 사용할 때 빌드 및 배포하는 방법을 다루었습니다.\n발표자료 Native addon을 포함하여 Node.js + Typescript + Serverless 빌드 및 배포하기 from Kyuhyun Byun References https://www.slideshare.net/KyuhyunByun1/native-addon-nodejs-typescript-serverless ","permalink":"https://novemberde.github.io/post/2019/02/14/Ts-Serverless-Build/","summary":"AWSKRUG Serverless Group에서 발표한 자료입니다. C++로 빌드한 Native addon을 Serverless 환경에서 사용할 때 빌드 및 배포하는 방법을 다루었습니다.\n발표자료 Native addon을 포함하여 Node.js + Typescript + Serverless 빌드 및 배포하기 from Kyuhyun Byun References https://www.slideshare.net/KyuhyunByun1/native-addon-nodejs-typescript-serverless ","title":"Native addon을 포함하여 Node.js + Typescript + Serverless 빌드 및 배포하기"},{"content":"\u0026ldquo;시계열 데이터 전용 DB 소개\u0026quot;라는 주제로 2019년 1월 25일에 AWSKRUG re:Invent recap 행사에서 발표한 자료입니다.\n발표자료 Amazon Timestream 시계열 데이터 전용 DB 소개 :: 변규현 - AWS Community Day 2019 from AWS Korea UserGroup (AWS한국사용자모임) References https://www.slideshare.net/awskr/amazon-timestream-db https://pages.awscloud.com/aws-community-day-seoul-2019.html ","permalink":"https://novemberde.github.io/post/2019/01/25/Timestream/","summary":"\u0026ldquo;시계열 데이터 전용 DB 소개\u0026quot;라는 주제로 2019년 1월 25일에 AWSKRUG re:Invent recap 행사에서 발표한 자료입니다.\n발표자료 Amazon Timestream 시계열 데이터 전용 DB 소개 :: 변규현 - AWS Community Day 2019 from AWS Korea UserGroup (AWS한국사용자모임) References https://www.slideshare.net/awskr/amazon-timestream-db https://pages.awscloud.com/aws-community-day-seoul-2019.html ","title":"Amazon Timestream 시계열 데이터 전용 DB 소개"},{"content":"2017부터 2018년에 대해서 회고를 남기려고 한다. 어느때보다 치열하고 열심히 달려온 한해였다. 다음은 한해동한 진행했던 일들의 대한 목록은 다음과 같다.\nAWSKRUG 회사 강의 활동 \u001d AWSKRUG 개발자 커리어에서 가장 크게 영향력을 준 모임이다. AWSKRUG는 Amazon Web Service Korea User Group의 약자로 AWS 한국 사용자 그룹이라고도 불린다. 이 모임에 처음으로 참여하게된 것은 2017년 4월 쯤이었다. 지난 2년여간 데이터 사이언스 그룹을 시작으로 거의 모든 모임에 참석하였다. AWSKRUG 통해 많은 것을 배울 수 있었다.\n시작하게 된 계기 이전의 회사에서도 많은 개발을 맡아서 진행했는데 대표적으로 DevOps, Front-end 그리고 Back-end였다. 그냥 풀스택 개발자였다. 솔직히 풀스택은 말도 안된다고 생각을 했었는데 깊이에 대해서 어느정도 포기하면 풀스택 개발자로 될 수가 있었다.\nAWS를 통해 서비스가 돌아가게 설정한다. Jenkins를 통해 자동으로 배포하는 스크립트를 짠다. React 튜토리얼을 기반으로 연습하고 이를 프로덕션에 적용한다. 백엔드는 Spring과 Node.js를 비교하여 개발 속도를 확인해보고 Node.js를 선택한다. 그리고 제품을 만든다. 이 모든과정을 2017년에 진행했었다. 튜토리얼에 의존하였다. 이런 상황에서 여태까지 사용했던 것들이 내부적으로 어떻게 동작하는지 이해가 부족하였다. AWS와 Docker에 대해서 어느정도 사용할 줄은 알았지만 DevOps의 대한 실전 테크닉이 부족하였다. 사내에서 성장을 하기 위해 문서와 블로그에 의존했다. 이 상황에서 같은 공부를 하는 누군가와 토론을 하고 싶었다. Use Case들을 공유하며 새로운 방법들을 찾고 싶었다. 그런 상태로 2017 AWS Summit에 참가하였고 새로운 세상이 열렸다.\n커뮤니티는 새로운 세상이었다. 이전에 \u0026ldquo;나는 프로그래머다\u0026quot;를 가끔 들었는데, 이때 Summit의 현장에서 정도현님을 처음 만났다. 도현님이 AWSKRUG라는 모임에 대해서 설명해주었다. 누구나 참여할 수 있다고 하였다. 이때부터 모임을 시작하였다. 커뮤니티는 회사와 달리 기술에 대한 공부가 주목적이기 때문에 시간을 내어 저녁에 참여하기만 하면 되었다. 그렇게 데이터 사이언스 모임을 시작했다. 새로운 지식에 목말라 있었기 때문에, 퇴근 후 모든 모임에 참석하였다. 처음 접해보는 지식들을 흡수하기 위해 노력했다.\n가장 빠르게 기술을 습득하는 방법을 실제로 서비스를 사용해보는 것이다. 업무에 적용할 수 있으면 바로 테스트해보았고, 만약 업무와 상관이 없다면 발표하겠다고 먼저 말했다. 그 다음 틈나는대로 공부하고 실제로 데모를 만들면서 모르는 것에 대해서 공부하는 재미를 들였다. 이 뿐만 아니라, 워크샵이 예정되어 있다면 도우미로 참여하여 워크샵 이전에 여러번 실습을 진행했다. 그리고 당일에 한번 더 데모 시에 발생하는 문제들을 해결하며 기술들에 대한 디테일에 대해서 공부하였다.\nAWS re:Invent 2017 이런 공부들을 발판 삼아, 2017년 AWS re:Invent 행사에 참가했다. 이때 처음으로 해외 행사에 참여해보았는데 개발을 바라보는 시선이 바뀐 계기였다. 또한 스스로 크게 성장할 수 있었다. 그 당시까지 AWS에서 나온 서비스들에 대해 그 자체만으로도 엄청난 기술이라고 생각하고 있었다. 그런데 re:Invent에서는 현재를 뛰어넘는 서비스 및 기능들이 발표되었다. 또한, netflix와 같이 대규모 트래픽을 받는 회사의 개발자가 직접 경험을 공유하고, 실제로 AWS의 서비스를 만드는 개발자들이 직접 Q\u0026amp;A를 해주는 모습을 보았다. 이들은 개발할 때 고려한 점들, 그리고 앞으로의 진행 방향에 대해서 정확한 내용을 이해하고 구체적으로 설명해주었다. 굉장히 인상적이었다.\n이뿐만아니라 같이 참석한 개발자 분들에게도 많이 배울 수 있었다. 매일 저녁마다 그날 들었던 세션에 대해서 공유하고, 현재 아키텍처의 문제점 및 나아갈 방향에 대해서 토론하였다. 눈을 떠있는 시간은 거의 모두 개발에 대해서 이야기를 나누었다. 작은 부분 하나하나 이해하기 위해 밤 늦게까지 토론했던 것은 잊지못할 추억이다.\n서버리스 모임 리인벤트를 계기로 서버리스에 대한 관심이 급증하였다. 이전까지만 해도 컨테이너가 세상을 바꿀 것이라 생각했지만 서버리스는 컨테이너 이상으로 업무를 줄여주는 내용이었다. 한국에 오자마자 모든 서비스를 AWS Lambda로 적용하였다. 그리고 사용자의 갑작스런 증가에 대비하여 대규모 아키텍처를 적용하였다.\n마침 2018년부터 AWSKRUG에서는 새로운 모임을 계획하고 있었다. 컨테이너 모임과 서버리스 모임이었다. 원래는 컨테이너 모임을 맡을지도 모르는 상태였다. 하지만 그 당시에 운영하는 모든 서비스가 이미 서버리스였기 서버리스 모임의 운영진이 되기로 결정하였다.\n서버리스 모임을 운영하는 방법은 간단했다. 발표자 한두 명, 모임 공간, 그리고 간단한 간식 준비였다. 모임을 하기전에 참가비는 5000원으로 받고 행사 준비만 하면 되었다. 귀찮지만 어렵지 않은 일이었다. 운영진이어서 좋은 점은 발표주제를 들어보고 미리 주제에 대해서 고민할 수 있는 점이었다.\n서버리스 모임에서는 주로 서버없이 Lambda, Glue 등의 서비스를 사용해서 운영의 리소스를 줄인 내용을 다뤘다. 각 발표자들마다 경험은 특별했고, 이에 대한 발표를 듣기위해 꾸준히 사람들이 참석했다. 한분 한분 소중한 경험을 공유해주었다.\n모든 발표 내용은 여기에 정리해두었다.\n2018년 9회의 핸즈온 AWSKRUG 모임에서 가장 많은 일을 맡아주시는 류한진님이 핸즈온을 계획했다. 처음에 얘기했을 때는 4회에서 6회 정도로 진행할 계획이었다. 하지만 점점 핸즈온을 진행하면서 괜찮은 주제와 진행자 분들이 생겨서 마지막까지 총 9회로 핸즈온을 마쳤다. 여름에 시작해서 초겨울까지 거의 매달 진행했다\u001c. 금, 토 일정을 모두 비워가며 진행했는데, 이 또한 성장하는데 많은 도움을 주었다. 컨테이너, 서버리스, 그리고 데이터 사이언스까지 거의 모든 장르를 아우렀다. 모두 좋은 내용이었다. 해당 내용은 여기를 참고 바란다.\n그중 내가 맡았던 핸즈온은 서버리스 핸즈온이었다. Todo앱과 크롤러 핸즈온을 준비했다. 이때 준비했던 자료는 현재 E-Book으로 출판 대기중이다.\nAWS re:Invent 2018 2017년에 이어 리인벤트에 참가했다. 이때 목표는 2017년과 달리 Workshop과 301/401 세션 위주로 들었다. 지난 1년간의 경험으로 어지간한 AWS 서비스를 써보았다. 하지만 각 서비스의 내용에 대해서 Deep Dive할 기회가 필요했다. 2017년과 반복된 세션은 이미 유튜브에 있기 때문에 새로운 관점에 대한 내용과 여태 다루지 않았던 내용을 위주로 세션을 들었다.\n가장 기억에 남는 것이라고 하면 GitOps였는데 상세 내용은 여기를 참고하길 바란다. 간단하게 Pull-request에 의한 운영방식이다.\n리인벤트 이전에 시애틀에 들려 Microsoft 캠퍼스와 AWS 캠퍼스를 견학했다. Microsoft에서 인상깊었던 점은 혼자서 코드를 작성하는 모습보다 여럿이서 모니터에 코드를 띄워놓고 토론하던 모습들이 많이 보였던 것이다. 그리고 Microsoft는 점심식사를 사먹어야했다. 사티아 나델리를 생각하며 카레를 먹고 싶었다. 하지만 인도음식은 없었기 때문에 몽골리안 음식을 먹고 무료로 먹을 수 있는 음료수를 열심히 마시며 다녔다.\nAWS 캠퍼스는 내부를 돌아보지는 않고 Spheres를 둘러보고 식당에서 식사를 했다. AWS에서 근무하시는 안재우님이 가이드해주셨다. Spheres는 식물원같은 느낌이었다. 돈이 많은 회사면 건물앞에 식물원도 그냥 지을 수 있다고 생각했다. 식당의 밥은 쉬는날이라 그런지 맛이없었다. 그런데 비쌌다. 한국이 이런면에서는 일하기 좋을지도 모른다.\n리인벤트 기간중에 재밌는 일이 있었다. CloudFront/API Gateway/Lambda를 아우르는 내용이었다. 리인벤트를 기준으로 한달 이전에는 신규서비스의 기반이되는 기능들이 추가되곤 한다. 이번에는 CloudFront의 웹소켓 지원이었다. 이걸보고 바로 API Gateway에 웹소켓이 붙을 수 있다는 생각이 들었고, 그렇다면 Lambda를 통해 웹소켓 어플리케이션을 운영할 수 있을 것이라 생각했다. 이에 대해 AWSKRUG Facebook에서 갑론을박이 있었지만 결과는 나와봐야 알 수 있었다. 리인벤트 마지막 날에 API Gateway 웹소켓 기능이 생긴 것을 확인할 수 있었고, Lambda에서 커넥션을 관리하는 데이터베이스를 통해 웹소켓을 구현한다고 문서도 공개됐다. 이것 때문에 리인벤트 첫날에 윤석찬님을 괴롭혔다. 일찍 라스베가스에 도착해서 둘이 얘기를 나누다가 Cloudfront만 웹소켓이 되면 람다도 분명히 웹소켓이 가능할거라 생각한다고 말했다. 그런데 해당 내용을 확인해보시겠다고 하면서 중간에 식사하러 가셨다. 이날 피곤했는지라 기다리다가 뻗었는데 이날 적잖이 당황했다고 말씀하셨다.\n*1월 7일 추가 내용\nAPI Gateway를 직접 만드시는 분에 의하면 Cloudfront의 웹소켓 지원과 API Gateway의 웹소켓 지원은 관련이 없다고 한다. 웹소켓을 Cloudfront는 전역적으로 지원하는 것과 달리, API Gateway는 Regional endpoint에서만 지원이 된다고 한다. \b위의 잘못된 내용으로 오해하는 분들이 없길 바란다.\n회사 개인적으로 회사일로 인해 크게 성장할 수 있었다. 현재 회사에서 주로 했던 일은 다음과 같다.\n서버리스 아키텍처의 적용 MongoDB 걷어내기 인증서버 걷어내고 Firebase 적용 RDS MySQL에서 Aurora MySQL로 Migration Typescript 도입 TIPS 준비 서버리스 아키텍처의 적용 서버리스 아키텍처를 적용하는 것은 솔직히 쉽지 않았다. 먼저 Lambda의 모든 옵션을 알아야만 했다. 그리고 Redis를 사용하기 위해 VPC에 대해서 더욱 자세히 알아야만 했다. 또한 VPC에서 외부 인터넷에 접근하기 위해 NAT를 두면서 네트워크 지식을 넓혀갈 수 있었다.\n또한 기존 서버에서 운영하는 방식과 서버리스에서 운영하는 것의 차이점을 명확히 이해해야했다. API 응답을 한 후에 백그라운드에서 동작하는 로직을 수정했다.\n콜드스타트를 줄이기 위한 방법들도 많이 생각했다.\n이 부분에 대한 내용은 서버리스 그룹에서 주로 다룬다.\n관련 발표내용은 여기을 참고 바란다.\nMongoDB 걷어내기 몽고디비는 관리형 서비스를 올리고 싶으면 Atlas를 사용하는게 최선이다. 아니면 직접 운영하는 방법밖에 없다. 직접 운영하기 위해 Sharded Cluster를 올려보았는데 생각보다 고된 작업이었다. Config, Router, Replica set 등 서버를 한두대로 운영할 수 없었다. 처음부터 비용이 많이 나왔다. 설정하는 것도 몽고디비의 버전마다 차이가 있었기 때문에 Config 파일 관리하는 것도 귀찮았다. 저장하는 데이터들을 확인하고 걷어내기로 결심했다.\n기존에 MongoDB를 Token 및 통계데이터 저장소로 사용했다. Token은 Firebase로 모두 이관했다. 또한, 통계 데이터는 RDB에 저장하고 몽고디비를 걷어내었다.\n인증서버 걷어내고 Firebase 적용 Firebase를 적용하고 처음엔 좋았다. 굳이 Access Token들을 관리하지 않아도 되니 편했다. 그런데 서비스가 갑자기 성장함에 따라 구글 인증 API의 Limit에 걸려 서비스가 마비되었다. 이때 두번다시 Firebase를 사용하지 않겠다고 다짐했다. 내부적으로 Firebase와 구글 관련 기능은 인증 API를 호출하는데 이것 때문에 하루 할당량 한계를 넘었다. 토큰을 클라이언트 캐싱하고, 서버에서도 별도의 캐싱을 통해 인증 API로의 호출을 최소화하였지만 급작스런 사용자 증가로 인해 \u0026ldquo;Limit Quotas\u0026quot;를 초과하여 결국엔 장애가 발생했다.\n여기서 더욱 문제였던 점은 구글의 지원을 받는데 많은 시간이 소요됐던 점이다. 두달전부터 예상하고 Limit increase를 몇번이나 요청했지만 묵묵부답. 그리고 Firebase에서 가장 많은 Support를 받는 Blaze요금제였음에도 불구하고 Support를 통해 답변은 한참뒤에 받을 수 있었다. 답변이 왔다고 할지라도 할당량은 증가해주지 않고 모든 모니터링 내역부터 증빙자료를 요청하는 핑퐁만 하루에 메일 한번씩하였고, 문제는 해결되지 않아 총 4일동안 장애에 대해서 속수무책이었다. 결국 구글의 서비스에 대해서 재검토해보겠다는 메일 발송 후에 이틀 후에 답변을 받았다. 결국 할당량을 5배로 늘려주었다.\n구글의 서비스 정신을 엿볼 수 있는 경험이었다.\nRDS MySQL에서 Aurora MySQL로 Migration Aurora에서 MySQL 5.7 버전 지원하는 것을 보고 바로 이전 완료하였다. 일단 프로시저같은 것들을 사용하지 않기 때문에 백서를 기준으로 어렵지 않게 마이그레이션을 할 수 있었다.\nTypescript 도입 이웅재님의 강의를 한 번 듣고 Node.js를 컴파일 언어처럼 사용해보고 싶어서 시험삼아 관리자 사이트를 모두 Typescript로 전환하였다.\nTypescript 덕분에 Lambda의 환경이 Node 6.10이었음에도 불구하고 Async/Await를 적용할 수 있었다.\nWebpack을 사용해서 기존 서버 코드를 1~3MB로 줄였는데, Lambda의 50MB의 코드 크기 제한에 많은 여유를 가져다주었다.\njQuery Good bye, welcome vue.js 기존 Legacy들은 jQuery로 되어 있었다. 여기서 데이터 바인딩이 복잡한 부분들은 모두 vue.js를 통해 재구현 하였다.\nTIPS 준비 TIPS는 Tech Incubator Program for startup Korea의 약자로 스타트업을 위한 정부지원금 중 큰 금액의 프로그램이었다. 결국엔 떨어졌지만 과정속에서 많은 부분을 배울 수 있었다. 빅뱅엔젤스의 황병선 대표님과 최광선 이사님의 조언은 사업적, 기술적 관점에 대한 성장을 가져다주었다. 논문을 읽어보고 기술에 대해서 점점 깊이 빠져들때 묘한 기분이 들기도 했다. 거의 두달 간 기술의 진행방향에 대해서 몰입하며 지냈었다. 부족함을 알 수 있었고, 성장할 방향에 대해서 다시금 확인할 수 있는 경험이었다.\n채용 채용은 개발자에게 가장 힘든 일 중에 하나다. 개발만 하는 것과 같이 함께할 동료를 선택하는 것은 완전히 다른 일이기 때문이다. 안드로이드 개발자를 채용하기 위해 최소한 가이드가 되어줄 수 있는 실력을 갖추어야만 했고, 채용할 사람이 나에게 함께 일하고 싶은 선택을 내릴 수 있도록 해야했다.\n적절할 질문을 하고, 어떤 답변인지 고심을 해보고, 어떻게 성장할 수 있는 사람인지 상상해보고, 이 모든 것에 대한 이유를 명확히 내리는 과정을 여러번 반복했다. 4개월이 지나서야 좋은 분을 채용할 수 있었다. 함께 개발하는 즐거움을 다시금 느끼고 있다.\n강의 활동 핸즈온 뿐만 아니라 개인적으로 별도의 강의도 진행했다. 양재동 코드랩의 조덕기님의 권유로 2017년 Docker강의를 시작으로 2018년에도 4회의 강의를 진행했다.\n2017년에는 도커 2회, 2018년에는 서버리스 강의 2회, 도커 1회, 그리고 AWS 기초 1회를 진행했다. 개인적으로는 마지막 도커 강의에 아쉬움이 남는다. 이직한 후로 도커를 이전처럼 계속 사용할 일이 줄어들었기 때문에 수강자들에게 최신의 정보를 공유해주지 못했던 것으로 기억한다. 쿠버네티스를 강의자료에 넣었지만 설명을 정확하게 하지못하고 적절한 예제가 없어서 아쉬움이 남는다.\nAWS 기초에 대한 강의는 12월에 진행했는데, 이전 3회의 강의에서 생각보다 초심자가 많았기 때문이었다. 예제 서비스를 실제로 배포하고 운영하는 것이 항상 마지막 단계였다. 이 과정에서 AWS를 사용했는데, 대부분의 수강자들은 AWS 계정조차 없는 경우가 많았다. 사전에 공지를 했음에도 불구하고 많은 수가 계정이 없었다. 또한 클라우드에 대한 개념을 버거워했기 때문에, A-Z라는 생각으로 계정생성부터 서버 운영 및 설정까지 강의를 진행했다.\n강의는 개인적으로 공부했던 자료를 정리하는 좋은 계기가 되었다.\n부산 밋업 주민규님의 제안으로 부산에서도 강의를 진행했다. 참석자는 많지 않았다. 30명 내외정도였다. 이때는 커뮤니티때 포털 검색어 순위에 대한 분석을 주제로 다루었다. 발표보다 개인적으로 여러 시니어 개발자 분들에게 많이 배웠다. 서울에서도 듣기 힘든 발표들을 먼 타지에서 열심히 들었다. 1박 2일동안 같이 다니면서 여태까지 개발했던 노하우, 그리고 개발자가 가져야할 덕목들, 업무를 진행할 때 가져야할 태도 등 강의 밖에서도 이야기를 나누면서 많은 도움을 받았다.\n언젠가 나도 이런 시니어가 되고 싶다.\n정리 회고는 개발자가 성장하기 위해서 필수적이라고 생각한다. 회고문을 남기는 것에 대한 강조가 아니다. 지난 생활에 대해서 반성을 해고 되짚어봐야한다는 얘기다. 지난 1년간 달려온 것들에 대해서 정리하는 것은 앞으로 나아갈 방향을 잡는데 많은 도움을 줄 것이라 생각한다.\n나는 개발 경력이 그렇게 오래되지 않았다. 고작 몇년이다. 그런데 돌이켜보면 정말 하루도 빠짐없이 공부했고 빠르게 성장했다고 생각한다.\n지하철에서는 개발 관련 블로그, 정식 문서, 그리고 유튜브에 있는 발표들을 본다. 관심있는 기술이 있으면 먼저 사용해보고 직접 올려본다. 그리고 지금까지 사용했던 기술과의 차이점에 대해서 생각해본다. AWSKRUG에서 다양한 개발자들과 관련주제에 대해서 질문을 던지고 여러 해답들을 듣는다. 잘 모르는 내용에 대한 컨퍼런스가 있으면 참가하고 지식의 폭을 넓힌다. 이런 생활의 반복이었다.\n다짐 매번 성장하고 싶을 때마다 생각하는 것은 다음과 같다.\n자신한테 모든게 달렸다. 하루도 빠짐없이 매일 반복하고 이해하기 위해 노력하면 어느새 성장해있다. 안하는 건 있어도 못하는 건 없다. 방법은 결국 찾아낼 것이다. 이런 생각을 바탕으로, 2019년에는 Low-level 및 Core 단을 이해하는 개발자가 될 것이다. 그리고 AI 및 아키텍처도. 계속 달려보자.\n","permalink":"https://novemberde.github.io/post/2019/01/01/Retrospect/","summary":"2017부터 2018년에 대해서 회고를 남기려고 한다. 어느때보다 치열하고 열심히 달려온 한해였다. 다음은 한해동한 진행했던 일들의 대한 목록은 다음과 같다.\nAWSKRUG 회사 강의 활동 \u001d AWSKRUG 개발자 커리어에서 가장 크게 영향력을 준 모임이다. AWSKRUG는 Amazon Web Service Korea User Group의 약자로 AWS 한국 사용자 그룹이라고도 불린다. 이 모임에 처음으로 참여하게된 것은 2017년 4월 쯤이었다. 지난 2년여간 데이터 사이언스 그룹을 시작으로 거의 모든 모임에 참석하였다. AWSKRUG 통해 많은 것을 배울 수 있었다.","title":"2017년부터 2018년까지의 회고"},{"content":"Summary 보안 취약점의 종류를 이해하고 정리한다. 보안은 개발속도를 늦추는 경우도 있지만 제품의 안정성과 신뢰성에 기여하기 때문에 필수적인 요소이다. 다음은 OWASP(The Open Web Application Security Project)의 년도별 TOP 10 취약점의 종류이다.\n2017 Injection\nBroken Authentication\nSensitivy Data Exposure\nXML External Entities(XXE)\nBroken Access Control\nSecurity Misconfiguration\nCross-Site Scripting(XXS)\nInsecure Deserialization\nUsing Component with Known Vulnerabilities\nInsufficient Logging \u0026amp; Monitoring\n2013 Injection\nBroken Authentication and Session Management\nCross-Site Scripting\nInsecure Direct Object References\nSecurity Misconfiguration\nSensitive Data Exposure\nMissing Function Level Acess Control\nCross-Site Request Forgery(CSRF)\nUsing Component with Known Vulnerabilities\nUnvalidated Redirects and Forwards\n2010 Injection\nCross-Site Scripting\nBroken Authentication and Session Management\nInsecure Direct Object References\nCross-Site Request Forgery(CSRF)\nSecurity Misconfiguration\nInsecure Cryptographic Storage\nFailure to Restrict URL Access\nInsufficient Transport Layer Protection\nUnvalidated Redirects and Forwards\n2007 Cross Site Scripting (XSS)\nInjection Flaws\nMalicious File Execution\nInsecure Direct Object Reference\nCross Site Request Forgery (CSRF)\nInformation Leakage and Improper Error Handling\nBroken Authentication and Session Management\nInsecure Cryptographic Storage\nInsecure Communications\nFailure to Restrict URL Access\n2004 Unvalidated Input Broken Access Control Broken Authentication and Session Management Cross Site Scripting Buffer Overflow Injection Flaws Improper Error Handling Insecure Storage Application Denial of Service Insecure Configuration Management References https://ko.wikipedia.org/wiki/OWASP ","permalink":"https://novemberde.github.io/post/2018/11/02/OWASP/","summary":"Summary 보안 취약점의 종류를 이해하고 정리한다. 보안은 개발속도를 늦추는 경우도 있지만 제품의 안정성과 신뢰성에 기여하기 때문에 필수적인 요소이다. 다음은 OWASP(The Open Web Application Security Project)의 년도별 TOP 10 취약점의 종류이다.\n2017 Injection\nBroken Authentication\nSensitivy Data Exposure\nXML External Entities(XXE)\nBroken Access Control\nSecurity Misconfiguration\nCross-Site Scripting(XXS)\nInsecure Deserialization\nUsing Component with Known Vulnerabilities\nInsufficient Logging \u0026amp; Monitoring\n2013 Injection\nBroken Authentication and Session Management\nCross-Site Scripting\nInsecure Direct Object References","title":"OWASP TOP 10"},{"content":"Summary 부산 스마트 앱 개발자 포럼에서 서버리스를 활용하여 데이터를 수집 및 분석 후기를 공유하였다.\n발표자료 Github repo. 발표 슬라이드 0원으로 시작하는 서버리스 데이터 수집 및 분석 from Kyuhyun Byun 고찰 지난 여름부터 모아온 데이터를 분석하고 이 데이터를 기반으로 AWS의 데이터 처리 서비스들에 대해서 공부하는 계기였다. 실제로 현업에서 데이터를 분석할 일은 많다. 데이터를 쌓고 보기 쉽게 변환하는 과정 그리고 시각화까지 다양한 기술을 요구한다. 데이터를 다루는 역량 뿐만 아니라 전체적인 웹서비스 구축 역량을 요구한다.\n기본적인 시각화는 프론트엔드에 대한 역량, 데이터를 수집하고 서비스를 운영하는 것은 백엔드의 역량을 필요로 한다. 이러한 역량을 데이터사이언티스트가 모두 지니는 것은 쉽지 않다. 직접 플랫폼을 구축하고 각 데이터 분석 도구의 Configuration을 설정하는 것은 상당한 지식을 필요로 한다. 또한, 데이터 분석을 위한 클러스터를 직접 운영한다는 것은 고급 인력을 요구한다.\n그럼에도 불구하고 비지니스의 성장을 위해 데이터 분석을 해야한다면 관리형서비스를 적극적으로 사용해야한다. 하둡 클러스터를 띄우고 스키마를 정의하고 직접 운영하는 것보다는 AWS Glue에 카탈로그를 추가하고, 주기적인 작업을 설정만 해두고 필요할 때 호출만 하는 것이 가장 좋을 것이다. 그리고 직접적으로 Serdes를 지정하고 데이터 스키마를 관리하는 것을 클라우드에 맡겨두고 비용은 Glue가 동작한 시간에 대해서만 지불하는 것이 낫다.\nQuickSight를 쓰면 직접 비주얼라이징 도구를 서버에 호스팅하지 않아도 되며, Athena를 통해 사용하는 데이터 스캔 비용만 지불하면 상당히 적은 비용으로 데이터 분석 도구를 운영할 수 있다.\n","permalink":"https://novemberde.github.io/post/2018/10/29/Potal-Analysis/","summary":"Summary 부산 스마트 앱 개발자 포럼에서 서버리스를 활용하여 데이터를 수집 및 분석 후기를 공유하였다.\n발표자료 Github repo. 발표 슬라이드 0원으로 시작하는 서버리스 데이터 수집 및 분석 from Kyuhyun Byun 고찰 지난 여름부터 모아온 데이터를 분석하고 이 데이터를 기반으로 AWS의 데이터 처리 서비스들에 대해서 공부하는 계기였다. 실제로 현업에서 데이터를 분석할 일은 많다. 데이터를 쌓고 보기 쉽게 변환하는 과정 그리고 시각화까지 다양한 기술을 요구한다. 데이터를 다루는 역량 뿐만 아니라 전체적인 웹서비스 구축 역량을 요구한다.","title":"0원으로 시작하는 데이터 수집 및 분석"},{"content":"Summary 현재 Terraform으로 ECS 인프라를 생성하고, CircleCI에서 docker image를 빌드하고 ECR에 푸시하는 과정을 자동화하고 있다. 이 과정에 있어서 docker image를 빌드하는 것에서 문제가 발생했다.\nCircleCI에서 script를 실행하는 환경은 Container 기반으로 되어 있기 때문이다. Docker image를 빌드하기 위해서는 docker가 설치되어 있는 환경이어야 했다.\ndocker-in-docker라는 개념으로 docker hub에 \u0026ldquo;docker\u0026quot;라는 docker image가 있다. 하지만 이 이미지로는 프로덕션 이미지를 빌드하고 배포할 때 사용하는 기본 패키지가 없는데, 이러한 기본패키지를 추가하여 CircleCI에서 docker를 빌드할 수 있는 이미지 생성하는 방법 및 CircleCI 설정을 정리해보았다.\nDockerfile 작성하기 Dockerfile 작성은 어렵지 않다.\n베이스 이미지로는 alpine linux 기반의 이미지를 사용한다. 또한 nodejs, npm, awscli, docker가 설치되어 있어야 한다.\n작성한 Dockerfile은 다음과 같다.\nFROM docker:stable # Install node RUN apk update \u0026amp;\u0026amp; apk add --update nodejs nodejs-npm # Install build-essentials RUN apk add --virtual build-dependencies build-base gcc wget git # Install aws-cli RUN apk -v --update add \\ python \\ py-pip \\ groff \\ less \\ mailcap \\ \u0026amp;\u0026amp; \\ pip install --upgrade awscli==1.14.5 s3cmd==2.0.1 python-magic \u0026amp;\u0026amp; \\ apk -v --purge del py-pip \u0026amp;\u0026amp; \\ rm /var/cache/apk/* ENTRYPOINT [] CMD [\u0026#34;sh\u0026#34;] https://github.com/novemberde/node-awscli/blob/master/docker/Dockerfile\n여기서 docker:stable은 alpine linux 기반으로 docker가 사전 설치된 이미지인데, docker 재단에서 공식적으로 제공한다. \u0026ldquo;docker\u0026rdquo; image는 docker in docker를 사용하기 위한 환경을 제공한다. 그 다음, 차례대로 nodejs, npm, build-essentials, awscli 등을 설치한다.\nENTRYPOINT는 docker:stable에서 Default로 docker-entrypoint.sh로 지정되어 있어 오류가 발생하기 때문에, 다시 재정의해주었다.\n이렇게 생성된 이미지는 현재 docker hub에 public으로 올렸다. 태그는 docker로 되어 있으며, 이미지는 다음과 같은 명령어로 받아올 수 있다.\n$ docker pull novemberde/node-awscli:docker CircleCI에서 설정하기 Docker가 설치되어 있는 docker image를 생성했으니 CircleCI에서 설정을 시작해보자.\n평소와 달라지는 부분은 \u0026lsquo;setup_remote_docker\u0026rsquo; 부분이다. 이 설정을 추가하면 docker command에 대해서 격리된 새로운 환경에서 사용할 수 있게 해준다.\nversion: 2 jobs: build: docker: - image: novemberde/node-awscli:docker working_directory: ~/repo steps: - checkout ### This configuration is enable to build a docker image. - setup_remote_docker: docker_layer_caching: true ### - run: docker build -t test ./ 확인해보기 CircleCI configuration을 마치고 git push를 하면 빌드가 시작된다.\n샘플 Dockerfile에 대해서 빌드한 결과는 다음과 같다.\n고찰 alpine linux를 사용하는 이유는 기타 리눅스 배포판과 기본 사이즈의 차이가 많이 나기 때문이다. 참고할 표는 다음과 같다. 적은 용량은 도커 이미지를 가져올 때의 네트워크 부하를 줄여주고, 이미지 생성 및 사용에 대해서도 속도를 향상시키는 효과를 가져올 수 있다.\nDISTRIBUTION VERSION SIZE Debian Jessie 123MB CentOS 7 193MB Fedora 25 231MB Ubuntu 16.04 118MB Alpine 3.6 3.98MB References 참고자료: https://nickjanetakis.com/blog/the-3-biggest-wins-when-using-alpine-as-a-base-docker-image 참고자료: https://circleci.com/docs/2.0/building-docker-images/ ","permalink":"https://novemberde.github.io/post/2018/09/17/Circleci-docker/","summary":"Summary 현재 Terraform으로 ECS 인프라를 생성하고, CircleCI에서 docker image를 빌드하고 ECR에 푸시하는 과정을 자동화하고 있다. 이 과정에 있어서 docker image를 빌드하는 것에서 문제가 발생했다.\nCircleCI에서 script를 실행하는 환경은 Container 기반으로 되어 있기 때문이다. Docker image를 빌드하기 위해서는 docker가 설치되어 있는 환경이어야 했다.\ndocker-in-docker라는 개념으로 docker hub에 \u0026ldquo;docker\u0026quot;라는 docker image가 있다. 하지만 이 이미지로는 프로덕션 이미지를 빌드하고 배포할 때 사용하는 기본 패키지가 없는데, 이러한 기본패키지를 추가하여 CircleCI에서 docker를 빌드할 수 있는 이미지 생성하는 방법 및 CircleCI 설정을 정리해보았다.","title":"Circle CI에서 Docker Build 하기"},{"content":"Summary 2018년 AWSKRUG에서 8회에 걸쳐 진행하는 핸즈온 중 하나인 Serverless Hands-on 입니다\n제목: 손쉽게 시작하는 Serverless Architecture\n내용: Serverless Architecture는 말그대로 서버를 올리지 않는 아키텍처를 의미합니다. 기존에는 각 서버에 운영하는 어플리케이션들을 배포했지만, Serverless Architecture를 적용하면 운영 부담없이 비지니스 로직에만 집중할 수 있습니다. 서버없이 Web Application과 Crawler를 만들어 운영이 필요없는 데모 서비스를 구성합니다.\nServerless Group First Hands-on Part 1 AWSKRUG Serverless Group의 첫번째 핸즈온 Part.1 웹어플리케이션 만들기입니다.😁\n바로가기\nServerless Group First Hands-on Part 2 AWSKRUG Serverless Group의 첫번째 핸즈온 Part.2 웹크롤러 만들기입니다.😁\n바로가기\nReferences https://www.meetup.com/ko-KR/awskrug/events/251326459/ https://github.com/awskrug/handson-labs-2018 https://github.com/novemberde/serverless-todo-demo https://github.com/novemberde/serverless-crawler-demo ","permalink":"https://novemberde.github.io/post/2018/07/02/Serverless-Handson-1/","summary":"Summary 2018년 AWSKRUG에서 8회에 걸쳐 진행하는 핸즈온 중 하나인 Serverless Hands-on 입니다\n제목: 손쉽게 시작하는 Serverless Architecture\n내용: Serverless Architecture는 말그대로 서버를 올리지 않는 아키텍처를 의미합니다. 기존에는 각 서버에 운영하는 어플리케이션들을 배포했지만, Serverless Architecture를 적용하면 운영 부담없이 비지니스 로직에만 집중할 수 있습니다. 서버없이 Web Application과 Crawler를 만들어 운영이 필요없는 데모 서비스를 구성합니다.\nServerless Group First Hands-on Part 1 AWSKRUG Serverless Group의 첫번째 핸즈온 Part.1 웹어플리케이션 만들기입니다.😁\n바로가기\nServerless Group First Hands-on Part 2 AWSKRUG Serverless Group의 첫번째 핸즈온 Part.","title":"2018년 AWS Serverless Hands-on 1, 손쉽게 시작하는 Serverless Architecture"},{"content":"Summary 개인용 개발계정, 회사계정, 워크샵 전용 계정 등등 여러 계정들을 사용하다보니 Default로 Access Key ID 와 Secret Access Key를 관리하고 싶어졌다. Default로 두고 사용하다가 잘못하면 회사계정에 잘못된 인프라를 생성 및 변경할 수도 있기 때문이다.\nAWS Configure \u0026ndash;profile 기본적인 aws cli를 설정하는 것은 어렵지 않다. AWS Console의 IAM에서 유저를 생성하고 Access Key를 생성하면 된다. 생성된 키를 통해 로컬이 AWS의 권한을 사용하도록 설정하는 것은 다음과 같다.\n# 생성된 키와 리전을 입력하면 된다. $ aws configure AWS Access Key ID [****************aaaa]: AWS Secret Access Key [****************aaaa]: Default region name [ap-northeast-2]: Default output format [json]: 그렇다면 여러 계정을 관리하려면 어떻게 해야할까?\n\u0026ndash;profile 옵션을 사용하면 어렵지 않다.\n$ aws configure --profile testUser AWS Access Key ID [****************aaaa]: AWS Secret Access Key [****************aaaa]: Default region name [ap-northeast-2]: Default output format [json]: 새로운 유저의 Profile을 입력하였으니 명령어를 통해 리소스가 정말 다르게 나오는지 확인해본다.\n# 생성한 버킷의 리스트가 출력된다. $ aws s3 ls --profile testUser 3-party도구를 사용하다보면 Default User를 피치못할 사정으로 사용하게 된다. 그런 상황에서는 Default User를 스위칭해가며 사용한다.\n# 환경변수로 default profile을 등록하여 준다. $ export AWS_DEFAULT_PROFILE=testUser # 만일 윈도우 사용자라면 set을 사용한다. $ set AWS_DEFAULT_PROFILE=testUser # 방금 전에 --profile 옵션과 함께 출력됐던 버킷의 리스트가 출력된다. $ aws s3 ls # 현재 사용하고 있는 default profile user가 출력된다. $ aws configure list Name Value Type Location ---- ----- ---- -------- profile testUser manual --profile access_key ****************aaaa shared-credentials-file secret_key ****************aaaa shared-credentials-file region ap-northeast-2 config-file ~/.aws/config 이렇게 하면 당장은 되는 것처럼 보이지만 다른 Terminal을 열어서 해보면 되지 않는다.\n$ aws s3 ls An error occurred (InvalidAccessKeyId) when calling the ListBuckets operation: The AWS Access Key Id you provided does not exist in our records. 당황하지 말고 ~/.bashrc 또는 ~/.zshrc파일의 마지막 라인에 \u0026ldquo;export AWS_DEFAULT_PROFILE=testUser\u0026quot;를 추가한다.\n~/.zshrc 또는 ~/.bashrc ... ... export AWS_DEFAULT_PROFILE=testUser # 재설정한다. $ source ~/.zshrc # 또는 source ~/.bashrc # Default로 설정이 완료되었다. $ aws s3 ls 하지만 변동 가능한 환경변수에 대한 설정정보를 bashrc에 넣는 것은 바람직해보이지 않는다. 귀찮더라도 이정도는 매번 손으로 설정하는 것이 위험 부담을 줄이는 길이라고 생각한다.\nReferences https://docs.aws.amazon.com/cli/latest/reference/configure/list.html ","permalink":"https://novemberde.github.io/post/2018/06/20/AWS-config-switching/","summary":"Summary 개인용 개발계정, 회사계정, 워크샵 전용 계정 등등 여러 계정들을 사용하다보니 Default로 Access Key ID 와 Secret Access Key를 관리하고 싶어졌다. Default로 두고 사용하다가 잘못하면 회사계정에 잘못된 인프라를 생성 및 변경할 수도 있기 때문이다.\nAWS Configure \u0026ndash;profile 기본적인 aws cli를 설정하는 것은 어렵지 않다. AWS Console의 IAM에서 유저를 생성하고 Access Key를 생성하면 된다. 생성된 키를 통해 로컬이 AWS의 권한을 사용하도록 설정하는 것은 다음과 같다.\n# 생성된 키와 리전을 입력하면 된다. $ aws configure AWS Access Key ID [****************aaaa]: AWS Secret Access Key [****************aaaa]: Default region name [ap-northeast-2]: Default output format [json]: 그렇다면 여러 계정을 관리하려면 어떻게 해야할까?","title":"AWS Configure 여러 계정으로 스위칭하며 사용하기"},{"content":"Summary 안드로이드 개발 언어의 트렌드는 바뀌었다. 최근 Google I/O에서 나오는 샘플 코드들은 Kotlin으로 짜여져 있었다. 또한 안드로이드 개발 컨퍼런스의 주제는 Kotlin으로 개발한 경험담이 주를 이루고 있다.\nKotlin으로 개발하는 것이 낫다는 내용을 많이 보기도 하였고 개발에 욕심이 있다보니, 이번에는 기존에 JAVA로 개발되어 있던 코드에 Kotlin을 적용하여 새로 구성하거나 변경하는 클래스를 Kotlin으로 구성해보았다.\n다음은 이런 과정을 거치면서 느낀 장점과 단점에 대한 고찰이다.\n고찰 Kotlin의 장점을 느끼기 전에는 치명적인 단점(?)과 싸워야만 한다.\n무엇보다 가장 크게 힘들었던 점은 손에 익은 Java 대신에 인내하며 억지로 Kotlin으로 작성해야된다는 점이었다. 개발자가 새로운 기술을 받아들여야 할 때 나타나는 문제점이었다. 기존에 잘하는 것으로 개발하면 바로 끝낼 수 있지만 새로운 것을 받아들이면 공부하고 적용하는데까지 시간이 몇배로 들기 때문이다. 이런 경우에 기술을 받아들일지는 상황에 따라 결정하게 된다. 상급자의 명령에 따라 빠른 퍼포먼스를 보여줘야하는 경우에는 기존의 기술을 택한다. 반면에 중간중간에 공부를 해두어서 적용할 수 있는 단계가 된 경우이거나 개발의 주체가 기술에 대한 욕심이 있고 새로운 것에 대해 무리없이 받아들이는 경우에는 새로운 기술을 택한다. 솔직히 후자라고 주장하고 싶지만 지난 몇번의 시도를 하였지만 다시 Java로 개발했었다. 편하게 살고싶은 마음을 이겨내는 것이 제일 힘들었다.\n이번에는 마음을 먹고 .kotlin으로 파일을 생성하여 .java는 생성하지도 않았다. 여러 언어를 접하면서, 공부하면 기본은 비슷하기 때문에 적응만 하면 배울 수 있다는 것을 깨달았기 때문이다.\nKotlin을 적용하는 것은 만만하지 않았다. Java에선 타입을 먼저 지정하고 그에 대한 private / public / protected와 같은 scope를 정하며, 객체를 통해 모든 데이터를 전달하고 Interface를 통해 메서드들을 정했었다. 여태까지 자연스러운 행위였다.\nKotlin에서는 var / val를 통한 변수 선언만이 존재했다. 처음엔 익숙하지 않았다. 먼저 객체 타입을 지정하였던 이전과 비교하여 콜론 다음에 타입을 지정할 수 있었다. 게다가 콜론 다음에 타입을 지정하는 것은 필수가 아니었다. 어색했다. 하지만 이것을 이겨내는 방법은 간단하였다. Kotlin이 이런 방식을 택한 이유에 대해 Java로 개발할 때보다 불편하게 만들기 위한 것이 아니라는 것만 생각하면 되었다.\n코틀린에서는 변수 선언과 동시에 값을 할당 할 때에는 타입을 지정할 필요가 없었다. 왜냐하면 바로 뒤에 해당 객체의 형을 볼 수 있기 때문이다. 만약 변수선언과 동시에 값을 할당하지 않는다면, 타입을 콜론한 다음에 지정해주면 된다. 예제는 다음과 같다.\nprivate var str = \u0026#34;SOME STRING\u0026#34; // 할당된 값을 통해 간단히 타입을 추론할 수 있다. private var str : String // 값이 할당되지 않을 때 변수 선언과 관련해서 바뀐점은 특별히 편하다는 생각은 많이 들지 않았다. 하지만 람다식이나 inner anonymous를 구현함에 있어서 코드를 아주 간결하게 표현할 수 있다.\n자바에서는 다음과 같이 표현했다.\nnew Thread(new Runnable() { @override public void run() { // RUN SOME CODES } }).start() // OR new Thread(() -\u0026gt; { // RUN SOME CODES }).start() 이를 코틀린으로 작성하면 다음과 같다.\nThread({ // RUN SOME CODES }).start() 코드가 java보다 간결하게 표현된 것을 확인할 수 있다. 람다식으로 표현된 것보다도 간결해진다. 하지만 이것만으로는 간결해졌다고 볼 수 없다.\n무엇보다 Kotlin에서 가장 매력적으로 느꼈던 부분은 functional programming의 특징이다. Java에서 Callback을 구현하기 위해서는 다음과 같은 프로세스로 진행해야한다.\ncallback으로 사용할 메서드가 정의된 AInterface를 생성 Async하게 동작하는 AClass에서 AInterface를 parameter로 받는 aMethod 메서드 생성 aMethod를 호출하는 BClass에서 AInterface를 내부익명으로 새로 구현하던지 상속받아 this를 파라미터로 넘겨 실행 (물론 더 다양한 방법도 존재하지만 이게 흔한 방법이다.) 글로 표현하기도 참 쉽지 않다. 헷갈린다. 하지만 Kotlin으로 작성하면 아주 간단하다. 파라미터를 함수로 받고 그것을 실행만 하면된다. 물론 이 함수는 별도로 정의되어 있는 인터페이스나 클래스가 아니다. Javascript로 개발한 적이 있다면 이러한 Callback 기법이 편안하게 다가올 것이다. 상세하게 알고 싶다면 다음의 링크를 참고하면 된다.\nHigher-Order Functions and Lambdas\n위처럼 Kotlin에 적응하기 위한 일련의 과정을 거치니 점점 개발 퍼포먼스가 증가하였다. Kotlin으로 작성하면 코드의 무게가 작아지는 것도 있고, 자잘한 Interface를 선언할 일도 줄어들었기 때문이다. 덕분에 순수하게 타자를 치는 시간도 줄었다.\n이렇게만 말하니 조금 안타깝지만 언어 선택이 개발에 있어서 엄청난 향상으로 나타나지 않는다는 것은 모두가 알 것이다. 웹서버 개발을 할 때에도 C, C#, PHP, JAVA, Go, Nodejs, Python 등등 다양한 방법이 있다. 그럼에도 불구하고, 우리가 최근에는 Go, Nodejs, C#, Python등으로 개발하는 이유가 있다. C가 익은 사람이라도 이제는 C로 웹서버를 개발하지 않는다. 왜냐하면 지속적인 개발을 위한 퍼포먼스에서 크게 차이가 나타나기 때문이다. 비록 처음에는 배움에 대한 문턱이 있다 할지라도, 결국에는 유지보수의 단계에서 비용절감의 결과로 나타날 것이다.\n개발 속도에 문제가 생기지 않도록 유지가능한 코드를 위해 Kotlin을 적극 도입하기를 추천한다.\n","permalink":"https://novemberde.github.io/post/2018/05/28/kotlin/","summary":"Summary 안드로이드 개발 언어의 트렌드는 바뀌었다. 최근 Google I/O에서 나오는 샘플 코드들은 Kotlin으로 짜여져 있었다. 또한 안드로이드 개발 컨퍼런스의 주제는 Kotlin으로 개발한 경험담이 주를 이루고 있다.\nKotlin으로 개발하는 것이 낫다는 내용을 많이 보기도 하였고 개발에 욕심이 있다보니, 이번에는 기존에 JAVA로 개발되어 있던 코드에 Kotlin을 적용하여 새로 구성하거나 변경하는 클래스를 Kotlin으로 구성해보았다.\n다음은 이런 과정을 거치면서 느낀 장점과 단점에 대한 고찰이다.\n고찰 Kotlin의 장점을 느끼기 전에는 치명적인 단점(?)과 싸워야만 한다.\n무엇보다 가장 크게 힘들었던 점은 손에 익은 Java 대신에 인내하며 억지로 Kotlin으로 작성해야된다는 점이었다.","title":"Legacy android application, Kotlin 적용기"},{"content":"Summary If you\u0026rsquo;re a lazy JAVA developer, you concatenate Strings by using the plus sign (\u0026ldquo;Some text\u0026rdquo; + \u0026quot; added text\u0026quot;) But if you want to level-up your skills as a JAVA developer, you should be more careful about the Class that you choose. Let\u0026rsquo;s take a glance at the use cases of String, StringBuilder and StringBuffer.\nFeature of Classes It\u0026rsquo;s necessary to be familiar with the Java API documents before getting your hands dirty.\nLet\u0026rsquo;s take a look at the java.lang package on Java API. Java.lang package has a bundle of classes that does not require you to import them manually. It contains basic classes (\u0026lsquo;WrapperClass\u0026rsquo;) like Boolean, Byte, and Integer.\nAmong them, we are going to look into String, StringBuffer, and StringBuilder.\nString class is inherited from Serializable, CharSequence, Comparable interfaces, and configured as \u0026lsquo;public final class\u0026rsquo;. In other words, String class is a sequence of characters, a comparable value, and is able to be serialized. Also, it cannot be used for the inherited class.\nWhen you look up the use cases of String, you can easily find articles that suggest using StringBuffer or StringBuilder instead of String.\nLet\u0026rsquo;s find out why.\nString stringValue1 = \u0026#34;TEST 1\u0026#34;; String stringValue2 = \u0026#34;TEST 2\u0026#34;; System.out.println(\u0026#34;stringValue1: \u0026#34; + stringValue1.hashCode()); System.out.println(\u0026#34;stringValue2: \u0026#34; + stringValue2.hashCode()); stringValue1 = stringValue1 + stringValue2; System.out.println(\u0026#34;stringValue1: \u0026#34; + stringValue1.hashCode()); StringBuffer sb = new StringBuffer(); System.out.println(\u0026#34;sb: \u0026#34; + sb.hashCode()); sb.append(\u0026#34;TEST StringBuffer\u0026#34;); System.out.println(\u0026#34;sb: \u0026#34; + sb.hashCode()); Results: stringValue1: -1823841245 stringValue2: -1823841244 stringValue1: 833872391 sb: 1956725890 sb: 1956725890 On the snippet above, a different reference value is created for each of the instances as a instance is created everytime a new value is assigned to the String. However, StringBuffer appends a string value on memory to concatenate and reuse the instance that was already created. Logically, Class creates methods and variables on creating an instance, but StringBuffer does not allow this time delay on instance creation.\nOn the above example, String instance is only created once, but if you concatenate several Strings, its instances stack on heap area of memory and it takes memories until JVM calls the Garbage Collector. This is a critical issue in managing memory of your application.\nHmm, why is String instance created every time calling \u0026rsquo;new\u0026rsquo;? Let\u0026rsquo;s look at the structure of String class.\nOn the following image, you can see an array \u0026lsquo;value[]\u0026rsquo; consist of character type. You should look carefully \u0026lsquo;value[]\u0026rsquo; is \u0026lsquo;private final char\u0026rsquo; type.\nA string value is saved as an array of characters, and this private array cannot be accessed from other classes. Also, \u0026lsquo;value[]\u0026rsquo; is a final type, cannot be changed since initialized.\nLet\u0026rsquo;s take a look at StringBuilder and StringBuffer that uses \u0026lsquo;append\u0026rsquo; method for concatenation.\nOn the following image, StringBuilder class is a mutable sequence of characters, but has no guarantee of syncronization. StringBuffer can also by safely used in multi-thread environments. This is the main difference between StringBuilder and StringBuffer classes.\nOn the following sample snippet, results show the difference between the two classes. The result value of StringBuilder has a smaller value because multiple threads accessed a StringBuilder instance simultaneously. However, StringBuffer is thread-safe unlike StringBuilder. The StringBuffer instance has a bigger and precise value on multiple threads environment because StringBuffer supports synchronization.\nStringBuffer stringBuffer = new StringBuffer(); StringBuilder stringBuilder = new StringBuilder(); new Thread(() -\u0026gt; { for(int i=0; i\u0026lt;10000; i++) { stringBuffer.append(i); stringBuilder.append(i); } }).start(); new Thread(() -\u0026gt; { for(int i=0; i\u0026lt;10000; i++) { stringBuffer.append(i); stringBuilder.append(i); } }).start(); new Thread(() -\u0026gt; { try { Thread.sleep(5000); System.out.println(\u0026#34;StringBuffer.length: \u0026#34;+ stringBuffer.length()); System.out.println(\u0026#34;StringBuilder.length: \u0026#34;+ stringBuilder.length()); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); Results: StringBuffer.length: 77780 StringBuilder.length: 76412 References http://docs.oracle.com/javase/8/docs/api/ http://javahungry.blogspot.com/2013/06/difference-between-string-stringbuilder.html ","permalink":"https://novemberde.github.io/post/2018/05/24/String/","summary":"Summary If you\u0026rsquo;re a lazy JAVA developer, you concatenate Strings by using the plus sign (\u0026ldquo;Some text\u0026rdquo; + \u0026quot; added text\u0026quot;) But if you want to level-up your skills as a JAVA developer, you should be more careful about the Class that you choose. Let\u0026rsquo;s take a glance at the use cases of String, StringBuilder and StringBuffer.\nFeature of Classes It\u0026rsquo;s necessary to be familiar with the Java API documents before getting your hands dirty.","title":"The difference among String, StringBuilder, and StringBuffer in JAVA"},{"content":"Summary 현재 공통적인 모듈을 Git으로 따로 관리하여 npm private module로 사용한다. 또한 Webpack을 사용하여 Typescript로 작성된 서버를 번들링한다. 로컬에서는 모두 정상적으로 동작하지만 CircleCI에서 빌드할 경우에는 CircleCI의 권한이 해당 repository에 대한 권한만 가지고 있기 때문에 npm private module을 가져올 수가 없다.\n이와같은 문제를 해결하기 위해서 트러블 슈팅을 하였다.\nProblem npm install을 할 때에 github에 있는 repository를 사용하는 방법은 두가지가 있다.\nhttps ssh ssh로 사용할 경우 관련 명령어는 다음과 같다.\n# ssh 키 생성하기 $ ssh-keygen -f id_rsa_kh -C \u0026#34;\u0026#34; # 생성한 키를 ~/.ssh 에 추가하기 $ cp id_rsa_kh ~/.ssh/id_rsa_kh # 생성한 키의 권한 수정하기 $ chmod 600 ~/.ssh/id_rsa_kh # 생성한 키의 퍼블릭 키를 출력하기. 이때 받은 키를 github private repo에 ssh키를 추가하여야 한다. $ cat id_rsa_kh.pub # ssh의 개인키 개수 확인하기 $ ls -al ~/.ssh/ # ssh-agent 실행하기 $ eval \u0026#34;$(ssh-agent -s)\u0026#34; # ~/.ssh 디렉터리에 있는 개인키를 모두 ssh agent에 등록하기 $ grep -slR \u0026#34;PRIVATE\u0026#34; ~/.ssh/ | xargs ssh-add # 현재 등록되어 있는 ssh key의 fingerprint 확인하기 $ ssh-add -l -E md5 위와 같이 키를 입력하였으면 이제 npm install을 해본다.\n# username, repository를 수정하여준다. $ npm i -S git+ssh://git@github.com:\u0026lt;username\u0026gt;/\u0026lt;repository\u0026gt;.git # https의 경우 $ npm i -S https://github.com/\u0026lt;username\u0026gt;/\u0026lt;repository\u0026gt; $ npm i -S git+https://\u0026lt;token\u0026gt;:x-oauth-basic@github.com/\u0026lt;username\u0026gt;/\u0026lt;repository\u0026gt;.git 로컬에서 사용시 여기까지는 문제없이 진행되었다. 하지만 CircleCI에서 ssh키를 추가하여 steps에 다음의 코드도 추가하였음에도 불구하고 npm install이 되지 않았다.\n- add_ssh_keys: fingerprints: - \u0026#34;XX:XX:...\u0026#34; 그래서 이전에 사용했던 명령어들을 통해 디버깅을 시작하였다. 다음의 명령어를 통해 fingerprint를 확인해보니 정상적으로 추가가 되어 있었다.\n$ ssh-add -l -E md5 2048 MD5:xx... (RSA) 2048 MD5:xx:yy... (RSA) 그렇다면 무엇이 문제일까? 해답은 다음과 같은 명령어를 통해 유추해낼 수 있었다.\n$ ssh -Tv git@github.com 이것은 ssh로 github에 인증이 되었는지 확인할 수 있는데, 위의 명령어를 입력하니 다음과 같은 것을 확인할 수 있었다.\nHi \u0026lt;username\u0026gt;/\u0026lt;another_repo\u0026gt;! You\u0026rsquo;ve successfully authenticated, but GitHub does not provide shell access.\n이를 보니 CircleCI에서 빌드하는 repository의 ssh키로 Github에 접근하니 추가한 ssh-key가 있다하더라도 default로 가지고 있는 키로 ssh를 시도하였다.\nSolution 해결방법은 고민이 무색할 정도로 간단하게 결정하였다. Github에 접근하는 키에 대해 switching 을 하는 스크립트를 만들고 매번 실행하여 해결할까라는 고민도 하였지만 너무 불필요한 코드라고 여겨졌다. 그래서 Gmail 계정을 하나 더 생성하고, github에 가입한 다음 권한을 주었다.\n그 다음은 https로 private repo에 접근하면 된다.\n솔직히 제일 간단한 방법은 npm 에 private repository를 매달 비용을 지불하면서 사용하면 된다. 아니면 직접 npm repository를 운영하여 사용해도 좋다. 그런데 운영 리소스를 줄이고 싶은 마음이 제일 크기 때문에 직접 운영하는 배제하였고, npm private repo는 아직 크게 사용할 일이 없어서 하지 않았다.\n나중에 private repository가 많아진다면 npm에 지불해야 된다고 생각한다.\n","permalink":"https://novemberde.github.io/post/2018/05/16/CircleCI-npm-private-github/","summary":"Summary 현재 공통적인 모듈을 Git으로 따로 관리하여 npm private module로 사용한다. 또한 Webpack을 사용하여 Typescript로 작성된 서버를 번들링한다. 로컬에서는 모두 정상적으로 동작하지만 CircleCI에서 빌드할 경우에는 CircleCI의 권한이 해당 repository에 대한 권한만 가지고 있기 때문에 npm private module을 가져올 수가 없다.\n이와같은 문제를 해결하기 위해서 트러블 슈팅을 하였다.\nProblem npm install을 할 때에 github에 있는 repository를 사용하는 방법은 두가지가 있다.\nhttps ssh ssh로 사용할 경우 관련 명령어는 다음과 같다.\n# ssh 키 생성하기 $ ssh-keygen -f id_rsa_kh -C \u0026#34;\u0026#34; # 생성한 키를 ~/.","title":"CircleCI에서 Github private repository를 npm module로 사용하기"},{"content":"Summary 각 사용자들의 연관 관계 분석을 위하여 GraphDB를 도입하려한다. 시작하기에 앞서서 GraphDB에 대해서 이해가 필요했다. 다음에서 GraphDB의 기본 내용을 담았다.\nGraph Database란? In computing, a graph database is a database that uses graph structures for semantic queries with nodes, edges and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store. The relationships allow data in the store to be linked together directly, and in many cases retrieved with one operation.\nThis contrasts with relational databases that, with the aid of relational database management systems, permit managing the data without imposing implementation aspects like physical record chains; for example, links between data are stored in the database itself at the logical level, and relational algebra operations (e.g. join) can be used to manipulate and return related data in the relevant logical format. The execution of relational queries is possible with the aid of the database management systems at the physical level (e.g. using indexes), which permits boosting performance without modifying the logical structure of the database.\nGraph databases, by design, allow simple and fast retrieval[citation needed] of complex hierarchical structures that are difficult to model[according to whom?] in relational systems. Graph databases are similar to 1970s network model databases in that both represent general graphs, but network-model databases operate at a lower level of abstraction[1] and lack easy traversal over a chain of edges.[2]\nThe underlying storage mechanism of graph databases can vary. Some depend on a relational engine and “store” the graph data in a table (although a table is a logical element, therefore this approach imposes another level of abstraction between the graph database, the graph database management system and the physical devices where the data is actually stored). Others use a key-value store or document-oriented database for storage, making them inherently NoSQL structures. Most[according to whom?] graph databases based on non-relational storage engines also add the concept of tags or properties, which are essentially relationships having a pointer to another document. This allows data elements to be categorized for easy retrieval en masse.\nRetrieving data from a graph database requires a query language other than SQL, which was designed for the manipulation of data in a relational system and therefore cannot “elegantly” handle traversing a graph. As of 2017, no single graph query language has been universally adopted in the same way as SQL was for relational databases, and there are a wide variety of systems, most often tightly tied to one product. Some standardization efforts have occurred, leading to multi-vendor query languages like Gremlin, SPARQL, and Cypher. In addition to having query language interfaces, some graph databases are accessed through application programming interfaces (APIs).\n[출처]: https://en.wikipedia.org/wiki/Graph_database\n위 내용을 국내 서비스 파파고로 번역하면 다음과 같다.\n컴퓨팅에서 그래프 데이터베이스는 노드, 가장자리 및 속성이 있는 의미 쿼리에 대해 데이터를 표시하고 저장하기 위해 그래프 구조를 사용하는 데이터베이스입니다. 시스템의 주요 개념은 저장소의 데이터 항목과 직접 관련된 그래프(또는 가장자리 또는 관계)입니다. 이 관계를 통해 저장소의 데이터를 직접 연결할 수 있으며, 대부분의 경우 한번의 작업으로 검색됩니다.\n이는 관계형 데이터베이스 관리 시스템의 도움을 받아 물리적 기록 체인과 같은 구현 측면을 부과하지 않고 데이터를 관리할 수 있는 관계형 데이터베이스와는 대조됩니다. 관계형 쿼리의 실행은 데이터베이스의 논리적 구조를 수정하지 않고도 성능을 높일 수 있도록 하는 물리적 수준(예:인덱스 사용)의 데이터베이스 관리 시스템의 도움으로 가능합니다.\n그래프 데이터베이스는 의도적으로 관계형 시스템에서 모델링 하기 어려운 복잡한 계층 구조를 단순하고 신속하게 복원할 수 있도록 해 줍니다. 그래프 데이터베이스는 일반 그래프를 나타내는 1970년대의 네트워크 모델 데이터베이스와 유사하지만, 네트워크 모델 데이터베이스는 더 낮은 수준의 추상화[1]로 작동하고 쉽게 편집할 수 없습니다.\n그래프 데이터베이스의 기본 저장 메커니즘은 다를 수 있습니다. 일부는 관계형 엔진에 따라 다르며 표에 그래프 데이터를 \u0026ldquo;저장\u0026rdquo; 합니다(표는 논리적 요소이지만, 따라서 이 접근 방식은 그래프 데이터베이스, 그래프 데이터베이스 관리 시스템 및 실제 데이터가 저장된 물리적 장치 사이의 또 다른 수준 추상화를 부과합니다). 일부는 키 값 저장소 또는 문서 지향 데이터베이스를 사용하여 저장하기 때문에 기본적으로 NoSQL구조가 됩니다. 관계가 없는 스토리지 엔진에 기반하여 가장 많이[누구에게 기록하는가?]그래프 데이터베이스는 기본적으로 다른 문서에 대한 포인터를 가진 관계인 태그 또는 속성 개념을 추가하기도 합니다. 이를 통해 데이터 요소를 분류하여 일괄 검색이 용이하도록 할 수 있습니다.\n그래프 데이터베이스에서 데이터를 검색하려면 SQL이외의 쿼리 언어가 필요합니다. SQL은 관계형 시스템의 데이터를 조작하도록 설계되었으며, 따라서 그래프 이동을 \u0026quot; 우아하게\u0026quot;처리할 수 없습니다. 2017년 현재, SQL과 같은 방식으로 일반적으로 채택된 단일 그래프 쿼리 언어는 없으며, 가장 많이 하나의 제품에 밀접하게 연관된 다양한 시스템이 있다. 몇가지 표준화 작업이 이루어져 Gremlin, SPARpd및 Cypher와 같은 멀티 벤더 쿼리 언어가 발생했습니다. 쿼리 언어 인터페이스와 함께 일부 그래프 데이터베이스는 API(응용 프로그램 프로그래밍 인터페이스)를 통해 액세스 됩니다.\n먼저 간단하게 생각해보자. RDB의 탄생은 데이터를 적재하고 빠르게 조회하기 위해 탄생했다. 외래키와 같이 참조할 값을 넣어 JOIN, SubQuery, UNION 과 같은 기능으로 관계에 대해 질의할 수 있다. 하지만 이는 여러 ROW로 결과가 출력되며 서로 간의 관계를 보는 것에는 적합하지 않았다.\n하지만 GraphDB는 이와 다른 관점에서 시작한다. 각 데이터는 고도로 연결되어 있고 그래프로 표현된다. 엣지라는 점에 연결되는 링크로 각 데이터를 구조화한다. 역사적으로 오일러의 그래프 이론으로 부터 나왔다. 공대를 나왔으면 오일러 공식 등 오일러라는 분에게 친숙한 느낌이 올 것이다. 그리고 이름을 들어보지 않았더라도 그래프 이론의 시작에 대해서 보면 한 번쯤은 들어봤던 이론이라는 것을 깨달을 것이다.\n그래프 이론은 Königsberg Bridges 에서 시작되었다. 18세기에 다리를 중복하지 않고 모두 한 번씩 건너서 모든 다리를 건널 수 있을지 의문점을 가졌었다. 이는 가끔씩 볼 수 있는 한붓그리기와 같은 문제와 같은 것이었다. 이 문제를 풀기 위해서 단순화하는 과정이 필요하다. 육지를 연결해주는 다리를 Edge, 그리고 접점의 역할을하는 육지를 Ver-tex라고 한다. 한 접점에 연결되어 있는 다리의 수를 Degree라고 하는데, 홀수 Degree의 Ver-tex가 2개면 이 둘 접점이 시적점이거나 끝점이면 한붓그리기를 성공할 수 있다. 또한 모든 접점이 짝수 Degree를 갖을 때 한붓그리기가 가능하다.\n그런데 이게 도대체 왜 GraphDB와 관련이 있을까? 이는 그래프 구조를 보여준 단적인 예였다. GraphDB는 이런 Graph 구조에 대해서 저장하는 Database일 뿐이고, 기존에 RDB로 표현하기 어려웠던 각 데이터간의 연결점들을 이어주고 표현해주는데 용이할 뿐이다. 만일 이런 데이터 Edge의 경중을 RDB로 표현하려면 굉장히 지저분한 쿼리를 볼 것이다. 각 파라미터를 Count를 하고 가중치를 주기 위해 새로운 데이터 View를 생성하던지 Table을 생성하고 또 이와 관계를 맺는 Join을 해야하고, 쉽지 않을 것이다.\n하지만 이러한 데이터 간의 관계를 그래프형태로 표현해 줄 수 있는 GraphDB를 사용하면 달라진다.\n솔직히 번역을 하더라도 감이 잘 안온다. 그럼 그림으로 보자.\n다음 그림은 영화배우와 영화, 그리고 감독간의 연관관계를 표현한 것이다. 아름답지 않은가! 이렇게 연관관계가 표현될 수 있다니!\n고찰 이런 GraphDB는 페이스북, 카카오, Netflix 등등 많은 기업에서 도입하여 사용중이다. 사용하는 알고리즘은 조금씩 다를 때도 있지만 표현하고자 하는 목적들은 비슷하다. 만약 저걸 SQL로 표현한다고 생각해보자. 솔직히 상상도 되지 않는다. 굉장히 힘든 작업이 될 것으로 예상된다. 하지만 GraphDB와 함께라면 Visualizing부터해서 손쉽게 표현될 수 있다.\n물론 리스크는 존재한다.\nGraphDB에 대해서 처음에 공부해야 하는 Learning Curve는 기본적으로 가져야만 하며, GraphDB에 대해 자료가 많지 않기 때문에 운영상 이슈에 대해 처리하는 것이 쉽지 않을 것이다. 또한 기존에 Collecting하는 Data Type이 GraphDB에서 어떻게 표현될지 고민해야 한다.\n매일 쉽지 않은 선택을 한다. 새로운 공부를 시작하고 PoC를 진행하고, 실제 Production에 반영하기 전에 운영상의 이슈에 대해서 고민해본다. 그럼에도 불구하고 항상 같은 결론을 내린다. 도입해보는 것이다. 도입해보고 기존의 서비스와 느슨한 결합을 하도록 구성하여 문제시에는 바로 내릴 수 있도록 하는 것이다. 하나하나의 작은 경험이 나중에 큰 도약으로 이루어질 것이기 때문에 작은 시도도 끊임없이 해야 한다.\nGraphDB를 선택하는 것을 잠깐이나마 멈칫했지만, 한 번 해보려고 한다. 다음번에는 GraphDB 사용기에 대해서 포스팅해봐야겠다.\nReferences https://en.wikipedia.org/wiki/Graph_database https://neo4j.com/ ","permalink":"https://novemberde.github.io/post/2018/04/12/Neo4j/","summary":"Summary 각 사용자들의 연관 관계 분석을 위하여 GraphDB를 도입하려한다. 시작하기에 앞서서 GraphDB에 대해서 이해가 필요했다. 다음에서 GraphDB의 기본 내용을 담았다.\nGraph Database란? In computing, a graph database is a database that uses graph structures for semantic queries with nodes, edges and properties to represent and store data. A key concept of the system is the graph (or edge or relationship), which directly relates data items in the store. The relationships allow data in the store to be linked together directly, and in many cases retrieved with one operation.","title":"GraphDB 란?"},{"content":"문제인식 서비스가 성장해가면서 기존에는 보이지 않던 문제점들이 나타났다. 처음에는 Slow query의 최적화를 필요로하지도 않았고, DB에 부하가 몰려서 Bottle neck point가 되는 것을 상상만 했지 직접 경험하지는 못했었다. 하지만 점차 Query의 optimization이 필요한 경우가 생겼고, DB로 몰리는 부하를 분산하기 위해 어떻게 처리해야하는지 고민하기 시작했다.\nCache me if you can 다행히도 AWSKRUG활동을 하면서 AWS re:Invent행사에 참석한 경험이 도움이 되었다. 들었던 세션중에서 가장 감명깊은 것중에 하나는 \u0026ldquo;Cache me if you can\u0026quot;이었다. 주된 내용은 점차 서비스가 커져감에 따라서 우린 Database로 몰리는 부하를 분산시켜야만 하고, 그것을 해결하기 위해서는 각 요청에 따라 Cache로 처리할 수 있는 부분은 모두 Cache로 해결해야 된다는 내용이었다.\nhttps://www.youtube.com/watch?v=WFRIivS2mpo\nApicache를 사용하여 문제 해결하기 물론 현재도 AWS ElasticCache Service를 쓰고 있다. 그렇지만 최대한 활용하여 쓰고 있다고 생각하지는 않는다. Client에 응답을 빠르게하기 위해 Redis를 사용하는데, DB 스키마와 형식이 다르기 때문에 막상 적용하려하면 처음에는 당혹스럽다. 또한 여러 전처리 과정이 들어가기 때문에 뭔가 아름답게 정리되지도 않는다. 그럼에도 불구하고 Redis를 사용해야만 했다. 회원마다 빠르게 처리해야하는 개인화 정보도 다르며, 실시간으로 많은 요청을 처리해야되기 때문에 최대한 데이터 유실이 없는 범위 내에서는 Redis를 사용했다.\n그래도 이것만으로는 부족했다. 하나하나 이렇게 변환해서 사용하기도 귀찮고 페이지 단위로 각 웹서버에서 처리하는 것도 괜찮다고 생각했다. 굳이 Redis에서 데이터를 가져오지 않고 Local memory에서 처리하는게 더 빠를 것이라 생각했고, 그 데이터의 양은 서비스 구조상 크지 않기 때문이었다.\n또한 AWS Lambda를 활용하여 서비스를 하고 있기 때문에 일정 시간(30분 미만) 후에 Container가 내려가고 새로운 Container가 올라가는 형식으로 메모리 누수에 비교적 자유로운 형태의 아키텍쳐였다.\n그래서 Redis를 연동하지 않고 local cache를 이용하는 것을 선택했다. 만일 Redis를 더 연동하면 점점 Redis에 의존성이 증가하기 때문에 이를 피하기 위한 점도 있었다.\nnode.js로 서버를 구성하고 있었기 때문에 library를 찾아보았고 apicache라는 사용법이 간단한 라이브러리를 찾을 수 있었다. express.js에서 사용법은 다음과 같다.\nlet cache = require(\u0026#34;apicache\u0026#34;).middleware app.use(cache(\u0026#39;5 minutes\u0026#39;)) app.get(\u0026#39;/will-be-cached\u0026#39;, (req, res) =\u0026gt; { res.json({ success: true }) }) 적용 방법은 매우 간단하지만 결과는 차원이 다르게 나타났다. 이전 평균 응답시간은 120~250ms 내외였다면 현재 평균 응답시간은 20~ 50ms로 성능 향상을 할 수 있었다.\n실제로 어플리케이션의 응답이 빨라져 사용자들이 더욱 쾌적하게 사용하게 되었다.\n이뿐만 아니라 근본적으로 Cache를 도입하게 된 배경인 Database의 관점에서도 눈에 띄는 성능 변화가 나타났다. 자주 Database의 CPU사용율이 70%를 쉽게 초과하고 그것에 대응하기 위해 Database의 Instance type을 두 배의 성능으로 증가시켰던 것에 비해 현재는 기존의 Instance type만으로도 버틸 수 있다.\n고찰 서버개발자 또는 인프라엔지니어로만 일을 할 수도 있었다. 하지만 스타트업에서 일하다보니 웹개발, 어플리케이션 개발, DB tuninng, 인프라 관리 등등 할일이 너무 많았다. 처음에는 이런점이 아쉽기도 했다. \u0026lsquo;하나만 파도 모자를 판에 어떻게 여러 문제를 해결할까\u0026rsquo;라는 의문점이 들면서도 \u0026lsquo;모든게 다 경험이다\u0026rsquo;라고 생각하며 계속 문제를 해결하기 위한 방안들을 생각하고 잘 해결되지 않는 문제점에 대해서 방법을 바꿔가며 길을 찾았다.\n이것이 점점 쌓이다보니 다른 시각이 생겼다. Application 및 웹서버의 최적화를 진행하며 인프라에서만 해결하려는 것이 아닌 전방위적인 해결방법을 모색하게 되었다. 웹서버에 요청이 계속 몰리는 것을 보며 웹서버를 확장할 고민을 하기 전에 어떤 요청이 클라이언트에게 오는지 보고 Client에서 어지간한 요청에 대해서 캐싱한다던지, 아니면 정규식이 없는 곳이 정규식을 통해 적절한 요청만 서버에 올 수 있도록 수정하던지, 아니면 request queue를 통해 실시간성이 필요하지 않는 요청이나 반드시 필요한 데이터가 아닌 경우에는 시간을 두어 데이터를 한번에 보내던지, 다양한 방법을 통해 서버의 부하를 줄일 수 있었다.\n무작정 서버의 비용을 증가시키기 보다는 클라이언트에서 처리를 하고, 서버에서는 기본을 잘 지켜 Redis 및 ReadReplica를 활용하여 부하를 분산시키고, Monitoring의 습관화를 통해 이상 징후를 계속 확인하였다.\n이제는 문제가 발생하더라도 빠른 복구가 가능하며, 성능이 점점 최적화되어서 큰 문제없이 서비스가 운영되고 있다.\n지금처럼 엔터프라이즈급이 되는 상황을 상상하여 설계하여 큰부하가 몰리거나, 갑작스런 서비스의 성장에도 대비할 수 있도록 해야겠다.\nReferences https://www.npmjs.com/package/apicache https://www.youtube.com/watch?v=WFRIivS2mpo ","permalink":"https://novemberde.github.io/post/2018/03/01/Node_apicache/","summary":"문제인식 서비스가 성장해가면서 기존에는 보이지 않던 문제점들이 나타났다. 처음에는 Slow query의 최적화를 필요로하지도 않았고, DB에 부하가 몰려서 Bottle neck point가 되는 것을 상상만 했지 직접 경험하지는 못했었다. 하지만 점차 Query의 optimization이 필요한 경우가 생겼고, DB로 몰리는 부하를 분산하기 위해 어떻게 처리해야하는지 고민하기 시작했다.\nCache me if you can 다행히도 AWSKRUG활동을 하면서 AWS re:Invent행사에 참석한 경험이 도움이 되었다. 들었던 세션중에서 가장 감명깊은 것중에 하나는 \u0026ldquo;Cache me if you can\u0026quot;이었다. 주된 내용은 점차 서비스가 커져감에 따라서 우린 Database로 몰리는 부하를 분산시켜야만 하고, 그것을 해결하기 위해서는 각 요청에 따라 Cache로 처리할 수 있는 부분은 모두 Cache로 해결해야 된다는 내용이었다.","title":"NODE response를 apicache로 처리하기"},{"content":"Summary AWS Lambda와 API Gateway를 연동하여 웹서버를 Serverless architecture로 운영하고 있다. 관리할 서버가 없고 비지니스 로직에만 집중할 수 있어서 좋기도 하지만 항상 Lambda container가 대기중인 상태가 아니다 보니 Cold start관련하여 요청사항이 발생했다.\n일정시간이 경과된 후에 해당 페이지를 접속할 경우에 로딩이 3~4초이상 걸리기 때문에 사용이 불편하였다. 이를 해결하기 위해 5분마다 각 api를 health check하는 scheduler를 두기로 결정하였다. 그렇게되면 지속적인 lambda 호출로 인해 항상 하나이상의 lambda container가 대기하는 형태가 되어 lambda의 cold start의 가장 큰 시간을 소비하는 DB connection의 시간을 느낄 수 없다.\n먼저 현재 사용하는 웹서버가 5개라고 하고, heathCheck는 비지니스 로직을 통과하지 않고 빠른 응답을 하기 때문에 처음에는 300ms에 응답한다고 가정하려하였다. 그런데 5분에 한 번씩 모든 api를 호출하고, 돌아오는 응답의 시간이 대략적으로 2초정도 걸렸다.\n무엇인가 이상하다고 생각하였다.\n단순한 request인데 몇번하였다고 2초가 걸리는 건 코드상의 오류라고 생각되었다. 이때 Go lang을 활용하였는데, 익숙치 않다보니 실수가 있었다.\n기존의 node로 개발했을 때는 Promise.all 패턴으로 비동기 작업을 한번에 보냈었지만, go로 생각없이 짜다보니 request하고 응답하고 request하고 응답하고 이런식으로 여러번하다보니 전체적인 시간이 늘어났다. 얼마되진 않지만 이 때문에 비용이 4배 이상으로 올라가서 Gorutine를 사용하여 처리하였다.\n동시에 요청을 보내고 전부 response를 받으면 lambda가 종료하는 방식이다. 기존에는 2초가 걸렸지만 현재는 1.5초로 실행시간을 감소시켰다. 빠른 때는 1초도 걸리지 않는다.\n비용 계산하기 위 테스트를 기반으로 https://s3.amazonaws.com/lambda-tools/pricing-calculator.html에서 참고하여 비용을 측정하였다.\nNumber of Executions: 5 * 12(시간당 호출수) * 24 * 30 = 43200 Memory: 단순 로직이기 때문에 128MB로 선정 Estimated Execution Time (ms): 1500ms Include Free Tier: no TOTAL COSTS Request Costs: $0.01 Execution Costs: $0.14 $0.14/month 계산에 따르면 한달에 200원 정도선에서 모든 api를 Healthy상태로 둘 수 있다.\n현재 가격은 최대로 계산한 것이고 Lambda의 메트릭을 살펴보면 비용은 좀 더 낮게 책정될 것을 예상할 수 있다. 보통은 1초 내외로 끝나기 때문이다.\n고찰 본격적으로 go언어를 사용하기로 마음을 먹고 이번에 실제로 적용해본 것은 처음이다. 기존에 스크립트 언어에 익숙했기 때문에 적응은 쉽게 되지 않았다. 기본적으로 스크립트 언어는 async한 로직을 쉽게 넣었지만 compile언어를 오랜만에 써보니 비동기 작업을 다르게 구현하는 점이 새로웠다. 물론 JAVA에서 Thread를 통해 비동기 작업을 처리하기도 했지만 gorutine을 통해 로직을 구현해보니 상당히 golang이 매력적인 녀석이라는 것을 깨달았다.\nJava처럼 각 request 마다 thread를 생성하지 않고 gorutine의 channel을 통한 방식이 아직은 낯설기도 하지만 점차 적응해나갈 것으로 보인다.\n그리고 node를 사용한 serverless deploy는 바로 소스코드를 업로드하는 방식이었지만 go는 해당 application을 Makefile 을 통해 빌드하고 bin 디렉터리만 serverless deploy를 하는 형식이었다. 이것은 go가 컴파일 언어이기 때문에 컴파일된 binany형태의 파일만으로 동작하기 때문이다.\n왜 기존에 잘 쓰던 node를 두고 golang으로 작성하였는지 물어본다면 performance에 대한 욕구가 나날이 증가하기 때문이다. 현재 서비스가 성장해감에 따라서 web-application의 성능의 차이가 느껴지기 시작했다. node는 결국 script언어이기 때문에 compile 언어와 차이가 날 수 밖에 없기 때문이다. 그렇다고 java를 사용하기엔 lambda에 jvm이 얹혀가는 구조이기 때문에 무겁게 동작해서 사용할 수가 없었다.\ngo언어를 점차 사용해서 모든 프로덕션에 적용하는게 목표이지만 언제 이룰 수 있을진 잘 모르겠다.\nReferences https://s3.amazonaws.com/lambda-tools/pricing-calculator.html ","permalink":"https://novemberde.github.io/post/2018/02/02/Lambda_coldStart/","summary":"Summary AWS Lambda와 API Gateway를 연동하여 웹서버를 Serverless architecture로 운영하고 있다. 관리할 서버가 없고 비지니스 로직에만 집중할 수 있어서 좋기도 하지만 항상 Lambda container가 대기중인 상태가 아니다 보니 Cold start관련하여 요청사항이 발생했다.\n일정시간이 경과된 후에 해당 페이지를 접속할 경우에 로딩이 3~4초이상 걸리기 때문에 사용이 불편하였다. 이를 해결하기 위해 5분마다 각 api를 health check하는 scheduler를 두기로 결정하였다. 그렇게되면 지속적인 lambda 호출로 인해 항상 하나이상의 lambda container가 대기하는 형태가 되어 lambda의 cold start의 가장 큰 시간을 소비하는 DB connection의 시간을 느낄 수 없다.","title":"AWS Lambda에서의 Cold Start 문제 해결하기(Golang + serverless framework)"},{"content":"Summary MySQL에서 Max Connection에 대해서 알아보려고 한다. AWS Lambda container가 지속적으로 생성될 때 Database가 감당할 수 있는 Max connection이 얼마인지 알아야 대응할 수 있기 때문이다. 만약 Lambda container가 MySQL이 감당할 수 없을 정도로 계속 생성된다면 Database에 connection이 일어나지 않게 되고, too many connections error가 발생하여 웹서버 역할을 해야하는 Lambda가 동작하지 않을 수 있다. 물론 MySQL에 접속하는 다른 Worker들도 동작하지 않는다.\nRDS를 사용하면 스케일 업이 될 때마다 Max connection 설정을 따로 하지 않더라도 알아서 늘어난다. 별다른 고민할 것 없이 Max connection이 생길 때마다 RDS를 scale up 해주어도 되겠지만 개발자이기 때문에 더 Graceful하게 문제를 해결해야한다.\nMySQL에서 max connection 확인하기 MySQL에서 max connection을 확인하는 쿼리는 다음과 같다.\nshow variables like \u0026#39;max_connections\u0026#39;; 그리고 RDS instance type에 따른 max_connections는 다음과 같다.\n2.micro: 66 t2.small: 150 m3.medium: 296 t2.medium: 312 M3.large: 609 t2.large: 648 M4.large: 648 M3.xlarge: 1237 R3.large: 1258 M4.xlarge: 1320 M2.xlarge: 1412 M3.2xlarge: 2492 R3.xlarge: 2540 Amazon Aurora의 instance type에 따른 max_connections는 다음과 같다.\ndb.t2.small: 45 db.t2.medium: 90 db.r3.large: 1000 db.r3.xlarge: 2000 db.r3.2xlarge: 3000 db.r3.4xlarge: 4000 db.r3.8xlarge: 5000 db.r4.large: 1000 db.r4.xlarge: 2000 db.r4.2xlarge: 3000 db.r4.4xlarge: 4000 db.r4.8xlarge: 5000 db.r4.16xlarge: 6000 사용하는 Persistance framework의 Connection pool size알기 WebApp 또는 Worker에서 동작하는 connection pool 옵션을 확인하고 RDS가 사용되는 max_connection의 수를 나누면 대략적으로 Concurrency하게 동작하는 개수를 알아낼 수 있다.\n그 다음 Lambda의 옵션 중 concurrency 옵션을 수정하면 된다.\n고찰 현재 업무에서 사용하는 모든 웹앱이 AWS Lambda에서 동작하고 있다. 점점 사용자가 늘어감에 따라 가끔 설계해놓은 스펙 이상으로 부하가 몰릴 경우가 있다. Lambda에서 Timeout이 빈번하게 발생할 경우 timeout되기 전 상태의 lambda가 계속 생성되어 순간적으로 RDS의 connection에 문제가 생겼었다. 물론 Lambda timeout을 큰 고찰없이 10초 이상으로 설정해 놓을 수도 있다. 예를 들어, 10초 사이에 많은 요청이 생긴다고 가정해보자. rds는 (컨테이너의 수*connection pool수)만큼 connection을 맺는데, timeout으로 끝나는 컨테이너가 많아질수록 RDS의 max_connections옵션을 초과하여 too many connections error를 내뿜게 된다. 결과적으로 클라이언트들은 원하는 상태를 처리하기 위해 지속적인 요청을 보낼 것이고 RDS는 CPU 100%로 클라이언트가 진정될 때까지 계속 힘들어할 것이다.\n이런 문제점 때문에 Timeout도 길게 설정하지 말고 4~8초 내외로 잡는 것이 낫다. 물론 배치잡같은 경우를 제외하고 말이다. 이렇게 되면 어느정도 too many connections error를 잡는데 도움을 준다.\n그렇지만 무엇보다 비지니스 로직에서 최적화를 잘 시켜서 timeout상태를 만들지 않는게 중요할 것이다.\n2019-12-22 업데이트 최근에 RDS Proxy라는 것이 릴리즈되었다. 이는 RDS의 Connection Pool을 제공하고 API를 통해 RDS에 접근한다. 기존의 Serverless Architecture에서 힘들게 한 Max Connection 문제에 대해서 해결하기 쉽게 해준다. 현재는 MySQL만 지원하면 다른 유형의 데이터베이스는 추후에 지원될 예정이다.\n해당 내용은 여기(https://aws.amazon.com/ko/rds/proxy/)서 확인할 수 있다.\n","permalink":"https://novemberde.github.io/post/2018/01/29/Mysql_maxConnection/","summary":"Summary MySQL에서 Max Connection에 대해서 알아보려고 한다. AWS Lambda container가 지속적으로 생성될 때 Database가 감당할 수 있는 Max connection이 얼마인지 알아야 대응할 수 있기 때문이다. 만약 Lambda container가 MySQL이 감당할 수 없을 정도로 계속 생성된다면 Database에 connection이 일어나지 않게 되고, too many connections error가 발생하여 웹서버 역할을 해야하는 Lambda가 동작하지 않을 수 있다. 물론 MySQL에 접속하는 다른 Worker들도 동작하지 않는다.\nRDS를 사용하면 스케일 업이 될 때마다 Max connection 설정을 따로 하지 않더라도 알아서 늘어난다.","title":"AWS Lambda와 MySQL의 max connection 문제"},{"content":"Summary \u0026ldquo;ECS와 Fargate\u0026quot;라는 주제로 2018년 1월 20일에 AWSKRUG re:Invent recap 행사에서 발표한 자료입니다.\n발표자료 ECS/Fargate와 함께하는 간편한 Docker 사용법 - 트랙2, Community Day 2018 re:Invent 특집 from AWS Korea UserGroup (AWS한국사용자모임) 발표 영상 데모로 시연한 샘플코드는 아래와 같습니다. https://github.com/novemberde/aws-fargate-demo References https://www.slideshare.net/awskr/ecs-fargate-2018 https://www.meetup.com/ko-KR/awskrug/events/245940818/ https://github.com/novemberde/aws-fargate-demo ","permalink":"https://novemberde.github.io/post/2018/01/20/ECS_Fargate/","summary":"Summary \u0026ldquo;ECS와 Fargate\u0026quot;라는 주제로 2018년 1월 20일에 AWSKRUG re:Invent recap 행사에서 발표한 자료입니다.\n발표자료 ECS/Fargate와 함께하는 간편한 Docker 사용법 - 트랙2, Community Day 2018 re:Invent 특집 from AWS Korea UserGroup (AWS한국사용자모임) 발표 영상 데모로 시연한 샘플코드는 아래와 같습니다. https://github.com/novemberde/aws-fargate-demo References https://www.slideshare.net/awskr/ecs-fargate-2018 https://www.meetup.com/ko-KR/awskrug/events/245940818/ https://github.com/novemberde/aws-fargate-demo ","title":"ECS \u0026 Fargate Demo"},{"content":"Summary 우리는 매일 각 웹사이트를 확인하여 뉴스를 취합한다. 별다른 요구사항 없이 직접 업무를 진행하시지만 이건 자동화해야된다는 생각이 들었다. 하루에 한 번 이뤄지는 일이니 주기적으로 슬랙에 최신 뉴스를 보내도록 자동화한다면 업무의 작은 시간도 아낄 수 있을 것이다. 그래서 이번에 크롤링 자동화 방법에 대해서 정리하려고 한다.\nServerless framework를 활용하면 빠른 배포 및 관리가 가능하니 기술 스택을 다음과 같이 정했다.\nAWS Lambda: javascript로 작성. got, cheerio를 사용하여 crawler 설계 got: Request 모듈. 우리나라에는 많이 알려져있지 않지만 해외에서는 주로 got을 사용. npm에서 download 수가 압도적으로 많다. 사용법이 간단하다. cheerio: jQuery형식으로 서버에서 사용하는 모듈 AWS CloudWatch: 주기적으로 Lambda 함수를 실행하기 위함 Serverless framework: 내부적으로 Serverless Application Model 파일을 생성하여 CloudFormation으로 배포하는 것을 자동화 Slack bot: 정해진 시간이 지나고 다시 뉴스정보를 불러오고 싶을 때 사용한다. Lambda를 trigger하는 방법으로 사용 개발 환경 설정 이 과정은 npm version 5 이상을 사용하고 있다고 가정하고 시작한다. 만일 사용하고 있지 않다면 npm install -g npx 를 실행한다. npx는 해당 패키지 내에서 node_modules/.bin에 있는 명령어를 바로 사용할 수 있게 해준다.\n프로젝트 디렉터리를 생성하고 node project로 초기화한다.\n$ mkdir lambda-crawler-demo $ cd lambda-crawler-demo $ npm init -y 해당 프로젝트에 필요한 패키지를 설치한다.\n$ npm i -D serverless 위에서 serverless package를 Global로 설치하지 않고 dev-dependency에 넣는 이유는 나중에 다른 작업환경에서도 Serverless의 버전을 명확하게 하기 위함이다. 그렇지 않으면 1, 2년이 지난 후에는 환경이 달라져 Global로 설치했던 Serverless 버전을 찾아야한 하기 때문이다.\nServerless framework의 개발환경을 설정한다.\n# app이라는 디렉터리에 aws-nodejs의 템플릿을 기본으로 생성한다. $ npx serverless create --template aws-nodejs --path app serverless.yml이라는 파일을 다음과 같이 편집한다.\nservice 명: my-crawler stage: dev region: us-east-1 [app/serverless.yml] service: my-crawler provider: name: aws runtime: nodejs6.10 stage: dev region: us-east-1 profile: my-service memorySize: 128 functions: crawler: handler: handler.crawler events: - schedule: rate(1 day) handler.js를 다음과 같이 편집한다.\n[app/handler.js] \u0026#39;use strict\u0026#39;; module.exports.crawler = (event, context, callback) =\u0026gt; { const response = { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Go Serverless v1.0! Your function executed successfully!\u0026#39;, input: event, }), }; callback(null, response); } 이제부터 모든 작업은 app 디렉터리에서 한다. serverless로 deploy를 하기 위해선 사전에 AWS Command line interface가 설치되어 있고 IAM user를 생성하여 등록해야한다. 아직 하지 않았다면 여기를 참고하여 설정한다.\n그리고 위에서 profile 설정을 해주었는데 기본적으로 aws configure로 설정하면 여러 service account을 매번 설정해주어야 하기 때문에 aws configure \u0026ndash;profile [profile-name] 으로 설정하여 여러 계정 정보를 가지고 있는 경우에도 문제없이 작업할 수 있도록 한다.\n비지니스 로직을 작성하기 전에 배포가 되는지 확인한다.\n$ npx serverless deploy 배포가 다 되었다면 Lambda 콘솔로 이동하여 다음과 같이 나타나는지 확인한다.\nCloudWatch Events가 있다면 정상적으로 배포가 된 것이다. 주기적으로 실행하기 위해 CloudWatch Event를 사용한다.\nCrawler 작성하기 크롤링 개요는 다음과 같다.\ngot을 사용하여 네이버 메인에 있는 뉴스 5개를 가져온다. cheerio를 사용해서 해당 DOM을 찾아낸다. 크롤링된 데이터를 Slack에 보낸다. 현재 디렉터리에 모듈을 설치한다\n[app/] $ npm init -y $ npm i cheerio got got의 사용법은 다음과 같다.\nconst got = require(\u0026#39;got\u0026#39;); got(\u0026#39;https://www.naver.com\u0026#39;).then(res =\u0026gt; { console.log(res.body); }); got(\u0026#34;POST_URL\u0026#34;, { method: \u0026#34;post\u0026#34;, body: JSON.stringify({text: \u0026#34;hi\u0026#34;}) }, () =\u0026gt; { }) got과 cheerio를 모두 사용하면 다음과 같다.\n네이버 메인 뉴스를 가져온다.\nconst got = require(\u0026#39;got\u0026#39;); const cheerio = require(\u0026#39;cheerio\u0026#39;); got(\u0026#39;https://www.naver.com\u0026#39;).then(res =\u0026gt; { $ = cheerio.load(res.body); const result = $(\u0026#39;.ca_item .ca_a\u0026#39;); console.log(result.text()); }); 이제 크롤링을 했으니 Slack으로 내용을 보내본다.\nSlack에 원하는 채널에 들어가서 Add an app을 클릭한다.\nIncoming WebHooks의 설정으로 들어가서 Webhook URL을 복사하여 저장해둔다.\nslack 설정은 모두가 다를 수 있으니 다음과 같이 파일을 작성한다.\n[app/slack.config.json] { \u0026#34;URL\u0026#34;: \u0026#34;Paste your slack url\u0026#34; } 거의 다 왔다. 이제 handler.js를 다음과 같이 편집해준다.\n[app/handler.js] \u0026#39;use strict\u0026#39;; const got = require(\u0026#39;got\u0026#39;); const cheerio = require(\u0026#39;cheerio\u0026#39;); const SLACK_URL = require(\u0026#39;./slack.config.json\u0026#39;).URL; module.exports.crawler = (event, context, callback) =\u0026gt; { let result; return got(\u0026#39;https://www.naver.com\u0026#39;).then(res =\u0026gt; { const $ = cheerio.load(res.body); result = $(\u0026#39;.ca_item .ca_a\u0026#39;); return got(SLACK_URL, { method: \u0026#34;post\u0026#34;, body: JSON.stringify({text: result.text()}) }); }).then(() =\u0026gt; { const response = { statusCode: 200, body: JSON.stringify({ message: result.text(), }), }; callback(null, response); }); } 이제 배포하면 매일 주기적으로 슬랙 알람이 올 것이다.\n$ npx serverless deploy 삭제하기 한 번 배포해봤으니 삭제하여 과금되지 않도록 한다.\n$ serverless remove References https://serverless.com/ https://ko.wikipedia.org/wiki/%ED%86%A0%EC%96%B4 https://github.com/novemberde/lambda-crawler-demo https://www.npmjs.com/package/got https://www.npmjs.com/package/cheerio ","permalink":"https://novemberde.github.io/post/2017/12/31/Node-crawler/","summary":"Summary 우리는 매일 각 웹사이트를 확인하여 뉴스를 취합한다. 별다른 요구사항 없이 직접 업무를 진행하시지만 이건 자동화해야된다는 생각이 들었다. 하루에 한 번 이뤄지는 일이니 주기적으로 슬랙에 최신 뉴스를 보내도록 자동화한다면 업무의 작은 시간도 아낄 수 있을 것이다. 그래서 이번에 크롤링 자동화 방법에 대해서 정리하려고 한다.\nServerless framework를 활용하면 빠른 배포 및 관리가 가능하니 기술 스택을 다음과 같이 정했다.\nAWS Lambda: javascript로 작성. got, cheerio를 사용하여 crawler 설계 got: Request 모듈. 우리나라에는 많이 알려져있지 않지만 해외에서는 주로 got을 사용.","title":"Serverless + AWS Lambda + AWS CloudWatch + Slack 를 활용한  Web crawler 만들기"},{"content":"Summary Javascript WebView로 특정 URL의 컨텐츠를 보여주는데 화면이 나오지 않았다. 현상은 배경색까지 나타나고 DOM이 뿌려지지 않는 문제였다. Webview에서 Unexpected token의 에러를 뿜었기 때문에 쉽게 Javascript 관련 오류라는 것을 알 수 있었고 Javascript error를 무시할 수 있도록 하는 메서드를 실행하였다.\nWebview의 Setting에 setDomStorageEnabled(true)를 추가하기 기존의 코드는 다음과 같다\npublic class MyWebView extends AppCompatActivity { private WebView webView; @Override protected void onCreate(Bundle savedStateInstance){ super.onCreate(savedStateInstance); setContentView(R.layout.webview); webView = ( WebView )findViewById( R.id.webview); webView.getSettings().setRenderPriority(WebSettings.RenderPriority.HIGH); webView.setWebViewClient(new WebViewClient()); webView.setWebChromeClient(new WebChromeClient()); webView.setNetworkAvailable(true); webView.getSettings().setJavaScriptEnabled(true); webView.loadUrl(url); } } 변경한 코드는 다음과 같다.\npublic class MyWebView extends AppCompatActivity { private WebView webView; @Override protected void onCreate(Bundle savedStateInstance){ super.onCreate(savedStateInstance); setContentView(R.layout.webview); webView = ( WebView )findViewById( R.id.webview); webView.getSettings().setRenderPriority(WebSettings.RenderPriority.HIGH); webView.setWebViewClient(new WebViewClient()); webView.setWebChromeClient(new WebChromeClient()); webView.setNetworkAvailable(true); webView.getSettings().setJavaScriptEnabled(true); //// Sets whether the DOM storage API is enabled. webView.getSettings().setDomStorageEnabled(true); //// webView.loadUrl(url); } } 요즘에는 Front Web Framework에서 DOM을 관리하기 때문에 HTML이 아닌 Javascript로 DOM을 뿌려주게 된다.\n그렇게 되는 경우에 Javascript에 에러가 나서 Javascript로 생성된 모든 DOM객체를 뿌려주지 않는다면 아무런 화면을 확인할 수 없다.\n그렇기 때문에 DomStorage를 Enable해야 에러가 생긴 지점까지 나온 DOM 객체를 뿌려주기 때문에, 기존의 웹사이트에서 보는 것을 Webview에서도 확인할 수 있다.\nReferences https://developer.android.com/reference/android/webkit/WebSettings.html ","permalink":"https://novemberde.github.io/post/2017/12/19/Android-Webview/","summary":"Summary Javascript WebView로 특정 URL의 컨텐츠를 보여주는데 화면이 나오지 않았다. 현상은 배경색까지 나타나고 DOM이 뿌려지지 않는 문제였다. Webview에서 Unexpected token의 에러를 뿜었기 때문에 쉽게 Javascript 관련 오류라는 것을 알 수 있었고 Javascript error를 무시할 수 있도록 하는 메서드를 실행하였다.\nWebview의 Setting에 setDomStorageEnabled(true)를 추가하기 기존의 코드는 다음과 같다\npublic class MyWebView extends AppCompatActivity { private WebView webView; @Override protected void onCreate(Bundle savedStateInstance){ super.onCreate(savedStateInstance); setContentView(R.layout.webview); webView = ( WebView )findViewById( R.id.webview); webView.getSettings().setRenderPriority(WebSettings.RenderPriority.HIGH); webView.","title":"Android Webview에서 Javascript에러로 인해 뷰가 안나올 경우"},{"content":"Summary \u0026ldquo;Docker와 DevOps에서 Serverless와 NoOps로의 여정\u0026quot;이라는 주제로 2017년 12월 06일에 W3C Conference에서 발표한 자료입니다.\nDocker와 DevOps에서 Serverless와 NoOps로의 여정 from Kyuhyun Byun 데모로 시연한 샘플코드는 아래와 같습니다. https://github.com/novemberde/serverless-webapp-demo References https://www.slideshare.net/KyuhyunByun1/docker-devops-serverless-noops https://onoffmix.com/event/119375 https://github.com/novemberde/serverless-webapp-demo ","permalink":"https://novemberde.github.io/post/2017/12/06/Docker-to-serverless/","summary":"Summary \u0026ldquo;Docker와 DevOps에서 Serverless와 NoOps로의 여정\u0026quot;이라는 주제로 2017년 12월 06일에 W3C Conference에서 발표한 자료입니다.\nDocker와 DevOps에서 Serverless와 NoOps로의 여정 from Kyuhyun Byun 데모로 시연한 샘플코드는 아래와 같습니다. https://github.com/novemberde/serverless-webapp-demo References https://www.slideshare.net/KyuhyunByun1/docker-devops-serverless-noops https://onoffmix.com/event/119375 https://github.com/novemberde/serverless-webapp-demo ","title":"Docker와 DevOps에서 Serverless와 NoOps로의 여정"},{"content":"Summary Amazon EC2의 설정을 자동으로 하기 위해선 인스턴스의 정보를 받아와서 설정할 수 있어야 한다.\n예를 들어 특정 태그로 묶인 그룹에게 재가동시 소스코드 갱신과 서버 재가동의 명령어를 init.d에 등록했을 때 인스턴스 정보를 얻어온다면 개별적으로 인스턴스의 역할에 맞는 work load를 할당할 수 있을 것이다.\nmeta-data 확인하기 Metadata에 대해서 찾아보니 위키백과에 아래와 같이 쓰여 있었다.\n메타데이터(metadata)는 데이터(data)에 대한 데이터이다. 이렇게 흔히들 간단히 정의하지만 엄격하게는, Karen Coyle에 의하면 \u0026ldquo;어떤 목적을 가지고 만들어진 데이터 (Constructed data with a purpose)\u0026ldquo;라고도 정의한다. 가령 도서관에서 사용하는 서지기술용으로 만든 것이 그 대표적인 예이다. 지금은 온톨로지의 등장과 함께 기계가 읽고 이해할 수 있는 (Machine Actionable)한 형태의 메타데이터가 많이 사용되고 있다. 이 뜻을 인스턴스에 대입해보면, 인스턴스에 대한 데이터라고 생각해볼 수 있다.\n여기에는 인스턴스가 가지고 있는 intance-id값과 같이 인스턴스의 특성을 알 수 있는 값들이 있을 것이다.\n아래와 같이 예제를 통해 인스턴스의 Meta-data를 받아 본다.\n169.254.169.254 라는 IP는 인스턴스의 정보를 받아 볼 수 있는 IP이다. 이 IP를 통해 정보를 받는다.\n$ curl http://169.254.169.254/latest/meta-data/ ami-id ami-launch-index ami-manifest-path block-device-mapping/ hostname instance-action instance-id instance-type local-hostname local-ipv4 mac metrics/ network/ placement/ profile public-hostname public-ipv4 public-keys/ reservation-id security-groups services/ # 인스턴스의 ami id $ curl http://169.254.169.254/latest/meta-data/ami-id ami-ccccccccc # 인스턴스의 Security group $ curl http://169.254.169.254/latest/meta-data/security-groups my-security-group1 my-security-group2 # 인스턴스의 Role 정보 $ curl http://169.254.169.254/latest/meta-data/iam/info { \u0026#34;Code\u0026#34; : \u0026#34;Success\u0026#34;, \u0026#34;LastUpdated\u0026#34; : \u0026#34;2017-11-05T13:34:37Z\u0026#34;, \u0026#34;InstanceProfileArn\u0026#34; : \u0026#34;arn:aws:iam::111111111:instance-profile/my-instance-role\u0026#34;, \u0026#34;InstanceProfileId\u0026#34; : \u0026#34;AAAAAAAAAAAAAA\u0026#34; } 고찰 지금까지 인스턴스의 정보를 받아보았다. 169.254.169.254에 get 요청을 하면 받는 인스턴스 정보를 특정하여 받아볼 수 있는데, 이는 활용하는 사람에 따라 다양하게 적용할 수 있을 것이다.\n먼저 Security Group의 정보를 받을 경우에는 인스턴스가 가동할 때 원하는 Security-Group이 할당여부를 확인할 수 있을 것이다. 또한 Role 을 받아오면 인스턴스의 역할을 명확히 알 수 있기 때문에, 인스턴스의 소스코드를 갱신하여 인스턴스가 재시작 될 때마다 동작해야 할 명령어들을 구분지을 수 있다.\n다른 활용 방법을 간단하게 구상해보자. 특정 S3에는 스크립트 파일들을 모아두고 role과 파일명을 일치해둔다. 그리고 AMI를 만드는데 내용은 다음과 같다. 가동될 때 meta-data로 role정보를 받아오면 role과 일치하는 S3버킷의 파일을 받아와 shell 또는 python 등 자신이 자신있는 script로 실행한다. script가 실행되면 각 인스턴스의 역할에 맞는 서버가 가동된다.\n이런 식으로 설정을 한다면 Scaling Group이 Scale out이 될 때 큰 걱정없이 배포용 코드로 서버들이 가동될 수 있을 것이다.\nReferences https://ko.wikipedia.org/wiki/%EB%A9%94%ED%83%80%EB%8D%B0%EC%9D%B4%ED%84%B0 http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ec2-instance-metadata.html ","permalink":"https://novemberde.github.io/post/2017/11/06/Instance_metadata/","summary":"Summary Amazon EC2의 설정을 자동으로 하기 위해선 인스턴스의 정보를 받아와서 설정할 수 있어야 한다.\n예를 들어 특정 태그로 묶인 그룹에게 재가동시 소스코드 갱신과 서버 재가동의 명령어를 init.d에 등록했을 때 인스턴스 정보를 얻어온다면 개별적으로 인스턴스의 역할에 맞는 work load를 할당할 수 있을 것이다.\nmeta-data 확인하기 Metadata에 대해서 찾아보니 위키백과에 아래와 같이 쓰여 있었다.\n메타데이터(metadata)는 데이터(data)에 대한 데이터이다. 이렇게 흔히들 간단히 정의하지만 엄격하게는, Karen Coyle에 의하면 \u0026ldquo;어떤 목적을 가지고 만들어진 데이터 (Constructed data with a purpose)\u0026ldquo;라고도 정의한다.","title":"EC2 meta data에 대해 알아보기"},{"content":"Summary Node JS의 라이브러리가 워낙 많다보니 자주쓰는 라이브러리를 정리해야될 필요성을 느꼈다.\n그리고 재밌는 라이브러리를 리스트로 관리하지 않다보니 잊게 되었다.\n발견할 때마다 정리하고 라이브러리의 용도에 맞게 분류하여 나중에 필요할 경우 바로 사용할 수 있도록 한다.\n자주 쓰는 패키지 JavaScript utility library\nunderscore lodash Year, month, date, time\nmoment.js MarkDown\nhighlight.js prismjs Ajax\nrequest request-promise superagent axios got Test\nmocha supertest chai should enzyme Logger\nmorgan Task Runner \u0026amp; Bundler\ngulp grunt webpack webpack-dashboard Database\nsequelize graphql-sequelize sequelize-cli mongodb mongoose AdminMongo waterline sails-mongo redis cassandra-driver realm oracledb mssql tedious pg-hstore influx mysql2 sqlite3 elasticsearch http-aws-es Framework\nsails loopback express connect fastify js-data vuejs micro next.js serverless Parser \u0026amp; Data binding\nuseragent redux flux Express Middle ware\ncors body-parser cookie-parser cookie-session compression csurf errorhandler method-override multer response-time serve-favicon serve-index serve-static session timeout vhost connect-rid connect-image-optimus express-debug express-partial-response express-simple-cdn express-slash express-stormpath express-uncapitalize helmet join-io passport static-expiry view-helpers sriracha-admin apicache: Api 호출에 대한 캐싱 SDK\naws alexa cognito google paypal auth0 slack firebase dropbox React\nreact react-dom react-router react-redux react-hot-loader create-react-app create-react-kotlin-app semantic-ui-react react-static react-native react-pwa react-json-tree preact pepperoni-app-kit React boilerplate. ant-design-pro UI\negjs-flicking egjs-axes egjs-visible egjs-infinitegrid picturefill Node.js native addon build tool\nnode-gyp Crypto\nscrypt bcrypt bcryptjs crypto-js node-forge TAR and ZIP archives\narchiver Create uuid\nuuid Socket\nsocket.io socket.io-client ws socket.io-redis A simple visual editor for creating commutative diagrams\ntikzcd-editor Chart\nFrappé Charts billboard.js Design Block\nfroala Drag and drop behaviour\ndraggable An opinionated code formatter\nprettier Flash OS images to SD cards \u0026amp; USB drives, safely and easily.\netcher Markup language for building responsive email.\nheml Image-to-Image Translation with Conditional Adversarial Nets\npix2pix OCR\nocr Uplod\nuppy Ip to Geolocation\ngeoip-lite geoip2 DynamoDB\ndynamoose vogels Child_process\nexeca Image resizer\nsharp Headless browser\npuppeteer Hackable console logger\nsignale Presentations from your Markdown files.\nreveal-md Fake data in the browser and node.js\nfaker.js A browser based code editor\nmonaco-editor Tesla Model S node.js apps and javascript libraries using Tesla\u0026rsquo;s HTTP interfaces\nteslams Game server framework\ncolyseus wscat\nguppy\nnode-fetch\nCodeceptJS\nclipboard.js\naws-amplify/amplify-js\ncommanderjs\ndel\nSkeleton\nNode.js Best Practices\nFront-End Checklist\nAirbnb JavaScript Style Guide\nDeveloper-roadmap\nhttps://devhints.io/\n","permalink":"https://novemberde.github.io/post/2017/11/05/Node.JS_Library/","summary":"Summary Node JS의 라이브러리가 워낙 많다보니 자주쓰는 라이브러리를 정리해야될 필요성을 느꼈다.\n그리고 재밌는 라이브러리를 리스트로 관리하지 않다보니 잊게 되었다.\n발견할 때마다 정리하고 라이브러리의 용도에 맞게 분류하여 나중에 필요할 경우 바로 사용할 수 있도록 한다.\n자주 쓰는 패키지 JavaScript utility library\nunderscore lodash Year, month, date, time\nmoment.js MarkDown\nhighlight.js prismjs Ajax\nrequest request-promise superagent axios got Test\nmocha supertest chai should enzyme Logger\nmorgan Task Runner \u0026amp; Bundler\ngulp grunt webpack webpack-dashboard Database","title":"Node js 라이브러리 및 유용한 자료"},{"content":"Summary 최근에 직방의 AWS Lambda 코드를 세미나에서 스쳐지나가는 것을 보았다. TypeScript로 짜여져 있었고 나중에 지속적인 프로젝트 관리적인 이점이 있을 것으로 생각이 되기 때문에 TypeScript로 프로젝트를 구성해보는 것을 정리해보기로 결심했다.\nnode.js 프로젝트 생성하기 먼저 프로젝트를 생성한다. 기존에 npm과 nodejs가 설치되어 있다는 전제하에 시작한다.\n만약 설치되어 있지 않다면 다음의 링크를 참고한다. https://nodejs.org/ko/download/package-manager/\n$ mkdir node_typescript $ npm init -y 그리고 편의를 위해 사전에 설치되어 있어야 하는 패키지들이 있다.\nnpx: global로 패키지를 설치하지 않더라도 프로젝트 내에서 사용할 수 있게 해준다. nodemon: 파일이 변화될 때마다 재실행해준다. typescript: typescript로 구성한 코드를 javascript로 트랜스파일링 해준다. npm-run-all: 여러 npm 실행 명령을 병렬로 실행할 수 있게 해준다. webpack: 요즘 각광받는 모듈 번들러 webpack-cli: webpack 명령을 사용하기 위한 CLI도구 source-map-support: typescript로 개발시 source-map을 지원해준다. @types/express: express 모듈에 대한 type을 지원해준다. $ npm install -g npx $ npm install --save-dev typescript ts-loader npm-run-all webpack @types/express nodemon webpack-cli $ npm install --save express source-map-support 기본 설정하기 다음과 같이 typescript에 대한 기본 설정을 한다.\n$ npx tsc --init tsconfig.json와 같은 파일이 생성되는데 안에 주석처리 되어 있는 \u0026ldquo;inlineSourceMap\u0026quot;을 true로 주석을 풀어준다.\n[tsconfig.json] { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;lib\u0026#34;: [ \u0026#34;es5\u0026#34;, \u0026#34;es6\u0026#34; ], \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;moduleResolution\u0026#34;: \u0026#34;node\u0026#34;, \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, \u0026#34;emitDecoratorMetadata\u0026#34;: true, \u0026#34;experimentalDecorators\u0026#34;: true, \u0026#34;sourceMap\u0026#34;: true } } 아래와 같이 루트디렉터리에 webpack.config.js 파일을 생성하여 아래의 코드를 입력한다.\n[config/webpack.config.js] const path = require(\u0026#39;path\u0026#39;); module.exports = { entry: \u0026#39;./src/www.ts\u0026#39;, module: { rules: [ { test: /\\.tsx?$/, use: \u0026#39;ts-loader\u0026#39;, exclude: /node_modules/ } ] }, devtool: \u0026#39;source-map\u0026#39;, target: \u0026#39;node\u0026#39;, resolve: { extensions: [ \u0026#39;.tsx\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.js\u0026#39; ] }, output: { filename: \u0026#39;bundle.js\u0026#39;, path: path.resolve(__dirname, \u0026#39;dist\u0026#39;) } }; 설정을 완료했다면 src 디렉터리를 추가하고 App.ts파일을 생성하고 아래의 코드를 입력한다.\n[src/App.ts] import * as express from \u0026#34;express\u0026#34;; class App { public app: express.Application; /** * @ class App * @ method bootstrap * @ static * */ public static bootstrap (): App { return new App(); } constructor () { this.app = express(); this.app.get(\u0026#34;/\u0026#34;, (req: express.Request, res: express.Response, next: express.NextFunction) =\u0026gt; { res.send(\u0026#34;Hello world\u0026#34;); }); } } export default App; express server를 실행하는 코드를 작성한다.\n[src/www.ts] import \u0026#39;source-map-support/register\u0026#39;; // source-map을 사용하기 위해 추가함. import App from \u0026#39;./App\u0026#39;; import * as express from \u0026#34;express\u0026#34;; const port: number = Number(process.env.PORT) || 3000; const app: express.Application = new App().app; app.listen(port, () =\u0026gt; console.log(`Express server listening at ${port}`)) .on(\u0026#39;error\u0026#39;, err =\u0026gt; console.error(err)); package.json에 scripts에 다음 설정도 추가해준다.\n[package.json] { \u0026#34;start\u0026#34;: \u0026#34;nodemon --watch src --delay 1 --exec \u0026#39;ts-node\u0026#39; src/www.ts\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;webpack --config webpack.config.js\u0026#34; } 마지막으로 npm start를 하면 코드가 바뀔 때마다 재시작 하는 것을 확인할 수 있다. 여기서 nodemon을 실행할 때 ts-node를 사용해서 typescript로 작성된 코드를 바로 동작시킨다.\n$ npm start \u0026gt; practice_node_server@1.0.0 start practice_node_server \u0026gt; nodemon --watch src --delay 1 --exec \u0026#39;ts-node\u0026#39; src/www.ts [nodemon] 1.18.6 [nodemon] to restart at any time, enter `rs` [nodemon] watching: practice_node_server/src/**/* [nodemon] starting `ts-node src/www.ts` Express server listening at 3000 실제로 배포할 때는 컴파일된 bundle file 하나만 배포하게 된다. 다음과 같은 명령어로 실행가능한 서버하나의 파일을 생성하고 실행해본다.\n# Webpack을 사용하여 번들링한다. $ npm run build \u0026gt; practice_node_server@1.0.0 build practice_node_server \u0026gt; webpack --config webpack.config.js # Bundled file을 실행해본다. $ node dist/bundle.js Express server listening at 3000 사소한 팁 추가적으로 초기에 build될 때 엄청나게 restart할 경우가 있는데, 이는 nodemon옵션으로 조절할 수 있다.\n$ nodemon --delay 10 server.js # 10초 $ nodemon --delay 2.5 server.js # 2.5초 $ nodemon --delay 2500ms server.js # 2.5초 그리고 Server side rendering을 지원해야하는 경우 views directory가 빌드된 패키지에 포함되어 있어야한다. 이걸 지원하기 위해서는 copy-webpack-plugin을 사용하면 손쉽게 빌드된 패키지에 views 디렉터리를 포함시킬 수 있다.\n고찰 TypeScript를 따로 공부해두긴 했었지만 실제로 적용하려하니 개발환경을 설정하는 것이 제일 힘들었다. 하나씩 webpack을 설정해야 되는 부분이 생각보다 디테일을 요구하였다. 또한 각각의 설정에 따른 결과를 명확히 알아야만 효율적인 bundling을 구현할 수 있다는 점이 힘들었다.\nTypeScript의 문법 자체는 기존에 여러 웹사이트를 SPA 방식으로 React.js로 개발한 경험으로 어느정도 커버가 되었다. 디테일한 데코레이터를 지정하는 것은 아직 연습이 필요해 보이지만 개발하는데 지장될 정도는 아닌 것 같다.\n만약 처음에 Node.js를 접하는 사람이 개발을 하는 경우에는 TypeScript를 사용하지 말라고 권하고 싶다. 다른 C++, Java, Go 와 같은 언어는 Type 지원이 Compiler에서 지원이 되기 때문에 따로 설정이 필요하지 않지만, TypeScript는 Webpack을 사용할 경우에는 ts-loader를 webpack에 module로 심어줘야 하는 등의 많은 번거로움이 있기 때문에 처음부터 진이 빠져 개발의 흥미를 잃을 가능성이 있기 때문이다.\n하지만 장점으로는 처음에 설정만 제대로 한다면 Type지원이 되기 때문에 Javascript로 개발할 때 약점이었던 IDE상에서의 Hint가 정의한 Type대로 나타나는 점이다. 각 Object의 어떤 function이 있고 각 parameter의 Type을 알려주기 때문에 점차 큰 프로젝트로 변화할 때는 개발 속도의 지연이 없을 것이다.\n이렇게 한 번 정리해놓았기 때문에 다음번에는 편한 개발이 가능할 것이다.\nReferences https://webpack.js.org/ https://www.youtube.com/watch?v=ose1VIo213k https://github.com/novemberde/practice_node_server ","permalink":"https://novemberde.github.io/post/2017/10/22/Express-Typescript/","summary":"Summary 최근에 직방의 AWS Lambda 코드를 세미나에서 스쳐지나가는 것을 보았다. TypeScript로 짜여져 있었고 나중에 지속적인 프로젝트 관리적인 이점이 있을 것으로 생각이 되기 때문에 TypeScript로 프로젝트를 구성해보는 것을 정리해보기로 결심했다.\nnode.js 프로젝트 생성하기 먼저 프로젝트를 생성한다. 기존에 npm과 nodejs가 설치되어 있다는 전제하에 시작한다.\n만약 설치되어 있지 않다면 다음의 링크를 참고한다. https://nodejs.org/ko/download/package-manager/\n$ mkdir node_typescript $ npm init -y 그리고 편의를 위해 사전에 설치되어 있어야 하는 패키지들이 있다.\nnpx: global로 패키지를 설치하지 않더라도 프로젝트 내에서 사용할 수 있게 해준다.","title":"TypeScript로 Node.js Express 서버 개발하기"},{"content":"Summary 개발을 하다가 명령어를 모두 기억하고 싶어도 잠깐 다른 업무를 하다가 다시하면 잊게되는 명령어들이 있다. 특히 OS 관련 명령어는 서버에 문제가 생겼을 때 사용하기 때문에 더욱 그렇다. 이번에는 자주 사용하지 않았으면 하는 명령어들을 정리해본다.\nOS 명령어 sar\n리소스 사용 내역을 볼 수 있다. CPU 사용율 Idle 상태 상태 확인 I/O 의 사용율 메모리 사용율 $ sudo apt-get install sysstat $ sudo vi /etc/default/sysstat ENABLED=\u0026#34;true\u0026#34; $ sar -u 1 5 Linux 4.4.0-1013-aws (ip-172-31-55-55) 10/22/2017 _x86_64_ (1 CPU) 05:52:57 AM CPU %user %nice %system %iowait %steal %idle 05:52:58 AM all 0.00 0.00 0.00 0.00 0.00 100.00 05:52:59 AM all 0.00 0.00 0.00 0.00 0.00 100.00 05:53:00 AM all 0.00 0.00 0.00 0.00 0.00 100.00 05:53:01 AM all 0.00 0.00 0.00 0.00 0.00 100.00 05:53:02 AM all 0.00 0.00 1.98 0.00 0.00 98.02 Average: all 0.00 0.00 0.40 0.00 0.00 99.60 top\nProcess의 snapshot 정보 어느정도 부하가 있는 명령어 $ top 19224 aws-kin+ 20 0 2480936 169728 8696 S 2.9 16.7 24:48.81 java 1 root 20 0 37856 4896 2976 S 0.0 0.5 1:00.60 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:08.99 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 7 root 20 0 0 0 0 S 0.0 0.0 4:34.75 rcu_sched 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root rt 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 vmstat\nOS의 커널을 통해 취득한 정보 메모리 상태 프로세스의 개수 CPU 사용률 Swap I/O I/O Context switch 수 $ vmstat 1 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 151836 89728 508492 0 0 1 4 2 3 0 0 100 0 0 0 0 0 151852 89728 508492 0 0 0 0 121 381 0 0 100 0 0 0 0 0 151804 89728 508492 0 0 0 0 176 415 1 0 99 0 0 0 0 0 151804 89728 508492 0 0 0 0 117 372 0 0 100 0 0 0 0 0 151804 89728 508492 0 0 0 8 121 389 0 0 100 0 0 ps\nOS의 커널로 프로세스 정보를 얻는다. ps 명령어를 실행한 시점에 어떤 프로세스가 동작하는지 상태 등을 확인 프로세스의 CPU 사용 누적시간 프로세스 번호, 이름, 명령어 $ ps -elf F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD 4 S root 1 0 0 80 0 - 9464 - Jun11 ? 00:01:00 /sbin/init 1 S root 2 0 0 80 0 - 0 - Jun11 ? 00:00:00 [kthreadd] 1 S root 3 2 0 80 0 - 0 - Jun11 ? 00:00:09 [ksoftirqd/0] 1 S root 5 2 0 60 -20 - 0 - Jun11 ? 00:00:00 [kworker/0:0H] 1 S root 7 2 0 80 0 - 0 - Jun11 ? 00:04:35 [rcu_sched] 1 S root 8 2 0 80 0 - 0 - Jun11 ? 00:00:00 [rcu_bh] 1 S root 9 2 0 -40 - - 0 - Jun11 ? 00:00:00 [migration/0] 5 S root 10 2 0 -40 - - 0 - Jun11 ? 00:00:50 [watchdog/0] 5 S root 11 2 0 80 0 - 0 - Jun11 ? 00:00:00 [kdevtmpfs] ... $ ps -elf | grep init 4 S root 1 0 0 80 0 - 9464 - Jun11 ? 00:01:00 /sbin/init 0 S ubuntu 26767 23875 0 80 0 - 3237 pipe_w 06:36 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn init netstat\n드라이버 수준에서 네트워크 정보를 출력 option -a: 소켓 정보 -r: 라우팅 정보 -i: 인터페이스 단위 정보 $ netstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg docker0 1500 0 26198 0 0 0 25454 0 0 0 BMU docker_gwbridge 1500 0 8 0 0 0 8 0 0 0 BMRU eth0 9001 0 6761565 0 0 0 3220652 0 0 0 BMRU lo 65536 0 3854159 0 0 0 3854159 0 0 0 LRU veth2ea2a18 1500 0 0 0 0 0 8 0 0 0 BMRU $ netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:ssh *:* LISTEN ... Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 3 [ ] DGRAM 8768 /run/systemd/notify ... $ netstat -r Kernel IP routing table Destination Gateway Genmask Flags MSS Window irtt Iface default ip-172-31-32-1. 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 * 255.255.0.0 U 0 0 0 docker0 172.18.0.0 * 255.255.0.0 U 0 0 0 docker_gwbridge 172.31.32.0 * 255.255.240.0 U 0 0 0 eth0 $ netstat -tnlp (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::2377 :::* LISTEN - tcp6 0 0 :::7946 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - $ netstat -ant | grep 5432 | wc -l iostat\n블록 장비 수준으로 OS 커널 내부에서 측정한다. 디스크 사용률 option -x: Response time, queue length $ iostat Linux 4.4.0-1013-aws 10/22/2017 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.06 0.00 0.02 0.01 0.01 99.91 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn xvda 0.18 0.90 4.01 10298246 45935300 $ iostat -x Linux 4.4.0-1013-aws 10/22/2017 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.06 0.00 0.02 0.01 0.01 99.91 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.10 0.07 0.11 0.90 4.01 54.75 0.00 2.98 1.08 4.26 0.49 0.01 lsof\nlist open files COMMAND : 실행한 명령어 PID : process id USER : 실행한 사용자 FD: File Descriptor, 파일의 종류. cwd: current working directory rtd: root directory mem : memory-mapped file txt: program text (code and data); TYPE: 파일 종류 DIR: 디렉터리 CHR: character special file REG: regular file unix: 유닉스 도메인 소켓 (MySQL 등이 사용하는 소켓으로 로컬 프로세스에서만 사용 가능하며 TCP/UDP 보다 속도가 매우 빠름) DEVICE : 장치 번호 SIZE/OFF: 파일의 크기나 오프셋 NODE: 노드 번호 NAME: 파일명 $ lsof -c docker $ lsof +D /tmp $ sudo lsof -i TCP:22 grep\nUsage: grep [OPTION]... PATTERN [FILE]... Search for PATTERN in each FILE or standard input. PATTERN is, by default, a basic regular expression (BRE). Example: grep -i \u0026#39;hello world\u0026#39; menu.h main.c $ grep -nir \u0026#34;test\u0026#34; ifconfig\n네트워크 정보 출력 eth0 Link encap:Ethernet HWaddr 12:99:72:e5:aa:aa inet addr:172.31.58.121 Bcast:172.31.63.255 Mask:255.255.240.0 inet6 addr: fe80::1099:72ff:fee5:aaaa/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:9001 Metric:1 RX packets:173257 errors:0 dropped:0 overruns:0 frame:0 TX packets:46138 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:213551810 (213.5 MB) TX bytes:20486641 (20.4 MB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:160 errors:0 dropped:0 overruns:0 frame:0 TX packets:160 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:11840 (11.8 KB) TX bytes:11840 (11.8 KB) free\n메모리 사용량 출력 total used free shared buff/cache available Mem: 1014660 50304 109820 5704 854536 750084 Swap: 0 0 0 nslookup\ndomain name server 정보 출력 $ nslookup naver.com Server: 172.31.0.2 Address: 172.31.0.2#53 Non-authoritative answer: Name: naver.com Address: 125.209.222.141 Name: naver.com Address: 125.209.222.142 Name: naver.com Address: 202.179.177.21 Name: naver.com Address: 202.179.177.22 watch\n파일 상태 실시간 확인 $ watch --help Usage: watch [options] command Options: -b, --beep beep if command has a non-zero exit -c, --color interpret ANSI color and style sequences -d, --differences[=\u0026lt;permanent\u0026gt;] highlight changes between updates -e, --errexit exit if command has a non-zero exit -g, --chgexit exit when output from command changes -n, --interval \u0026lt;secs\u0026gt; seconds to wait between updates -p, --precise attempt run command in precise intervals -t, --no-title turn off header -x, --exec pass command to exec instead of \u0026#34;sh -c\u0026#34; -h, --help display this help and exit -v, --version output version information and exit For more details see watch(1). $ watch -n 2 ls -al adduser\n유저 생성 # 비밀번호 없이 유저 생성 $ sudo adduser myUser --disabled-password --ingroup ubuntu who\n현재 접속하고 있는 유저 리스트 출력 $ who ubuntu pts/0 2017-10-30 02:08 (232.232.232.121) whoami\n현재 사용하는 유저 출력 $ whoami ubuntu pwd\n현재 작업하는 디렉터리 출력 $ pwd /home/ubuntu du\nDisk Usage 디스크의 사용 정보를 출력한다. df\nDisk Free 디스크 정보를 출력한다. $ du -c 4 ./.git/objects/info 59944 ./.git/objects/pack 59952 ./.git/objects $ df Filesystem 1K-blocks Used Available Use% Mounted on udev 499480 0 499480 0% /dev tmpfs 101468 5676 95792 6% /run /dev/xvda1 8065444 1761212 6287848 22% / tmpfs 507328 0 507328 0% /dev/shm tmpfs 5120 0 5120 0% /run/lock tmpfs 507328 0 507328 0% /sys/fs/cgroup tmpfs 101468 0 101468 0% /run/user/1000 Referensces 오다 케이지/ 쿠레마츠 타니히토/ 오카다 노리마사/ 히라야마 츠요시 지음, 김완섭 옮김,『그림으로 공부하는 시스템 성능 구조』, 제이펍(1999), p50-p90 https://www.lesstif.com/pages/viewpage.action?pageId=20776078 ","permalink":"https://novemberde.github.io/post/2017/10/22/OS-Command/","summary":"Summary 개발을 하다가 명령어를 모두 기억하고 싶어도 잠깐 다른 업무를 하다가 다시하면 잊게되는 명령어들이 있다. 특히 OS 관련 명령어는 서버에 문제가 생겼을 때 사용하기 때문에 더욱 그렇다. 이번에는 자주 사용하지 않았으면 하는 명령어들을 정리해본다.\nOS 명령어 sar\n리소스 사용 내역을 볼 수 있다. CPU 사용율 Idle 상태 상태 확인 I/O 의 사용율 메모리 사용율 $ sudo apt-get install sysstat $ sudo vi /etc/default/sysstat ENABLED=\u0026#34;true\u0026#34; $ sar -u 1 5 Linux 4.","title":"유용한 OS 명령어 모음"},{"content":"Summary Jenkins는 CD/CI로 가장 알려진 도구이다. 이번에는 Jenkins 설정부터 시작하여 Pipeline으로 배포관리하는 과정을 정리해본다.\nJenkins로 기본 설정하기 Jenkins를 Install Jenkins를 참고하여 설치한다.\n설치하여 맨처음 접속하면 아래와 같은 화면이 나타난다. 다음의 명령어로 나온 텍스트를 입력한다.\n$ cat /var/jenkins_home/secrets/initialAdminPassword Customize Jenkins화면에서 여기서는 크게 설정할 필요없이 Install suggested plugins을 선택한다.\n이후에 해당 플러그인을 설치하고 관리자 계정을 설정할 수 있다.\n테스트를 위해 계정 정보는 다음과 같이 설정한다.\n계정명: admin 암호: 1234 이름: admin 이메일 주소: 본인 이메일 주소 Jenkins 관리 \u0026gt; 플러그인 관리 \u0026gt; 설치 가능 으로 들어가서 Blue ocean을 선택하여 재시작없이 설치하기 버튼을 클릭한다.\n설치 후에 메인으로 들어가면 아래와 같이 Open blue ocean이 생긴 것을 볼 수 있다.\nBlue Ocean 시작하기 Open blue ocean 을 클릭하고 create pipeline을 하면 아래와 같은 화면을 볼 수 있다.\nGithub를 선택하여 repository를 통한 Pipeline을 생성한다.\n클릭후에 Github에서 Token을 Default로 선택된 옵션을 선택하여 발급한다.\n그 다음 pipeline으로 생성하고 싶은 repository를 선택한 후 pipeline을 생성한다.\nPipeline setting하기 Pipeline을 생성하면 아래와 같은 화면을 확인할 수 있다.\n+ 버튼을 누르면 stage를 설정할 수 있는 화면이 나타난다.\n+ add steps를 통해 작업을 실행할 수 있다.\nShell script를 선택하여 ls 를 입력한다.\n설정 후에 상단의 save 버튼을 누르면 아래와 같이 pipeline에 대한 commit을 할 수 있다.\nJenkinsfile을 repository에 반영하게 된다.\n저장 완료 후에 Pipeline의 Stage에서 동작 로그를 확인해볼 수 있다.\n고찰 요즘엔 AWS의 managed service를 쓰는 것을 좋아해서 AWS Code Pipeline을 사용하는 연습을 했었다.\n하지만 AWS의 종속적이지 않을 경우에 CD/CI를 구축한다면 어떻게 Pipeline을 구성할지 생각해보았다.\n기존의 서비스에서 Jenkins를 통한 배포 방식은 하나의 Project를 생성하여 직접 배포를 하였다. 현재처럼 각 단계를 두어 Pipeline으로 분리하지는 않았었다. 그래서 Pipeline으로 구성할 필요성을 느꼈었다. Pipeline으로 구성하면 어떤 곳에서 문제가 생겼는지 시각화되어 명확하게 디버깅을 할 수 있기 때문이다.\nBlue Ocean은 그런점에 있어서 적절한 대안이 된다. 또한, Blue Ocean이 기존의 Jenkins 대시보드 화면보다 훨씬 세련되기 때문에 사용하기 편리하기 때문이다.\n마지막으로, 직접 서비스를 구성한다면 AWS의 Code Pipeline을 사용하겠지만, AWS의 가치는 이번 포스팅처럼 꽤나 긴 여정을 지나야만 느낄 수 있기 때문에 Blue Ocean을 한 번 구성해보는 것도 좋을 것이다.\nReferences https://jenkins.io/download/ https://jenkins.io/projects/blueocean/ ","permalink":"https://novemberde.github.io/post/2017/10/21/Jenkins/","summary":"Summary Jenkins는 CD/CI로 가장 알려진 도구이다. 이번에는 Jenkins 설정부터 시작하여 Pipeline으로 배포관리하는 과정을 정리해본다.\nJenkins로 기본 설정하기 Jenkins를 Install Jenkins를 참고하여 설치한다.\n설치하여 맨처음 접속하면 아래와 같은 화면이 나타난다. 다음의 명령어로 나온 텍스트를 입력한다.\n$ cat /var/jenkins_home/secrets/initialAdminPassword Customize Jenkins화면에서 여기서는 크게 설정할 필요없이 Install suggested plugins을 선택한다.\n이후에 해당 플러그인을 설치하고 관리자 계정을 설정할 수 있다.\n테스트를 위해 계정 정보는 다음과 같이 설정한다.\n계정명: admin 암호: 1234 이름: admin 이메일 주소: 본인 이메일 주소 Jenkins 관리 \u0026gt; 플러그인 관리 \u0026gt; 설치 가능 으로 들어가서 Blue ocean을 선택하여 재시작없이 설치하기 버튼을 클릭한다.","title":"Jenkins의 Blue ocean을 활용하여 배포 관리하기"},{"content":"2017.06.08에 AWSKRUG에서 EC2에서 Docker와 Docker-compose 사용하기라는 주제로 발표했던 자료입니다.\n","permalink":"https://novemberde.github.io/post/2017/10/20/Docker/","summary":"2017.06.08에 AWSKRUG에서 EC2에서 Docker와 Docker-compose 사용하기라는 주제로 발표했던 자료입니다.","title":"EC2에서 Docker와 Docker-compose 사용하기"},{"content":"Summary AWS CodeCommit은 AWS 완전 관리형 private git repository로 인데, 콘솔화면이 조금 부실해서 콘솔화면에서 repository 관리가 좋아보이진 않았다.\nSourceTree라는 Atlassian의 Git GUI tool로 AWS CodeCommit을 연동해보자.\nAWS CodeCommit에서 Git repository 생성하기 AWS CodeCommit화면으로 들어가서 Create repository를 하면 아래와 같은 화면이 나오는데 각 항목에 내용을 입력하자.\nRepository name: test Description: CodeCommit with SourceTree Local에 Git repository 설정하기 Repository를 생성하면 다음과 같은 화면이 나타난다.\n주목해야 할 부분은 빨간 박스로 표시해놓았다.\n현재 root계정으로 작업하고 있는데 이는 권장하지 않고, 별도의 IAM user를 통해 접근을 하는 것을 권장한다는 내용이다.\n또한 생성한 유저로 git clone을 하기 위해서는 git config에 credential.helper를 설정한다.\n이는 한번 설정한 후에는 반복적으로 자격증명을 할 필요없이 CodeCommit에 반영할 수 있도록 해준다.\n먼저 로컬의 Terminal을 열어 아래와 같이 코드를 입력해주자.\n$ git config --global credential.helper \u0026#34;!aws codecommit credential-helper $@\u0026#34; $ git config --global credential.UseHttpPath true 그 다음 Local에서 CodeCommit과 연동할 IAM user를 생성한다.\n만약 이미 AWS cli에 configure가 되어 있다면 해당 유저에게 AWSCodeCommitPowerUser라는 AWS managed type의 policy를 추가한다.\n그렇지 않다면 IAM user를 생성한다. Security, Identity \u0026amp; Compliance 의 IAM 으로 들어가서 Users라는 탭을 클릭한다. Add user 버튼을 클릭하여 유저를 생성한다. 내용은 아래와 같다.\nUser name: CodeCommitUser Access type: Programmatic access Attach existing policies directly를 선택하여 AWSCodeCommitPowerUser를 선택한다. 이는 CodeCommit에 대해 삭제빼고 모든 권한을 준다.\n생성이 되었다면 아래와 같은 창이 나온다. Download를 해도 되지만 기록되면 좋을게 없으니 이창을 그대로 두고 AWS command line interface를 설치한다.\nLocal computer에 aws-cli를 링크된 곳으로 가서 설치한다.\n설치 후에 켜둔 창에서 Access key ID와 Secret access key를 복사해서 입력한다. Default region은 ap-northeast-2로 한다.\n$ aws configure AWS Access Key ID [****************AAAA]: AWS Secret Access Key [****************AAAA]: Default region name [ap-northeast-2]: 다시 IAM user에서 방금생성한 user를 선택한다.\n다음의 화면에서 Generate 버튼을 눌러 AWS CodeCommit에서 사용할 Git credentials을 생성한다.\nHTTPS Git credential이 생성이 되면 아래와 같은 화면이 나타난다.\n다시 Local로 돌아와서 아래와 repository를 clone하면 Username과 Password를 입력하는데 방금 생성한 값을 넣어주면 된다.\n$ git clone https://git-codecommit.us-east-1.amazonaws.com/v1/repos/test Username for \u0026#39;https://git-codecommit.us-east-1.amazonaws.com/v1/repos/test\u0026#39;: Password for \u0026#39;https://home-admin-at-739806549786@git-codecommit.us-east-1.amazonaws.com/v1/repos/test\u0026#39; Clone한 repository로 들어가서 변경사항을 반영해본다.\n$ \u0026gt; sample.txt $ git add . $ git commit -m \u0026#34;add sameple.txt\u0026#34; $ git push origin master SourceTree에서 Git repository 확인하기 SourceTree에서 repository를 add한 후에 사용하면 Local의 GUI환경에서 CodeCommit을 사용할 수 있다.\n처음 Push를 하면 아래와 같이 계정정보를 등록하는 화면이 나타난다.\n이전과 같이 IAM User의 HTTPS Git credential 값을 입력하면 된다.\n나중에 여러 해당 CodeCommit에 대한 계정 정보를 삭제하고 싶은 경우 [도구\u0026gt;옵션]에서 삭제할 수 있다.\nReferences http://docs.aws.amazon.com/ko_kr/codecommit/latest/userguide/welcome.html ","permalink":"https://novemberde.github.io/post/2017/10/20/CodeCommit/","summary":"Summary AWS CodeCommit은 AWS 완전 관리형 private git repository로 인데, 콘솔화면이 조금 부실해서 콘솔화면에서 repository 관리가 좋아보이진 않았다.\nSourceTree라는 Atlassian의 Git GUI tool로 AWS CodeCommit을 연동해보자.\nAWS CodeCommit에서 Git repository 생성하기 AWS CodeCommit화면으로 들어가서 Create repository를 하면 아래와 같은 화면이 나오는데 각 항목에 내용을 입력하자.\nRepository name: test Description: CodeCommit with SourceTree Local에 Git repository 설정하기 Repository를 생성하면 다음과 같은 화면이 나타난다.\n주목해야 할 부분은 빨간 박스로 표시해놓았다.\n현재 root계정으로 작업하고 있는데 이는 권장하지 않고, 별도의 IAM user를 통해 접근을 하는 것을 권장한다는 내용이다.","title":"CodeCommit 과 SourceTree 연동"},{"content":"Summary 여러 프로젝트를 동시에 진행하다보니 여러 repository를 한번에 갱신할 필요성이 생겼다. 일일이 하나씩 들어가서 git pull을 하려니 은근 귀찮았다. 그렇기 때문에 특정 디렉터리에 있는 all repositories(sub directories)에 대해서 git을 갱신해주는 코드를 개발하였다. 코드는 github에 공개되어 있으며 사용 방법은 아래와 같다.\n$ npm install -g git-puller Usage Usage: git-puller [options] Options: -V, --version output the version number -d, --directory [value] Target directory -r, --remote [value] Git Remote (default: origin) -b, --branch [value] Git branch (default: master) -h, --help output usage information examples: git-puller -d ./ # Current directory git-puller -d ../../_my_project # Other directory git-puller -d ./ -r origin -b master # Specify remote and branch gplr -d ./ # Current directory gplr -d ../../_my_project # Other directory gplr -d ./ -r origin -b master # Specify remote and branch References https://github.com/novemberde/git-puller ","permalink":"https://novemberde.github.io/post/2017/09/26/git_puller/","summary":"Summary 여러 프로젝트를 동시에 진행하다보니 여러 repository를 한번에 갱신할 필요성이 생겼다. 일일이 하나씩 들어가서 git pull을 하려니 은근 귀찮았다. 그렇기 때문에 특정 디렉터리에 있는 all repositories(sub directories)에 대해서 git을 갱신해주는 코드를 개발하였다. 코드는 github에 공개되어 있으며 사용 방법은 아래와 같다.\n$ npm install -g git-puller Usage Usage: git-puller [options] Options: -V, --version output the version number -d, --directory [value] Target directory -r, --remote [value] Git Remote (default: origin) -b, --branch [value] Git branch (default: master) -h, --help output usage information examples: git-puller -d .","title":"Git pull all sub repository of certain directory."},{"content":"Summary When I first started programming, I went on a game project to familiarize myself with Javascript.\nI thought there would be a problem with the image license. If there\u0026rsquo;s a problem, please comment below. But, I decided to release this code on Github and hope to be helpful for juniors. Please enjoy this game. Thanks.\nReferences https://github.com/novemberde/js-game/tree/master/dragon_ball ","permalink":"https://novemberde.github.io/post/2017/09/26/dragon_ball_game/","summary":"Summary When I first started programming, I went on a game project to familiarize myself with Javascript.\nI thought there would be a problem with the image license. If there\u0026rsquo;s a problem, please comment below. But, I decided to release this code on Github and hope to be helpful for juniors. Please enjoy this game. Thanks.\nReferences https://github.com/novemberde/js-game/tree/master/dragon_ball ","title":"프로그래밍을 막 시작했을 때 만든 Dragon ball 게임"},{"content":"Summary ElasticBeanstalk를 Docker로 배포하기 위해 살펴보았는데 문제점이 있었다. 기존의 사용하던 ALB와 연동하여 사용하고 싶었지만 설정화면에서는 Classic Load Balancer만 지원되었기 때문이다. eb-cli를 사용하여 AutoScaling Group을 생성하여 ALB의 Target Group에 설정하여 앱을 배포해보자.\nEB cli 설치하기 Install eb cli를 참고하여 로컬에 eb-cli를 설치하자.\n사전에 python이 2.7 또는 3.4이상의 버전이 설치되어 있어야 한다.\n$ pip install awsebcli --upgrade --user 설치 후에 환경변수에 아래와 같은 path를 추가하자.\nLinux – ~/.local/bin macOS – ~/Library/Python/3.4/bin Windows – %USERPROFILE%\\AppData\\Roaming\\Python\\Scripts Python 3.5 on Windows – %USERPROFILE%\\AppData\\Roaming\\Python\\Python3.5\\Scripts Python 3.6 on Windows – %USERPROFILE%\\AppData\\Local\\Programs\\Python\\Python36\\Scripts 올바르게 입력했다면 eb의 version을 확인할 수 있을 것이다.\n$ eb --version EB Command Line Interface로 AutoScaling Group 생성하기 AutoScaling Group을 생성하기 위해선 아래와 같은 과정이 필요하다.\nElasticBeanstalk Application 생성하기 ElasticBeanstalk Environment 생성하기(여기서 AutoScaling Group을 설정한다) 그럼 위 과정에 대해서 eb-cli를 통해 생성해본다.\n# 먼저 eb init을 통해 배포할 region을 지정해준다. $ eb init Select a default region 1) us-east-1 : US East (N. Virginia) 2) us-west-1 : US West (N. California) 3) us-west-2 : US West (Oregon) 4) eu-west-1 : EU (Ireland) 5) eu-central-1 : EU (Frankfurt) 6) ap-south-1 : Asia Pacific (Mumbai) 7) ap-southeast-1 : Asia Pacific (Singapore) 8) ap-southeast-2 : Asia Pacific (Sydney) 9) ap-northeast-1 : Asia Pacific (Tokyo) 10) ap-northeast-2 : Asia Pacific (Seoul) 11) sa-east-1 : South America (Sao Paulo) 12) cn-north-1 : China (Beijing) 13) us-east-2 : US East (Ohio) 14) ca-central-1 : Canada (Central) 15) eu-west-2 : EU (London) (default is 3): 10 # region을 선택했으면 아래와 같은 내용이 나타난다. 여기서 사용할 Application을 생성해주자 Select an application to use 1) legacyEBApplication 2) [ Create new Application ] (default is 2): 2 # 사용할 Application name을 입력하자. Enter Application Name (default is \u0026#34;novem\u0026#34;): TestApp Application TestApp has been created. # 사용할 Platform을 선택해주자. 여기서 Docker로 배포하기 때문에 Docker를 선택한다. Select a platform. 1) Ruby 2) Go 3) Java 4) Tomcat 5) PHP 6) Python 7) Node.js 8) IIS 9) Docker 10) GlassFish 11) Packer (default is 1): 9 # Platform version은 Community Edition을 선택해주도록 하자. Select a platform version. 1) Docker 17.03.1-ce 2) Docker 1.12.6 3) Docker 1.11.2 4) Docker 1.9.1 (default is 1): 1 # SSH로 접근할 수 있도록 할지 선택할 수 있다. Cannot setup CodeCommit because there is no Source Control setup, continuing with initialization Do you want to set up SSH for your instances? (Y/n): Y # SSH 접근을 허용했다면 사용할 KeyPair를 선택해주자. Select a keypair. 1) RootKeyPair 2) OtherUserKeyPair 3) [ Create new KeyPair ] (default is 1): 1 ElasticBeanstalk Application을 생성하였다.\n다음으로 ElasticBeanstalk environment를 생성하자.\n이때 윈도우 환경이라면 CMD창을 Administrator권한으로 실행해야 올바르게 동작한다.\n$ eb create # Environment Name을 입력한다. Default로 [ApplicationName-dev] 로 잡힌다. Enter Environment Name (default is TestApp-dev): # DNS Name을 입력한다. Default로 [ApplicationName-dev] 로 잡힌다. Enter DNS CNAME prefix (default is TestApp-dev): # Load balancer type을 입력한다. Default로 [Classic Load Balancer] 로 잡힌다. Select a load balancer type 1) classic 2) application (default is 1): 2 Creating application version archive \u0026#34;app-170926_015406\u0026#34;. Uploading TestApp/app-170926_015406.zip to S3. This may take a while. Upload Complete. Environment details for: TestApp-dev Application name: TestApp Region: ap-northeast-2 Deployed Version: app-170926_015406 Environment ID: e-mdj25dyzuu Platform: arn:aws:elasticbeanstalk:ap-northeast-2::platform/Docker running on 64bit Amazon Linux/2.7.4 Tier: WebServer-Standard CNAME: TestApp-dev.ap-northeast-2.elasticbeanstalk.com Updated: 2017-09-26 01:54:09.941000+00:00 Printing Status: ... 이제 모두 생성되었다.\n소스코드를 배포해 보자. 로컬에 아래와 같은 예제 git repository를 가져와서 배포하자.\n# 로컬에 소스코드를 가져온다. $ git clone https://kyuhyun@bitbucket.org/kyuhyun/docker_node_server.git 해당 폴더를 zip 파일로 압축한다. AWS console에서 ElasticBeanstalk로 접속하여 해당 Environment로 이동한다. 압축한 파일을 업로드하여 Deploy 한다. 이 과정을 eb cli로 진행하려 하였지만 EB-cli 문서에 codecommit의 repository만 지정할 수 있게 나와있다. 내부적으로는 S3에 업로드하지만 S3 주소를 따로 가리키는 option이 없기 때문에 eb-cli로만 진행할 수는 없었다.\nDefault로 생성된 ALB를 삭제하고 TargetGroup 재지정 후 상태 확인 이 글을 쓰게된 계기는 기존에 사용하던 ALB에서 TargetGroup만 지정하여 사용할 수 있는지가 궁금해서 시작한 것이다.\n하지만 Default로 EB를 AutoScalingGroup과 TargetGroup만 생성해서 만들지는 못하기 때문에 ALB와 함께 생성하였다.\n이제 궁금한 부분은 같이 생성된 ALB를 삭제하였을 때 지속적으로 다시 ALB가 살아나는지 확인하고 기존의 TargetGroup을 엮어줘도 괜찮은가이다.\n아래와 같은 프로세스로 진행해보았다.\nEB와 생성된 ALB를 삭제한다. 새로 ALB를 생성하고 ALB의 Security Group을 인스턴스들의 SecurityGroup으로 열어준다. 동작 확인! 문제없이 동작은 하였지만 살짝 마음에 걸리는 부분은 있다.\nEB는 아직 ALB가 삭제되었다고 표시되는 부분이 없다. 또한 아래와 같이 url이 나타나있지만 실제로는 ALB가 사라졌기 때문에 동작하지 않는다. 나중에 전체 구조를 다시 파악할 때 큰 어려움이 있을 것으로 보인다.\nReferences http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install.html http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-deploy.html ","permalink":"https://novemberde.github.io/post/2017/09/25/ALB_to_elasticbeanstalk/","summary":"Summary ElasticBeanstalk를 Docker로 배포하기 위해 살펴보았는데 문제점이 있었다. 기존의 사용하던 ALB와 연동하여 사용하고 싶었지만 설정화면에서는 Classic Load Balancer만 지원되었기 때문이다. eb-cli를 사용하여 AutoScaling Group을 생성하여 ALB의 Target Group에 설정하여 앱을 배포해보자.\nEB cli 설치하기 Install eb cli를 참고하여 로컬에 eb-cli를 설치하자.\n사전에 python이 2.7 또는 3.4이상의 버전이 설치되어 있어야 한다.\n$ pip install awsebcli --upgrade --user 설치 후에 환경변수에 아래와 같은 path를 추가하자.\nLinux – ~/.local/bin macOS – ~/Library/Python/3.4/bin Windows – %USERPROFILE%\\AppData\\Roaming\\Python\\Scripts Python 3.","title":"AWS ALB로 ElasticBeanstalk 배포하기"},{"content":"빅데이터를 직접 모으는 방법이 있지만, 공공데이터 포털과 네이버 데이터랩처럼 정해진 API를 통해 접근하거나 데이터를 JSON, XML, CSV와 같은 형식으로 지원해주는 사이트들을 적극 활용해볼 수 있습니다.\nAWSKRUG 류한진 님과 함께 준비한 Athena, QuickSight Hands-on lab입니다. 아래 링크는 발표자료 및 Hands-on 문서입니다.\n발표자료 Hands-on 아래는 류한진 님과 함께 작성한 \u0026lt;공공데이터 + Athena + QuickSight\u0026gt; 튜토리얼입니다.\n공공데이터를 이용한 데이터 만들기부터 분석까지 개요 빅데이터를 직접 모으는 방법이 있지만, 공공데이터 포털과 네이버 데이터랩처럼 정해진 API를 통해 접근하거나 데이터를 JSON, XML, CSV와 같은 형식으로 지원해주는 사이트들을 적극 활용해볼 수 있다.\n이번에는 공공데이터 포털에서 예제를 통해 전국무료와이파이 표준데이터에 대해서 AWS Athena로 쿼리하는 것을 진행한다. 또한, 결과에 대해 BI도구인 AWS QuickSight로 시각화해서 확인한다.\n서비스 소개 AWS Athena 표준 SQL을 사용해 Amazon S3에 저장된 데이터를 간편하게 분석할 수 있는 대화식 쿼리 서비스 서버리스 서비스이므로 관리할 인프라가 없으며 실행한 쿼리에 대해서만 과금 Amazon S3에 저장된 데이터를 지정하고 스키마를 정의한 후 표준 SQL을 사용하여 쿼리 Athena에서는 데이터 분석을 준비하기 위한 복잡한 ETL(Extract, transform, load) 작업이 필요없음 ANSI SQL을 지원하는 Presto를 사용하며, CSV, JSON, ORC, Avro, Parquet 등 표준 데이터 형식과 호환됨 AWS QuickSight BI 도구 데이터 소스 접근 기존의 Redshift, RDS, Amazon Aurora, EMR, DynamoDB, Kinesis, S3 및 기존 파일도 가능하며 Salesforce 같은 서드파티에 저장된 데이터 접근 커넥터도 제공 빠른 데이터 연산 고속의 병렬 인메모리 최적화된 연산 엔진(Super-fast, Parallel, In-memory optimized Calculation Engine, SPICE)을 가지고 있으며, 클라우드 기반으로 더 빠른 상호 작용 기반으로 데이터 시각화를 위한 사용자 경험을 제공 손 쉬운 사용법 AWS 데이터 소스를 자동으로 발견하고 손쉽게 연결 테이블 및 항목을 선택하면 최적의 데이터 그래프 형태와 시각화 방법을 제공 이렇게 만들어진 리포트를 친구들에게 공유하거나, 몇몇 다른 리포트와 합쳐서 데이터가 말하는 바를 전달 할 수 있으며, 웹사이트에 임베딩해서 출력 가능 높은 확장성 지원 빠른 분석 및 시각화를 제공하는 데, 이를 위해 수백 및 수천 사용자와 기관별로 테라바이트 급 데이터를 높은 확장성을 기반으로 처리 저비용 구조 기존 온프레미스 환경의 1/10 비용 만으로 스마트한 BI를 구성 파트너 지원 ODBC 커넥터를 지원하여 파트너사의 기존 BI 도구를 연결 가능 SQL을 통해 SPICE 엔진이 기존 도구를 지원할 수 있으며, Domo, Qlik, Tableau 및 Tibo 같은 파트너와 협력 공공데이터 포털에서 데이터 가져오기 공공데이터포털에 계정이 있다면 전국무료와이파이 표준데이터에서 CSV파일을 다운받고, 자신의 Bucket에 업로드하면 된다.\n없다면 아래와 같은 명령어로 자신의 S3 bucket에 복사해와야 한다.\n$ aws s3 cp s3://awskrug-workshop-publicdata s3://\u0026lt;USER_BUCKET_NAME\u0026gt; --recursive 버킷을 확인하면 아래와 같은 두 파일이 있을 것이다.\n전국무료와이파이표준데이터.xls csv/전국무료와이파이표준데이터.csv 우리는 CSV파일을 통해 Athena로 쿼리를 던져 결과를 받아볼 것이다.\nAthena에서 테이블 생성하기 (여기서부터는 N.virginia 리전에서 진행 필수)\nAthena에서 S3저장소에 있는 CSV파일에 대해서 쿼리하기 위해서는 파일 형식에 대해 Athena가 이해하고 있어야 가능하다.\n이를 위해서는 DBMS처럼 Athena에 database를 생성하고 table을 생성해야 한다.\nQuery Editor 항목에서 아래와 같은 쿼리를 입력하고 Run query를 한다.\n# awskrug라는 database 생성 CREATE DATABASE IF NOT EXISTS awskrug database를 생성하였다. 다음은 Athena가 이해할 수 있도록 CSV파일의 따른 table을 생성해주어야 한다.\n# Catalog Manager로 생성 CREATE EXTERNAL TABLE IF NOT EXISTS awskrug.free_wifi_standard_data ( `name` string, `detail` string, `city` string, `gungu` string, `facility` string, `service_provider` string, `wifi_ssid` string, `installed_at` DATE, `road_name_address` string, `parcel_address` string, `management_agency` string, `management_agency_phone` string, `latitude` float, `longitude` float, `created_at` DATE ) ROW FORMAT SERDE \u0026#39;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;,\u0026#39;, \u0026#39;field.delim\u0026#39; = \u0026#39;,\u0026#39;, \u0026#34;serialization.encoding\u0026#34;=\u0026#39;utf-8\u0026#39; ) LOCATION \u0026#39;s3://\u0026lt;USER_BUCKET_NAME\u0026gt;/csv/\u0026#39; TBLPROPERTIES (\u0026#39;has_encrypted_data\u0026#39;=\u0026#39;false\u0026#39;); 제대로 생성했다면 아래와 같은 쿼리를 실행했을 때 결과가 나와야 한다.\nSELECT * FROM awskrug.free_wifi_standard_data LIMIT 100; QuickSight - Athena 로 확인하기 QuickSight 열기 Manage Data 클릭 New Data Set 클릭 Athena를 데이터 소스로 선택 데이터 소스명을 입력 awskrug Create Data Source 클릭 awskrug database 를 선택 free_wifi_standard_data 테이블 선택 실행 결과 - 시도별 와이파이 설치 - 시도별 와이파이 서비스 제공업체 상단의 Capture 버튼을 동해 스토리를 생성할 수 있다.\nQuickSight - uploaded file 로 확인하기 Manage Data 클릭 New Data Set 클릭 Upload a file 클릭 S3에 있는 CSV파일 다운로드 후 QuickSight에 업로드 데이터 소스명을 입력 awskrug-upload Create Data Source 클릭 Create Analysis로 전국무료와이파이표준데이터.csv 생성 이전과 같은 과정 반복하여 결과 확인\n고찰 Athena \u0026amp; 공공데이터 포털\n인코딩 문제 공공데이터 포털에서 제공해주는 CSV파일이 EUC-KR로 되어 있었음 별도로 EUC-KR에서 UTF-8로 수정하여 해결 변환작업하는 OS가 Window일 경우 줄 시퀀스가 CRLF로 되어 있다면 LF로 바꾸어 저장할 것(Linux기반 OS와 Windows의 줄바꿈의 기준이 다르기 때문) 공공데이터 포털의 대부분은 XML형식으로 이루어져 있기 때문에 만약 XML의 파일을 사용한다면 별도로 데이터 변환작업이 필요함 Python: https://github.com/hay/xml2json Javascript: https://github.com/Leonidas-from-XIV/node-xml2js 공공데이터 포털의 데이터는 각 시군구 데이터의 형식이 다를 경우도 있기 때문에 전국적인 데이터로 사용하기 위해서는 전처리 작업이 필요함 QuickSight\nQuickSight 계정에서 Account Setting \u0026gt; Account Permissions \u0026gt; Edit AWS permissions에서 문제가 발생했을 경우 AWS IAM에서 이전에 생성된 IAM Role 및 policy(QuickSight로 검색)을 삭제해주면 정상적으로 다시 권한을 부여할 수 있음 장점 별도로 BI툴을 운영하거나 관리할 필요가 없음 튜토리얼만 따라한다면 진입장벽이 높지 않음 Filter 기능을 통해 다양한 쿼리를 시각적으로 구현할 수 있음 스토리로 저장할 수 있기 때문에 차트 관리에 유리 단점 한글화된 문서가 거의 존재하지 않음 실제로 기업에서 사용한 사례가 많지 않기 때문에 도입하기가 쉽지 않음(보통은 Excel을 선호하기 때문에) Suggested를 보면 추천되는 모형이 있지만 정규화가 제대로 되어있지 않은 데이터에 대해서는 쓸모가 없음(별도로 필터링이 필요) Cross-Region - S3-Athena는 다른 리전간에도 사용 가능. (현재 서울리전에서 가장 가까운 곳은 도쿄리전) - Athena-Quicksight는 같은 리전에서만 사용 가능.\n사례 모음 Athena https://aws.amazon.com/ko/blogs/korea/category/amazon-athena/ https://aws.amazon.com/ko/blogs/korea/top-10-performance-tuning-tips-for-amazon-athena/ 샘플 Athena https://github.com/awskrug/athena-workshop QuickSight https://aws.amazon.com/ko/blogs/aws/category/amazon-quicksight/ References https://prestodb.io/ http://docs.aws.amazon.com/athena/latest/ug/json.html https://aws.amazon.com/ko/blogs/korea/amazon-quicksight-fast-easy-to-use-business-intelligence-for-big-data-at-110th-the-cost-of-traditional-solutions/ https://www.slideshare.net/awskorea/6-aws-bigdata-architecture-pattern-and-good-cases ","permalink":"https://novemberde.github.io/post/2017/09/14/public_data_athena/","summary":"빅데이터를 직접 모으는 방법이 있지만, 공공데이터 포털과 네이버 데이터랩처럼 정해진 API를 통해 접근하거나 데이터를 JSON, XML, CSV와 같은 형식으로 지원해주는 사이트들을 적극 활용해볼 수 있습니다.\nAWSKRUG 류한진 님과 함께 준비한 Athena, QuickSight Hands-on lab입니다. 아래 링크는 발표자료 및 Hands-on 문서입니다.\n발표자료 Hands-on 아래는 류한진 님과 함께 작성한 \u0026lt;공공데이터 + Athena + QuickSight\u0026gt; 튜토리얼입니다.\n공공데이터를 이용한 데이터 만들기부터 분석까지 개요 빅데이터를 직접 모으는 방법이 있지만, 공공데이터 포털과 네이버 데이터랩처럼 정해진 API를 통해 접근하거나 데이터를 JSON, XML, CSV와 같은 형식으로 지원해주는 사이트들을 적극 활용해볼 수 있다.","title":"Athena, QuickSight를 활용한 공공데이터 분석"},{"content":"Summary c9.io를 살펴보니 상당히 괜찮은 IDE로 느껴졌다. Docker container를 할당해서 독립적인 작업 공간을 부여하는 점과 리눅스환경이기 때문에 window를 사용하는 사람에게 여러 환경설정의 늪에서 벗어나게 해줄 수 있을 것 같았다.\n하지만 불편한 점도 있다. 브라우저 안에 갇혀 있기 때문에 답답한 느낌이 드는게 가장 큰 부분이었다. 거기에다가 installer도 지원해주지 않기 때문에 별도로 app형식으로 사용하지 못했다.\n이럴 때 Electron이 떠올랐는데, Chromium 기반으로 Google chrome에서 돌아가는 웹페이지는 모두 어플리케이션으로 만들 수 있기 때문이다.\n혼자 Toy project의 개념으로 Electron을 활용해서 c9.io의 installer를 만들고 로컬에서 c9.io를 어플리케이션으로 사용해보자.\nElectron 시작하기 Electron quick start 템플릿을 받고 폴더명만 c9-app으로 고쳐주자.\n$ git clone https://github.com/electron/electron-quick-start 그 다음 \u0026lsquo;hello world\u0026rsquo;를 보기 전에 필수 패키지를 설치하자. 사전에 nodejs와 npm이 설치되어 있어야 한다.(nodejs \u0026amp; npm 참고)\n# install electron as global $ npm install -g electron ~/c9-app $ npm start 새 창이 열리면서 \u0026lsquo;hello world\u0026rsquo;가 나타날 것이다.\n거의 다 왔다.\n별도로 앱 커스텀은 따로하면 되고 설정하기 귀찮으니 \u0026lsquo;index.html\u0026rsquo;만 변경해주자.\n아래쪽의 스크립트영역에 아래와 같이 써주자.\nlocation.href = \u0026#39;https://c9.io\u0026#39; 다시 시작해주면 아래와 같은 화면이 나타날 것이다.\n~/c9-app $ npm start Build Desktop app 앱으로 만들기 위해선 electron-packagr가 필요하다. Windows환경에서 개발하고 있으니 win32로 platform을 지정해주자.\n$ npm install electron-packager -g $ electron-packager . c9-app --platform=win32 --arch=x64 모든 과정을 마치면 루트 디렉터리에 \u0026lsquo;c9-app-win32-x64\u0026rsquo; 폴더가 생길 것이다.\n실행하면 아까와 같은 c9.io 페이지가 열릴 것이다.\n이제 편하게 c9으로 작업하자.\n관련 작업한 repository는 public으로 github에 올려놓았다. https://github.com/novemberde/c9-app\nReferences https://electron.atom.io/docs/ https://electron.atom.io/docs/tutorial/quick-start/ https://github.com/electron-userland/electron-packager ","permalink":"https://novemberde.github.io/post/2017/08/18/make_c9_app/","summary":"Summary c9.io를 살펴보니 상당히 괜찮은 IDE로 느껴졌다. Docker container를 할당해서 독립적인 작업 공간을 부여하는 점과 리눅스환경이기 때문에 window를 사용하는 사람에게 여러 환경설정의 늪에서 벗어나게 해줄 수 있을 것 같았다.\n하지만 불편한 점도 있다. 브라우저 안에 갇혀 있기 때문에 답답한 느낌이 드는게 가장 큰 부분이었다. 거기에다가 installer도 지원해주지 않기 때문에 별도로 app형식으로 사용하지 못했다.\n이럴 때 Electron이 떠올랐는데, Chromium 기반으로 Google chrome에서 돌아가는 웹페이지는 모두 어플리케이션으로 만들 수 있기 때문이다.\n혼자 Toy project의 개념으로 Electron을 활용해서 c9.","title":"Electron으로 Cloud 9 (c9.io) desktop app 만들기"},{"content":"Summary AWS Lambda와 api gateway를 사용하여 작업하면 배포하는 부분에서 상당부분 시간을 사용한다. 또한 API Gateway와 lambda를 엮는 것은 별도의 설정 과정이 필요하며, Resource \u0026amp; Stage 개념이 있어서 변경사항이 생길 경우에 API배포를 매번 해주어야 한다.\nServerless framework는 이 모든 것을 자동화해주며, 내부적으로 CloudFormation을 사용하기 때문에 API gateway에서 api변동사항을 더욱 쉽게 반영해줄 수 있다.\nServerless framework 란? The open-source, application framework to easily build serverless architectures on AWS Lambda \u0026amp; more. Startups and Fortune 500 companies are using it to build incredibly efficient applications.\n오픈소스이며, 쉽게 서버리스 아키텍쳐를 AWS나 다른 클라우드 서비스에서 빌드할 수 있는 어플리케이션 프레임워크이다. 스타트업이나 포춘지 500여개의 회사가 효율적인 어플리케이션 빌딩에 사용하고 있다.\n출처: https://serverless.com/\nServerless framework 특징 Move Fast Provision and deploy a REST API, data pipe-line, or one of many other use cases in minutes. Simplicity Serverless CLI makes it simple to manage and build a serverless architecture by abstracting away provider-level complexity. 100% Utilization Pay when your code runs, so you never have to worry about paying for idle server time. Collaboration Serverless provide a flexible application structure for easy management of code, resources, and events across large projects \u0026amp; teams. Community Serverless is an MIT Open-source project, actively maintained by a vibrant and engaged community of developers. Infinite Scaleability Framework users are reacting to bilions of events per month on AWS Lambda infrastructure Serverless framework 가 지원하는 클라우드 서비스 Amazon Web Services Microsoft Azure IBM OpenWhisk Google Cloud Platform 메이저급의 회사는 모두 지원하고 있다. 이번에는 AWS Lambda를 통해 배포해볼 것이다.\nServerless framework 사용해보기 배포하기에 앞서서 사전에 설치되어 있어야 할 것이 있다.\nnodejs \u0026amp; npm AWS Cli 링크된 곳에서 모두 설치하고 터미널을 열자.\nserverless가 설치되지 않을 수도 있다. 이럴 땐 관리자 권한으로 터미널을 실행하야 설치할 수 있다. npm을 global로 설치하기 때문에 권한 상승이 필요하다.\n# Serverless framework 설치하기 $ npm install -g serverless # 배포를 연습할 디렉터리 생성하고 해당 디렉터리로 들어가기 $ mkdir serverless-practice $ cd serverless-practice # Serverless framework template 생성하기 $ serverless create --template hello-world 이와같이 진행하면 아래와 같은 파일 트리가 생성된다.\nserverless-practice │ .gitignore │ handler.js └ serverless.yml serverless.yml을 보면 아래와 같다.\n# Welcome to serverless. Read the docs # https://serverless.com/framework/docs/ # Serverless.yml is the configuration the CLI # uses to deploy your code to your provider of choice # The `service` block is the name of the service service: serverless-hello-world # The `provider` block defines where your service will be deployed provider: name: aws runtime: nodejs6.10 # The `functions` block defines what code to deploy functions: helloWorld: handler: handler.helloWorld # The `events` block defines how to trigger the handler.helloWorld code events: - http: path: hello-world method: get cors: true 위를 살펴보면 각 function에 대한 handler를 지정할 수 있으며, 서비스 명을 지정할 수 있는 것을 볼 수 있다.\n이제 배포해보자.\n$ serverless deploy 배포가 되지 않을 것이다. Credential 관련해서 따로 설정해준 적이 없기 때문이다.\nAWS IAM console로 들어가서 Programmatic access유저를 생성하고 정신건강을 위해 policies는 AdministratorAccess권한을 주자.\n최소한의 권한으로 주고 싶다면 Minimal IAM policy for Serverless Issue를 참고해보자.\n생성을 마친다면 AccessKeyId 와 SecretAccessKeyId 가 발급된다.\n이젠 다시 터미널로 돌아와서 아래와 같이 진행하자.\n$ aws configure AWS Access Key ID[]: # AccessKeyId 입력. AWS Secret Access Key ID[]: # SecretAccessKeyId 입력. AWS계정과 연결이 완료되었다.\n다시 배포해보자\n$ serverless deploy Serverless로 배포하게 된다면 내부적으로는 CloudFormation Template을 생성하고 AWS 계정을 통해 CloudFormation으로 배포하게 된다.\n궁금하신 분들은 deploy를 한 후에 CloudFormation을 살펴보면서 각 이벤트에 대해 S3, Lambda가 어떻게 반응하는지 확인해보면 될 것이다.\n번외로 AWS 말고도 다른 클라우드 서비스에 대해서도 템플릿이 존재한다.\n$ serverless create --template [아래의 목록 중 하나] \u0026#34;aws-nodejs\u0026#34;, \u0026#34;aws-python\u0026#34;, \u0026#34;aws-python3\u0026#34;, \u0026#34;aws-groovy-gradle\u0026#34;, \u0026#34;aws-java-maven\u0026#34;, \u0026#34;aws-java-gradle\u0026#34;, \u0026#34;aws-scala-sbt\u0026#34;, \u0026#34;aws-csharp\u0026#34;, \u0026#34;aws-fsharp\u0026#34;, \u0026#34;azure-nodejs\u0026#34;, \u0026#34;openwhisk-nodejs\u0026#34;, \u0026#34;openwhisk-python\u0026#34;, \u0026#34;openwhisk-swift\u0026#34;, \u0026#34;google-nodejs\u0026#34;, \u0026#34;plugin\u0026#34;, \u0026#34;hello-world\u0026#34; References https://serverless.com/ https://serverless.com/framework/docs/ ","permalink":"https://novemberde.github.io/post/2017/08/14/Serverless/","summary":"Summary AWS Lambda와 api gateway를 사용하여 작업하면 배포하는 부분에서 상당부분 시간을 사용한다. 또한 API Gateway와 lambda를 엮는 것은 별도의 설정 과정이 필요하며, Resource \u0026amp; Stage 개념이 있어서 변경사항이 생길 경우에 API배포를 매번 해주어야 한다.\nServerless framework는 이 모든 것을 자동화해주며, 내부적으로 CloudFormation을 사용하기 때문에 API gateway에서 api변동사항을 더욱 쉽게 반영해줄 수 있다.\nServerless framework 란? The open-source, application framework to easily build serverless architectures on AWS Lambda \u0026amp; more. Startups and Fortune 500 companies are using it to build incredibly efficient applications.","title":"Serverless을 이용한 AWS Lambda의 배포 자동화"},{"content":"Windows에서 Power shell이나 CMD로 작업하면 linux 명령어를 사용하기 불편하다.\n그렇기 때문에 종종 git bash를 사용했는데 매번 git bash를 켜서 작업하는 것도 귀찮았다.\nVisual Studio Code에서 git bash를 기본 터미널로 설정하면 편하게 작업할 수 있을 것이다.\n방법은 설정에서 사용자 정의 부분을 아래와 같이 덮어씌우면 된다.\n{ \u0026#34;terminal.integrated.shell.windows\u0026#34;: \u0026#34;C:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\u0026#34; } 이제 linux 명령어를 편하게 사용하면서 작업하자.\nReference https://code.visualstudio.com/docs/editor/integrated-terminal ","permalink":"https://novemberde.github.io/post/2017/08/13/Git_Bash/","summary":"Windows에서 Power shell이나 CMD로 작업하면 linux 명령어를 사용하기 불편하다.\n그렇기 때문에 종종 git bash를 사용했는데 매번 git bash를 켜서 작업하는 것도 귀찮았다.\nVisual Studio Code에서 git bash를 기본 터미널로 설정하면 편하게 작업할 수 있을 것이다.\n방법은 설정에서 사용자 정의 부분을 아래와 같이 덮어씌우면 된다.\n{ \u0026#34;terminal.integrated.shell.windows\u0026#34;: \u0026#34;C:\\\\Program Files\\\\Git\\\\bin\\\\bash.exe\u0026#34; } 이제 linux 명령어를 편하게 사용하면서 작업하자.\nReference https://code.visualstudio.com/docs/editor/integrated-terminal ","title":"VS code에서 git bash 사용하기"},{"content":"Windows에서 shell script를 작성하여 배포하였을 경우에 다음과 같은 에러를 만날 수 있다.\n$ bash SomeScript.sh /bin/bash^M: bad interpreter: No such file or directory 이것은 CRLF를 Windows에서 기본으로 사용하였기 때문에 나타난다. 리눅스 기반은 LF를 기반으로 하기 때문에 newline문자가 달라지기 때문이다. VS code를 사용한다면 오른쪽 맨 밑에 CRLF를 LF를 수정하면 해결된다.\n만일 다른 에디터를 사용한다면 설정메뉴에서 바꾸면 될 것이다.\nCRLF와 LF란 CR과 LF의 뜻을 알아보자.\nCR: Carriage Return LF: Line Feed CR은 커서의 위치를 가장 앞으로 옮기는 동작이며, LF는 커서의 위치를 한칸 내리는 것을 의미한다.\nCRLF와 LF의 차이는 \\r\\n과 \\n의 차이이다.\n","permalink":"https://novemberde.github.io/post/2017/08/12/file_format_sh/","summary":"Windows에서 shell script를 작성하여 배포하였을 경우에 다음과 같은 에러를 만날 수 있다.\n$ bash SomeScript.sh /bin/bash^M: bad interpreter: No such file or directory 이것은 CRLF를 Windows에서 기본으로 사용하였기 때문에 나타난다. 리눅스 기반은 LF를 기반으로 하기 때문에 newline문자가 달라지기 때문이다. VS code를 사용한다면 오른쪽 맨 밑에 CRLF를 LF를 수정하면 해결된다.\n만일 다른 에디터를 사용한다면 설정메뉴에서 바꾸면 될 것이다.\nCRLF와 LF란 CR과 LF의 뜻을 알아보자.\nCR: Carriage Return LF: Line Feed CR은 커서의 위치를 가장 앞으로 옮기는 동작이며, LF는 커서의 위치를 한칸 내리는 것을 의미한다.","title":"/bin/bash^M: bad interpreter: No such file or directory"},{"content":"Summary AWS CloudFormation의 Master Class를 보고 Reference document를 통해 내용을 살펴보자.\n특징 Infra structure as a code를 실현하기에 간편한 도구 리소스를 Provisioning하고 update를 해줌 Code로 관리하기 때문에 버전관리에 용이 AWS cli 또는 AWS console을 통해 배포 및 업데이트가 가능 리소스에 대해서만 과금되기 때문에 별도의 비용지출이 없음 Parameter를 통해 Project별로 Customizing이 용이 코드만 올리면 인프라가 형성되기 때문에 인프라 도입에 대한 리소스 투입이 적음 Cloudformation template의 특징 JSON, YAML 로 개발자 친화적인 포맷 코드로 관리하기 때문에 재사용에 용이 Stack 생성시 message를 통해 feedback 제공 Sample template 제공 아래는 yaml형식의 ec2를 생성하는 sample template이다. CloudFormation으로 ec2를 생성할 때 파라미터를 받는다. instanceType, KeyName, SSHLocation을 설정할 수 있도록 되어 있다. 선택할 수 있는 인스턴스의 종류를 제한했기 때문에 t2계열의 인스턴스만 선택할 수 있다. 그리고 AMI는 Amazon linux를 사용하였다.\n# EC2 sample template AWSTemplateFormatVersion: 2010-09-09 Description: EC2 Sample Parameters: # Using before cloudformation is being created KeyName: Description: Name of an existing EC2 KeyPair to enable SSH access to the instance. Recommend use only office IP. Type: \u0026#39;AWS::EC2::KeyPair::KeyName\u0026#39; ConstraintDescription: must be the name of an existing EC2 KeyPair. InstanceType: Description: WebServer EC2 instance type Type: String Default: t2.small AllowedValues: # allow only restricted instance - t2.nano - t2.micro - t2.small - t2.medium - t2.large ConstraintDescription: must be a valid EC2 instance type. SSHLocation: Description: The IP address range that can be used to SSH to the EC2 instances Type: String MinLength: \u0026#39;9\u0026#39; MaxLength: \u0026#39;18\u0026#39; Default: 0.0.0.0/0 AllowedPattern: \u0026#39;(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})\u0026#39; ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x. Mappings: # Conditional value when cloudformation is being created AWSInstanceType2Arch: t2.nano: Arch: HVM64 t2.micro: Arch: HVM64 t2.small: Arch: HVM64 t2.medium: Arch: HVM64 t2.large: Arch: HVM64 AWSInstanceType2NATArch: t2.nano: Arch: NATHVM64 t2.micro: Arch: NATHVM64 t2.small: Arch: NATHVM64 t2.medium: Arch: NATHVM64 t2.large: Arch: NATHVM64 AWSRegionArch2AMI: ap-northeast-2: PV64: NOT_SUPPORTED HVM64: ami-2b408b45 HVMG2: NOT_SUPPORTED Resources: EC2Instance: Type: \u0026#39;AWS::EC2::Instance\u0026#39; Properties: InstanceType: !Ref InstanceType SecurityGroups: - !Ref InstanceSecurityGroup KeyName: !Ref KeyName ImageId: !FindInMap - AWSRegionArch2AMI - !Ref \u0026#39;AWS::Region\u0026#39; - !FindInMap - AWSInstanceType2Arch - !Ref InstanceType - Arch InstanceSecurityGroup: Type: \u0026#39;AWS::EC2::SecurityGroup\u0026#39; Properties: GroupDescription: Enable SSH access via port 22 SecurityGroupIngress: - IpProtocol: tcp FromPort: \u0026#39;22\u0026#39; ToPort: \u0026#39;22\u0026#39; CidrIp: !Ref SSHLocation Outputs: InstanceId: Description: InstanceId of the newly created EC2 instance Value: !Ref EC2Instance AZ: Description: Availability Zone of the newly created EC2 instance Value: !GetAtt - EC2Instance - AvailabilityZone PublicDNS: Description: Public DNSName of the newly created EC2 instance Value: !GetAtt - EC2Instance - PublicDnsName PublicIP: Description: Public IP address of the newly created EC2 instance Value: !GetAtt - EC2Instance - PublicIp 한국 유저는 Asia/seoul region cloudformation sample template 을 통해 여러 샘플들을 볼 수 있다.\n다른 지역의 템플릿을 사용하고 싶으면 left bar에서 다른 region을 선택하면 된다.\nAWS CLI for CloudFormation CloudFormation은 다른 서비스와 마찬가지로 AWS Cli를 통해 사용할 수 있다. 명령어들은 아래와 같다.\n# example $ aws cloudformation update-stack help get-stack-policy set-stack-policy create-stack update-stack cancel-update-stack delete-stack list-stack-resources list-stacks describe-stack-events describe-stack-resouce describe-stack-resouces describe-stacks get-template validate-template Intrinsic functions \u0026amp; pseudo parameters 아래와 같은 function과 parameter를 통해 yaml형식의 파일에서 별도의 로직을 추가할 수 있다.\nIntrinsic function Fn::Base64 Fn::FindInMap Fn::GetAtt Fn::GetAZs Fn::Join Fn::Select Ref Pseudo parameters AWS::NotificationARNs AWS::Region AWS::StackId AWS::StackName 위에서 EC2를 생성하는 경우에 Fn::FindInMap와 Ref과 같은 것을 사용하였는데 ref는 글자에서 느껴지듯이 reference로 특정 변수를 가리킬 때 사용한다. Fn::FindInMap은 별도로 Mapping에 두엇던 파라미터에서 값을 불러오기 위해 사용한다.\n더 자세한 내용을 알고 싶다면 AWS Intrinsic function reference를 참고하도록 하자.\nReferences http://aws.amazon.com/cloudformation http://aws.amazon.com/cloudformation/getting-started http://aws.amazon.com/cloudformation/aws-cloudformation-templates http://github.com/awslabs/cfncluster http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks.html ","permalink":"https://novemberde.github.io/post/2017/08/03/CloudFormation/","summary":"Summary AWS CloudFormation의 Master Class를 보고 Reference document를 통해 내용을 살펴보자.\n특징 Infra structure as a code를 실현하기에 간편한 도구 리소스를 Provisioning하고 update를 해줌 Code로 관리하기 때문에 버전관리에 용이 AWS cli 또는 AWS console을 통해 배포 및 업데이트가 가능 리소스에 대해서만 과금되기 때문에 별도의 비용지출이 없음 Parameter를 통해 Project별로 Customizing이 용이 코드만 올리면 인프라가 형성되기 때문에 인프라 도입에 대한 리소스 투입이 적음 Cloudformation template의 특징 JSON, YAML 로 개발자 친화적인 포맷 코드로 관리하기 때문에 재사용에 용이 Stack 생성시 message를 통해 feedback 제공 Sample template 제공 아래는 yaml형식의 ec2를 생성하는 sample template이다.","title":"AWS CloudFormation을 활용한 Architecture"},{"content":"Summary AWS에서 Elastic Beanstalk를 통해 docker image를 배포할 수 있다. 이번에는 기존에 만들었던 Dockerfile을 Elastic beanstalk에 배포해 보겠다.\nDockerfile 준비하기 이전에 node js server를 하나의 Dockerfile로 만들어 놓았다. 테스트하고 싶으신 분들은 this repository를 참고하길 바란다.\nFROM novemberde/node-pm2 MAINTAINER KH BYUN \u0026#34;novemberde.github.io\u0026#34; ENV NODE_ENV production EXPOSE 3000 COPY ./ /src RUN npm install --prefix /src CMD [\u0026#34;pm2-docker\u0026#34;, \u0026#34;/src/app.js\u0026#34;] Elastic Beanstalk 설정하기 Elastic Beanstalk로 배포하는 경우에 아래와 같이 2가지 방법이 있다.\nSingle instance Load balancing, auto scaling Single instance는 하나에 인스턴스에 해당 dockerfile로 구성된 인스턴스가 올라가는 경우를 발한다.\n만약 실무적으로 하나의 웹어플리케이션을 배포한다고 봤을 때는 Load balancing, auto scaling은 필수적으로 이루어져야 하기 때문에 load balancing, auto scaling을 택하는 것이 좋을 것이다.\n이번에는 테스트이기 때문에 Single instance로 배포하고 메뉴를 살펴볼 것이다.\nElastic Beanstalk에 Docker패키지 배포하기 Environment를 생성하면 다음과 같은 화면을 볼 수 있다.\n여기서 Confiuration을 통해 docker 설정 정보를 변경할 수 있다.\n우리는 Dockerfile과 함께 웹어플리케이션을 배포해야하므로 Upload and Deploy를 선택하자.\n직접 업로드하기를 선택하고, git repository에서 배포에 필요한 파일들인 app.js, Dockerfile, package.json을 zip으로 압축하여 업로드하면 배포가 완료된다.\nupload가 완료되었으면 Dashboard화면에서 위쪽의 url의 3000번 포트로 접속하여 배포가 완료되었는지 확인해 보자.\nAddition Seoul region 사용자들은 ECS(EC2 Container Service)를 사용하지 못해 안타까워하고 있다. 하지만 Elastic Beanstalk에서 Multicontainer Docker Platform을 사용할 때 내부적으로 ECS cluster를 사용하고 있다.\n이말은 ECS는 공식적으로 지원하지 않지만 Elastic Beanstalk를 docker로 활용하면 ECS를 사용하는 것과 같은 형태라고 볼 수 있는 것이다.\n이에 대해서 좀 더 자세히 알고 싶으신 분은 다음의 링크를 참고하길 바란다. Working with multicontainer docker platform\nReferences https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html?icmpid=docs_elasticbeanstalk_console https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker_ecs.html ","permalink":"https://novemberde.github.io/post/2017/07/03/Elastic_Beanstalk/","summary":"Summary AWS에서 Elastic Beanstalk를 통해 docker image를 배포할 수 있다. 이번에는 기존에 만들었던 Dockerfile을 Elastic beanstalk에 배포해 보겠다.\nDockerfile 준비하기 이전에 node js server를 하나의 Dockerfile로 만들어 놓았다. 테스트하고 싶으신 분들은 this repository를 참고하길 바란다.\nFROM novemberde/node-pm2 MAINTAINER KH BYUN \u0026#34;novemberde.github.io\u0026#34; ENV NODE_ENV production EXPOSE 3000 COPY ./ /src RUN npm install --prefix /src CMD [\u0026#34;pm2-docker\u0026#34;, \u0026#34;/src/app.js\u0026#34;] Elastic Beanstalk 설정하기 Elastic Beanstalk로 배포하는 경우에 아래와 같이 2가지 방법이 있다.\nSingle instance Load balancing, auto scaling Single instance는 하나에 인스턴스에 해당 dockerfile로 구성된 인스턴스가 올라가는 경우를 발한다.","title":"Docker image를 EB(Elastic Beanstalk)를 통해 배포하기"},{"content":"Summary node js로 서버를 구성할 때 ORM framework로 sequelize를 사용한다. 하지만 비동기로 모든 CRUD가 진행되다보니 동시에 여러 쿼리문의 결과가 요구될 때도 있다. serial execution과 parallel execution을 살표보자.\nparallel execution과 serial execution Promise pattern을 활용하여 절차적으로 함수를 실행하면 여러 트랜잭션 과정을 파악하기 쉽다. callback 패턴의 늪에서 벗어날 수 있는 Promise는 현재 서버사이드에서 사용되는 라이브러리들에서 적극 활용되어지고 있다.\n먼저 serial execution을 살펴보고 이에 대한 단점도 파악해 보자.\n아래의 예제는 User를 검색하고 관계가 형성되어 있지 않은 다른 테이블을 Select하는 경우이다.\n// Serial execution let users; let menus; models.User.findAll({ attributes: [\u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;phone\u0026#39;, \u0026#39;address\u0026#39;] }) .then( result =\u0026gt; { if (!result) throw new Error(\u0026#34;Not Found\u0026#34;); users = result; return models.Menu.findAll() }) .then( result =\u0026gt; { if (!result) throw new Error(\u0026#34;Not Found\u0026#34;); menus = result; console.log(users); console.log(menus); }); 이를 살펴보면 조금 이상한 점이 있다. 하나의 결과를 받고 그 다음에 또 다시 쿼리를 실행하는 느낌이다. 서로 관계없는 데이터이기 때문에 두개의 쿼리를 동시에 보내고 따로 값을 받아서 처리하는게 나아보인다. 왜냐하면 절차적으로 반드시 이렇게 이루어져야만 하는 쿼리가 아니기 때문이다.\n만약 하나의 값을 select해서 insert하는 경우라면 사용할 수 있겠지만 위의 경우는 상관관계가 없기 때문이다.\n그렇다면 어떻게 사용할 수 있을까?\nPromise.all() 함수를 사용하면 간단히 해결할 수 있다.\n// Serial execution let users; let menus; Promise.all([ models.User.findAll({ attributes: [\u0026#39;id\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;phone\u0026#39;, \u0026#39;address\u0026#39;] }), models.Menu.findAll() ]) .then( result =\u0026gt; { if (!result[0]) throw new Error(\u0026#34;Not Found\u0026#34;); if (!result[1]) throw new Error(\u0026#34;Not Found\u0026#34;); users = result; menus = result; console.log(users); console.log(menus); }); 위 뿐만아니라 하나의 transaction이 일어나는 과정에서 여러 데이터를 CRUD하는 경우에도 유용하게 사용될 수 있다.\n이처럼 Promise는 비동기적으로 일어나는 과정을 간단히 표현할 수 있다. 모든 이벤트가 종료되었을 때 then절이 동작하기 때문에 코드가 난잡해지는 것을 방지하기 때문이다.\nPromise 패턴이 javascript에서 많은 변화를 가져왔다. 최근에는 Async/Await가 사용되는데 nodejs 8 version이후부터 사용 가능하다고 한다.\n비동기 패턴에 대해 더욱 공부하고 싶으신 분들은 Async/Await에 대해 찾아보길 바란다.\nReferences http://docs.sequelizejs.com/manual/tutorial/transactions.html https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Promise ","permalink":"https://novemberde.github.io/post/2017/07/01/Sequelize_0/","summary":"Summary node js로 서버를 구성할 때 ORM framework로 sequelize를 사용한다. 하지만 비동기로 모든 CRUD가 진행되다보니 동시에 여러 쿼리문의 결과가 요구될 때도 있다. serial execution과 parallel execution을 살표보자.\nparallel execution과 serial execution Promise pattern을 활용하여 절차적으로 함수를 실행하면 여러 트랜잭션 과정을 파악하기 쉽다. callback 패턴의 늪에서 벗어날 수 있는 Promise는 현재 서버사이드에서 사용되는 라이브러리들에서 적극 활용되어지고 있다.\n먼저 serial execution을 살펴보고 이에 대한 단점도 파악해 보자.\n아래의 예제는 User를 검색하고 관계가 형성되어 있지 않은 다른 테이블을 Select하는 경우이다.","title":"Sequelize에서 parallel execution과 serial execution"},{"content":"Summary 의뢰중에 호스팅 서버를 AWS로 옮겨달라는 요청이 있었다. MongoDB서버를 옮기기 위해서 DB를 백업하고 SCP를 사용하여 백업한 정보를 해당 인스턴스로 보내 백업을 진행하였다. 몇몇 간단한 명령어를 통하면 DB의 backup정보를 통해 복구할 수 있다. 과정을 살펴보자.\n현재 db정보를 dump로 만들어 SCP로 파일 전송하기 이전작업을 하기 전에 먼저 클라이언트에게 DB를 실제 서비스에서 분리하고 작업해야된다고 하였다.\n설정정보를 바꾼다면 DB를 재가동 해야하는 이유도 있었으며, mongodb dump파일을 생성한 시점부터는 추가되는 데이터가 없어야 하기 때문이다.\n먼저 외부와의 접속을 차단하고 mongodump파일을 생성해 보자.\n# ~/dump 에 mongodumb파일 생성하기. $ mongodump --port 27017 # scp로 파일 보내기 $ scp -r -i /home/\u0026lt;USER\u0026gt;/\u0026lt;AWS_USER\u0026gt;.pem /home/\u0026lt;USER\u0026gt;/dump \u0026lt;AWS_USER\u0026gt;@ec2-111-111-111-111.ap-northeast-2.compute.amazonaws.com:~/dump 이전될 서버에서 dbdump파일로 복구하기 SCP를 통해 파일이 제대로 전송됐다면 mongorestore를 통해 DB를 restore해주자.\n# localhost에서 동작중인 mongodb에 데이터를 복구하기. $ mongorestore -h 127.0.0.1 ~/dump/ References https://docs.mongodb.com/v3.0/reference/program/mongodump/ ","permalink":"https://novemberde.github.io/post/2017/07/01/Mongodb_transport/","summary":"Summary 의뢰중에 호스팅 서버를 AWS로 옮겨달라는 요청이 있었다. MongoDB서버를 옮기기 위해서 DB를 백업하고 SCP를 사용하여 백업한 정보를 해당 인스턴스로 보내 백업을 진행하였다. 몇몇 간단한 명령어를 통하면 DB의 backup정보를 통해 복구할 수 있다. 과정을 살펴보자.\n현재 db정보를 dump로 만들어 SCP로 파일 전송하기 이전작업을 하기 전에 먼저 클라이언트에게 DB를 실제 서비스에서 분리하고 작업해야된다고 하였다.\n설정정보를 바꾼다면 DB를 재가동 해야하는 이유도 있었으며, mongodb dump파일을 생성한 시점부터는 추가되는 데이터가 없어야 하기 때문이다.\n먼저 외부와의 접속을 차단하고 mongodump파일을 생성해 보자.","title":"다른 서버로 Mongodb 이전하기"},{"content":"Summary 요즘 서버 및 웹클라이언트 환경을 javascript로 대부분 진행하고 있다. 그러던 도중 최근 한 스타트업의 서버 최적화를 진행할 때 굉장히 문제가 많은 코드를 접하였다. 거의 난독증이 생길정도의 코드였고, 기본 수칙만 지켜도 나타나지 않을 오류들이 많았다.\n이번에는 node js와 web framework를 개발하는 개발자들이 기본적으로 지켜주었으면 하는 내용을 담아보겠다.\nJavascript를 떠나 개발자가 코드를 짤 때 지켜야할 수칙 code를 짜다보면 대충 stackoverflow에서 복붙하고 넘어가고 싶고 그것을 으레 당연하게 여기는 개발자가 많음을 느끼고 있다. 하지만 이는 개발자 자신의 발전에 커다란 걸림돌이 된다. 또한 그 프로젝트가 점점 진행될수록 복붙한 코드가 발목을 잡을 것이다. 궁금증이 생겼을 때 구글링으로 stackoverflow나 blog를 중심으로 검색한다면 그 또한 성장하지 못하는 이유가 될 수 있다.\n그렇다면 만일 모르는 문제가 생겼을 때는 어떻게 해야 할까?\n먼저 해당 라이브러리 또는 프레임워크의 reference guide부터 찾아보아야 한다. 많은 사람들이 spring framework나 노드 개발자는 expressjs framework를 사용하는데, 블로그에서 해결했다는 내용을 보고 복붙만 하여 결국에는 엉망으로 변한 코드 구조를 발견할 것이다.\n사실 처음에는 나도 블로그를 통해 기술을 익혔었다. 하지만 실제로 프레임워크나 라이브러리를 적용할 때는 블로그의 있는 tutorial수준의 정보만으로는 프로젝트를 진행할 수 없었다. 언제나 reference document를 찾았고, 반복되서 나타나는 궁금증들은 reference 가이드에 항상 명시되어 있고 best solution을 알려주는 경우도 많았다.\n예를 들자면 블로그나 stackoverflow는 사용법, 해법에 대한 내용이 맞는 경우가 있지만 software는 매달마다 새로운 버전이 나오는 경우도 많고, 지속적인 update로 인해 문법이나 내용이 바뀌는 경우가 종종 있다. 이럴 경우에는 난관에 봉착하게 되고, 천천히 마음을 다잡고 살펴봤을 때 버전호환에서 문제가 있었다는 것을 알아차린다.\n무엇보다도 guide 문서를 기반으로 코드를 진행했을 때 팀원과 협업이라는 것을 원활하게 진행할 수 있다. 개성있는 코드도 멋있지만, design pattern에 기반하여 가이드 라인을 따라가면 시간이 지날수록 프로젝트 진행에 속도가 붙게된다. 복붙 코드는 결국에는 복붙한 코드의 수정사항이 발생하면 엄청난 괴로움이 밀려오기 때문이다.\n그렇다면 코드를 짤 때 어떤 생각을 가져야 할까?\n항상 염두해야 할 것은 Cross cutting concern이다. 일명 \u0026lsquo;횡단적 관심사항\u0026rsquo;이다. 정말 중요하게 생각하는 부분이다. Spring framework를 사용하는 사람은 한번쯤 들어봤을 것이다. AOP의 개념과도 일맥상통하는데 이걸 염두하지 않으면 굉장히 수고로운 코드를 작성할 것이다.\nAPI에 모두 인증이 필요하다면 어떻게 짤 것인가? 세션에 원하는 정보가 없다면? 아니면 토큰이 가진 권한에 대해서 체크한다면? 모든 request 객체 또는 response 객체에 담아야할 필수적인 내용이 있다면?\n이 모든 것을 해결해줄 방법은 AOP의 개념을 적용하면 쉽게 해결할 수 있을 것이다. 항상 API 앞단에 필수적으로 실행할 method 또는 function 을 두면 해결될 것이다. 그리고 이 코드는 하나의 모듈로 따로 관리하고 API의 시작점에서 체크하고 뒷단으로 해결하라고 보내주기만 하면된다.\nnode js에서는 이를 middleware라 부르기도하고 app.use()에서 해결할 수 있다. spring은 aspect라고 이름 그대로 존재한다.\n그리고 AOP 뿐만 아니라 중요한 것은 DI 의존성 주입이다. 최근에 이것때문에 많이 힘들었다. 의뢰를 받은 서버 최적화를 진행하려는데 한곳을 바꾸면 우르르 의존성에 의해 엄청난 오류가 물밀듯이 밀려왔기 때문이다. 모든 모듈은 강하게 결합되어 있었고 분리라는게 사실상 불가능한 상태였다. 결국은 성능이 필요한 부분만 살려냈다.\n각 모듈은 느슨하게 결합되도록 하고 하나의 모듈이 다른 모듈을 필요로 하고 트리 모형으로 의존성이 있으면 좋지만 망형식으로 의존성이 걸려 있으면 이제 고생길만 남은 것이다. 이것만은 피해야 한다.\nif문 for문만 있으면 다 만들 수 있다. 하지만 그 다음은? 정말 분노하게 만드는 코드가 있다면 if문 안에서 switch문으로 구분하고 case에서 for문을 돌리는데 거기서 if문을 사용하는 것이다. 실제로 이렇게 코드를 짜는 사람이 있다. 모듈화라는 개념이 필요한 사람이다.\n또한 library는 사용을 안하고 자존심으로 구현해서 사용한다는 사람도 있다. 그래서 자신만이 이해하는 코드를 짜고 그것을 자랑스럽게 남겨놓는 경우가 있다. 협업과 효율성이라는 개념이 필요한 사람이다.\n최근에는 Javascript로 프로젝트를 진행한다. 모두가 그렇듯 String에 대한 처리가 은근 사람 힘들게 한다. 그냥 if문으로 처리하던지 직접 파싱하고 싶을 때가 많다. 하지만 이러한 방식은 자중해야 한다. 주석을 아무리 열심히 달아놓아도 이해하기 쉽지 않으며 코드가 지저분하다.\n이것을 해결하는 방법은 아주 간단하다. Useful library라고만 쳐도 빈번하게 사용되는 라이브러리들을 찾아볼 수 있으며, 기본적으로 개발자를 괴롭히는 여러 문제들은 이미 많은 사람들이 고민해서 library화 해놓았다. 가끔 구현내용이 궁금하면 소스코드를 한 번 열어보면되고 연습삼아 한번하자. 그런데 직접 작업한 내용을 적용하지 말고, 사용자가 많은 적절한 라이브러리를 공부하여 적용하자. 그게 팀에 대한 예의이며 추후에 후임자를 괴롭히지 않는 최선이 될 것이다.\n그럼 convention을 왜 중요할까? Convention을 따라야 할 이유는 뭘까?\n무엇보다도 같이 일할 팀원을 위해서이고 다른 개발자들을 배려하기 위해서이다. Convention은 일종의 관습으로 많은 개발자들이 사용하는 룰이다. Class는 대문자로 시작하고, 상수는 대문자로만 작성하고, isArray와 같이 함수는 동사형으로 시작하고, 데이터베이스를 구축할 때 외래키는 \u0026lsquo;테이블명_id\u0026rsquo;와 같이 일종의 룰들이다. for each문을 사용하기 보다는 for(let i=0; i\u0026lt;length; i++)과 같이 사용하는 것도 하나의 convention이다.\n이런 convention들은 개발자들이 성능을 점검하고 협업을 했을 때 보이는 코드 구조의 일관성을 지키기 위해 존재한다.\n이러한 룰을 지키지 않는 경우에는 추후의 유지보수의 기간에 엄청난 시간을 낭비할 수도 있다.\n각 convention들은 회사마다 조금씩 다르지만 전반적으로 거의 같다고 볼 수 있다.\n또한 naming convention도 잘 따라주면 직관적으로 코드를 이해하기 수월해진다.\n각 언어에 대한 code convention은 아래와 같다.\nJava http://www.oracle.com/technetwork/java/javase/documentation/codeconvtoc-136057.html http://www.oracle.com/technetwork/java/codeconventions-150003.pdf 디자인 패턴 https://www.tutorialspoint.com/design_pattern/ C https://users.ece.cmu.edu/~eno/coding/CCodingStandard.html C++ https://users.ece.cmu.edu/~eno/coding/CppCodingStandard.html Google C++ Style Guide Javascript https://www.w3schools.com/js/js_conventions.asp https://github.com/airbnb/javascript https://google.github.io/styleguide/jsguide.html MySQL https://www.toadworld.com/platforms/mysql/w/wiki/6103.naming-conventions https://www.toadworld.com/platforms/mysql/w/wiki/6108.naming-indexes http://www.sqlstyle.guide/ Oracle https://oracle-base.com/articles/misc/naming-conventions Linux kernel https://www.kernel.org/doc/html/v4.10/process/coding-style.html Shell https://google.github.io/styleguide/shell.xml MongoDB https://docs.mongodb.com/manual/meta/style-guide/ HTML https://www.w3schools.com/html/html5_syntax.asp 개인적으로 airbnb의 javascript 스타일 가이드를 통해 전반적인 코드의 가독성과 테크닉을 향상시킬 수 있었다.\n","permalink":"https://novemberde.github.io/post/2017/05/21/Javascript_policy/","summary":"Summary 요즘 서버 및 웹클라이언트 환경을 javascript로 대부분 진행하고 있다. 그러던 도중 최근 한 스타트업의 서버 최적화를 진행할 때 굉장히 문제가 많은 코드를 접하였다. 거의 난독증이 생길정도의 코드였고, 기본 수칙만 지켜도 나타나지 않을 오류들이 많았다.\n이번에는 node js와 web framework를 개발하는 개발자들이 기본적으로 지켜주었으면 하는 내용을 담아보겠다.\nJavascript를 떠나 개발자가 코드를 짤 때 지켜야할 수칙 code를 짜다보면 대충 stackoverflow에서 복붙하고 넘어가고 싶고 그것을 으레 당연하게 여기는 개발자가 많음을 느끼고 있다. 하지만 이는 개발자 자신의 발전에 커다란 걸림돌이 된다.","title":"Code convention과 개발자가 지켜야할 수칙에 관하여"},{"content":"Summary 최근에 글 중에서 aurora와 sequelize가 과연 연동이 가능할까라는 글을 본적이 있다. aurora는 MySQL과 호환이 가능한 DB라고 하기 때문에 나 또한 궁금증이 생겼다. 직접 aurora와 sequelize를 연동해보고, MySQL workbench로 aurora를 사용할 수 있는지까지 확인해보겠다.\nAurora instance 생성하기 이전까지 사용할 때는 MySQL이나 MariaDB위주로 사용했다. 스타트업은 라이센스 비용에 민감하기 때문에 Open Source를 주로 선택했기 때문이다.\n또한 아래 리스트를 보면 RDS 이름에서 추측할 수 있듯이 RDS에서는 관계형 DB만 사용할 수 있는 것을 알 수 있다. 별도로 NoSQL을 사용하고 싶다면 AWS에서 지원하는 DynamoDB를 사용하거나 EC2에 DB를 올리는 방법이 있다.\n이제 다시 본론으로 돌아와서 아래와 같은 화면에서 aurora를 선택한다.\n특징을 살펴보면\nMySQL에 비해 5배의 처리 성능을 지님 15개의 레플리카를 만드는데 최고 10 ms 지연 64TB까지 오토스케일링 저장소가 여러 availability zone에 replicated 이와 같은 특징을 보면 별도로 MySQL에서 레플리카, 별도의 저장공간 확보나 클러스터링에 대해서 신경쓸 부분들이 확연히 줄어든다는 것을 알 수 있다.\nDB설정정보를 입력하자.\nDB Instance Identifier* 에는 DB를 구분할 값이다. 우리가 사용할 이름을 넣어주면된다. Multi_AZ Deployment는 여러 Zone에 Replica를 둠으로써 현재 DB가 올라가 있는 Zone에 이상이 발생하더라도 대처할 수 있게 해주는 고마운 도구다. Master Username* 에는 db의 마스터 계정 아이디라고 보면된다. Master Password* 에는 db의 마스터 계정 비밀번호를 입력하자. 테스트 환경이므로 여기서는 큰 설정을 하지 않는다.\nVPC Security Group에서 새로운 Security Group을 생성한다는 부분만 상기하고 넘어가자.\nSecurity Group에서 별도로 Port를 열어주지 않더라도 RDS인스턴스를 생성할 때 접속한 로컬의 IP주소로 3306포트가 열려있다.\n별도로 security group을 설정하지 않고 넘어가겠다.\n이제 Aurora DB가 생성되고 있음을 볼 수 있다.\nMySQL Workbench로 접속하기 MySQL workbench를 실행하고 새로운 connection을 test해보자.\n아래와 같은 화면으로 connection이 성공한 것을 볼 수 있다.\n이제 접속하여 SQL 쿼리를 사용하여 보자. MySQL과 동일한 쿼리가 동작하는 것을 볼 수 있다.\n-- 스키마 생성하기. CREATE SCHEMA `test` ; -- 테이블 생성하기. createdAt,updatedAt,deletedAt은 sequelize가 기본적으로 찾는 필드이다. 이를 제어하고 싶으면 별도의 설정이 필요하다. CREATE TABLE `test`.`user` ( `id` INT NOT NULL AUTO_INCREMENT, `name` VARCHAR(45) NOT NULL, `createdAt` DATETIME NULL, `updatedAt` DATETIME NULL, `deletedAt` DATETIME NULL, PRIMARY KEY (`id`)); 아래와 같은 테이블이 생성된 것을 볼 수 있다.\nSequelize로 사용하기 sequelize-auto를 사용해서 models를 뽑아오자.\nnpm으로 사전에 sequelize-auto와 mysql을 global로 설치해 놓아야 한다.\n# 기본 패키지 설치 $ npm install -g sequelize-auto mysql # models 뽑기 $ sequelize-auto -o \u0026#34;./models\u0026#34; -d test -h HOST -u USERNAME -p 3306 -x PASSWORD -e mysql 나온 models는 아래와 같다.\nmodule.exports = function(sequelize, DataTypes) { return sequelize.define(\u0026#39;user\u0026#39;, { id: { type: DataTypes.INTEGER(11), allowNull: false, primaryKey: true, autoIncrement: true }, name: { type: DataTypes.STRING(45), allowNull: false }, createdAt: { type: DataTypes.DATE, allowNull: true }, updatedAt: { type: DataTypes.DATE, allowNull: true }, deletedAt: { type: DataTypes.DATE, allowNull: true } }, { tableName: \u0026#39;user\u0026#39; }); }; 마지막으로 Sequelize로 insert와 findAll을 해본다.\nconst models = require(\u0026#39;./models\u0026#39;); models.user.create({name: \u0026#34;KHBYUN\u0026#34;}) .then( result =\u0026gt; { console.log(result.dataValues); }) .catch( err =\u0026gt; { console.error(err); }); models.user.findAll() .then( result =\u0026gt; { console.log(result); }) .catch( err =\u0026gt; { console.error(err); }); 이상없이 동작하는 것을 확인할 수 있다.\nAurora는 MySQL과 호환성이 있기 때문에 MySQL과 사용하듯 Sequelize를 적용하면 Aurora도 큰 무리없이 사용할 수 있을 것으로 예상된다.\n무엇보다 관리적인 이점을 Aurora가 가지고 있기 때문에 Aurora를 사용하는 면이 개발자에게 많은 수고로움을 덜어줄 것이다.\n","permalink":"https://novemberde.github.io/post/2017/05/09/Aurora_sequelize_0/","summary":"Summary 최근에 글 중에서 aurora와 sequelize가 과연 연동이 가능할까라는 글을 본적이 있다. aurora는 MySQL과 호환이 가능한 DB라고 하기 때문에 나 또한 궁금증이 생겼다. 직접 aurora와 sequelize를 연동해보고, MySQL workbench로 aurora를 사용할 수 있는지까지 확인해보겠다.\nAurora instance 생성하기 이전까지 사용할 때는 MySQL이나 MariaDB위주로 사용했다. 스타트업은 라이센스 비용에 민감하기 때문에 Open Source를 주로 선택했기 때문이다.\n또한 아래 리스트를 보면 RDS 이름에서 추측할 수 있듯이 RDS에서는 관계형 DB만 사용할 수 있는 것을 알 수 있다.","title":"Amazon Aurora와 sequelize 연동해보기."},{"content":"Summary 서버에 프로젝트를 배포할 경우 ftp로 파일을 옮기는 방식으로 사용할 수도 있다. 하지만 git repository를 사용하면 git 명령어만으로 간단히 서버코드를 갱신할 수 있다.\n로그인이 아닌 access key를 통해 git repository에 접근하는 방법에 대해 알아보자.\nKey pair 생성하기 먼저 배포하고 싶은 서버에 ssh로 접속한 후 key pair를 생성하자.\n# 이 커맨드는 현재 접속한 유저 directory에 .ssh폴더가 없으면 생성할 것이고, 있다면 .ssh directory에 key pair만 생성할 것이다. $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/USERNAME/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/USERNAME/.ssh/id_rsa. Your public key has been saved in /home/USERNAME/.ssh/id_rsa.pub. The key fingerprint is: SHA256:L68PHdXfH2yfSUKraajtNLnm9ltO2HXtzk0y8Z76XUI USERNAME@localhost The key\\\u0026#39;s randomart image is: +---[RSA 2048]----+ | | | . . . | | . = ... | | + + ... o.o| | =So. +E*+| | o o+.o.=+*| | oo.o= +oB| | . .++ O=| | .=+. .oo*| +----[SHA256]-----+ # ~/.ssh의 file을 확인해보자. $ ls -a ~/.ssh . .. authorized_keys id_rsa id_rsa.pub # 파일을 확인했다면 권한설정을 해주자. $ chmod 700 .ssh \u0026amp;\u0026amp; chmod 600 .ssh/id_rsa \u0026amp;\u0026amp; chmod 600 .ssh/id_rsa.pub 개인키와 공개키를 발급하였다. 이제 ssh-agent를 시작하고 keys를 load하자.\n# ssh-agent가 실행중인지 확인해보자 $ ps -e | grep [s]sh-agent 9060 ?? 0:00.28 /usr/bin/ssh-agent -l # 만일 아무 반응이 없거나 실행 중이지 않다면 아래 명령어를 실행하자. $ ssh-agent /bin/bash # 새로운 키를 load 하자. $ ssh-add ~/.ssh/id_rsa Enter passphrase for /home/USERNAME/.ssh/id_rsa: Identity added: /home/USERNAME/.ssh/id_rsa (/Users/emmpa1/.ssh/id_rsa) # ssh-agent가 관리할 수 있도록 리스트에 등록해주자. $ ssh-add -l 2048 7a:9c:b2:9c:8e:4e:f4:af:de:70:77:b9:52:fd:44:97 /home/USERNAME/.ssh/id_rsa (RSA) 다음의 명령어로 공개키를 따로 복사해두자. bitbucket에서 사용할 것이다.\n# 이 명령어 뒤에 나온 ssh-rsa로 시작하는 부분을 전부 복사하자. $ cat ~/.ssh/id_rsa.pub ssh-rsa ~~~ ~~~ USERNAME@ip-172-31-14-07 Access Key 발급하기 Bitbucket에서 별도의 access key를 발급하고 싶은 repository 에 들어가서 setting 화면으로 넘어가자.\nadd key를 누르면 아래와 같은 화면이 나온다. label에는 구분하고 싶은 이름을 넣어주고, key에는 아까 복사한 ssh-rsa로 시작하는 공개키를 붙여넣어주자.\n다시 ssh 접속화면으로 돌아와서 가져오고 싶은 repository를 clone하자.\n주의할 점은 https가 아닌 ssh를 선택한 값으로 clone해야 한다.\n$ git clone git@bitbucket.org:KH_Own_Team/test.git References https://confluence.atlassian.com/bitbucket/set-up-ssh-for-git-728138079.html ","permalink":"https://novemberde.github.io/post/2017/04/18/Bitbucket_access_key_0/","summary":"Summary 서버에 프로젝트를 배포할 경우 ftp로 파일을 옮기는 방식으로 사용할 수도 있다. 하지만 git repository를 사용하면 git 명령어만으로 간단히 서버코드를 갱신할 수 있다.\n로그인이 아닌 access key를 통해 git repository에 접근하는 방법에 대해 알아보자.\nKey pair 생성하기 먼저 배포하고 싶은 서버에 ssh로 접속한 후 key pair를 생성하자.\n# 이 커맨드는 현재 접속한 유저 directory에 .ssh폴더가 없으면 생성할 것이고, 있다면 .ssh directory에 key pair만 생성할 것이다. $ ssh-keygen Generating public/private rsa key pair.","title":"Bitbucket access key 발급하기"},{"content":"Summary Localhost에서 elastic cache에는 원칙적으로 접근할 수 없다. 별도로 VPC내에 Virtual Private Gateways나 Customer Gateways를 사용하여 VPC내에 존재하는 Elasic Cache에 접근할 수 있다. 하지만 이는 별도의 설정과정이 들어가므로 귀찮았다. 그래서 바로 VPC내의 EC2 인스턴스에서 Elastic Cache에 접근하였다. Docker 이미지 중에서 Redis-cli가 있기 때문에 손쉽게 별도의 설치과정 없이 접근할 수 있다.\n이 과정은 이미 elastic cache를 사용하고 있고 인스턴스에 Docker가 설치되어 있다는 전제 하에 진행한다.\nDocker hub에서 redis-cli 이미지를 받아 접속하자. 아래와 같은 Dockerfile을 기반으로 redis client를 사용할 수 있다.\n이 이미지를 도커허브에 등록해 놓았다.\nFROM redis ENTRYPOINT [ \u0026#34;redis-cli\u0026#34; ] 이미지는 찾았으니 같은 VPC내에 Elastic Cache를 사용하는 EC2 인스턴스에 SSH로 접속한다.\n# docker image를 가져온다. $ docker pull novemberde/redis-cli # redis client를 실행하자. $ docker run --name redis-cli -it novemberde/redis-cli not connected\u0026gt; 여기까지 진행했으면 거의 끝났다.\nnot connected라고 나와 있다. 이제 VPC내의 redis에 접속하자. redis의 url을 복사한 다음 접속하자.\n# redis 에 접속하기 not connected\u0026gt; connect $URL $PORT 접속이 완료되었다. 이제 하고싶은 것을 할 수 있다.\n개발 환경중일 경우에는 Redis를 가끔 비울 경우가 있다.\n다음의 명령어들을 참고하자.\n# 현재 접속한 DB의 모든 정보를 지우기 192.168.99.100:6379\u0026gt; flushdb # 모든 데이터를 지우기 192.168.99.100:6379\u0026gt; flushall ","permalink":"https://novemberde.github.io/post/2017/04/30/VPC_Redis_0/","summary":"Summary Localhost에서 elastic cache에는 원칙적으로 접근할 수 없다. 별도로 VPC내에 Virtual Private Gateways나 Customer Gateways를 사용하여 VPC내에 존재하는 Elasic Cache에 접근할 수 있다. 하지만 이는 별도의 설정과정이 들어가므로 귀찮았다. 그래서 바로 VPC내의 EC2 인스턴스에서 Elastic Cache에 접근하였다. Docker 이미지 중에서 Redis-cli가 있기 때문에 손쉽게 별도의 설치과정 없이 접근할 수 있다.\n이 과정은 이미 elastic cache를 사용하고 있고 인스턴스에 Docker가 설치되어 있다는 전제 하에 진행한다.\nDocker hub에서 redis-cli 이미지를 받아 접속하자. 아래와 같은 Dockerfile을 기반으로 redis client를 사용할 수 있다.","title":"Docker를 활용하여 AWS의 Elastic Cache 에 접근하기."},{"content":"Summary node js나 web ui를 다루기 위해 javascript를 사용하면 closure를 사용할 것이다. constructor로 객체를 생성하지 않고 왜 closure를 사용하는지 살펴보자.\nConstructor와 Closure의 성능차이 샘플코드는 아래와 같다. 성능 결과값을 보면 거의 2배의 차이가 나는 것을 볼 수 있다.\n이러한 차이는 node 서버를 사용할 경우 더욱 두드러지게 체감할 것이다.\nconstructor를 사용하는 경우 javascript 객체가 반드시 가져야할 함수들을 상속받기 때문에 속도차이가 나타나는 것이다. 하지만 front에서는 클라이언트가 메모리를 가지기 때문에 크게 우려하지 않아도 된다.\nreact와 같이 사용하는 프레임워크는 ES6문법으로 class를 사용하는 것을 권장하고 있다.\nvar iterations = 1000000; var closureObj = function( a, b ) { var c = a + b; return { getA: function() { return a; }, getB: function() { return b; }, getC: function() { return c; }, sayHello: function() { console.log(\u0026#34;say\u0026#34;); } }; } var ConstructorObj = function(a, b) { this.a = a; this.b = b; this.c = a + b; this.sayHello = function() { console.log(\u0026#34;say\u0026#34;); } } console.time(\u0026#39;Closure\u0026#39;); for(var i = 0; i \u0026lt; iterations; i++ ){ var a = closureObj(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;); }; console.timeEnd(\u0026#39;Closure\u0026#39;) console.time(\u0026#39;Constructor\u0026#39;); for(var i = 0; i \u0026lt; iterations; i++ ){ var a = new ConstructorObj(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;); }; console.timeEnd(\u0026#39;Constructor\u0026#39;); 결과: Closure: 103.231ms Constructor: 206.072ms References https://developer.mozilla.org/ko/docs/Web/JavaScript/Guide/Closures ","permalink":"https://novemberde.github.io/post/2017/04/16/Closure_0/","summary":"Summary node js나 web ui를 다루기 위해 javascript를 사용하면 closure를 사용할 것이다. constructor로 객체를 생성하지 않고 왜 closure를 사용하는지 살펴보자.\nConstructor와 Closure의 성능차이 샘플코드는 아래와 같다. 성능 결과값을 보면 거의 2배의 차이가 나는 것을 볼 수 있다.\n이러한 차이는 node 서버를 사용할 경우 더욱 두드러지게 체감할 것이다.\nconstructor를 사용하는 경우 javascript 객체가 반드시 가져야할 함수들을 상속받기 때문에 속도차이가 나타나는 것이다. 하지만 front에서는 클라이언트가 메모리를 가지기 때문에 크게 우려하지 않아도 된다.","title":"Javascript에서 Closure와 Constructor"},{"content":"Summary Java를 개발하다보면 String에 대해서 별다른 고민없이 (\u0026ldquo;Some text\u0026rdquo; + \u0026quot; added text\u0026quot;)와 같이 \u0026lsquo;+\u0026lsquo;기호를 통해 스트링을 더하곤 한다. 하지만 Java 개발자라면 고민을 더 해보고 Class를 선택해야한다. String과 StringBuilder, 그리고 StringBuffer를 어떤 경우에 사용하는지 확인해보자.\n각 클래스의 특징 설명에 들어가기에 앞서서 java api와 친숙해져야 된다고 생각한다.\njava api에 접속해서 java.lang 패키지를 들어가보자. java.lang은 별도로 import를 해주지 않아도 사용할 수 있는 class들이 모여있다. Classes항목을 보면 자주 기본적인 클래스들이 있는 것을 볼 수 있다. Boolean, Byte, Integer등과 같은 WrapperClass들도 찾아볼 수 있다.\n그중에서 우리가 눈여겨 볼 것은 String, StringBuffer, StringBuilder이다.\n자세히 알아보기 위해 클릭해보자.\nSerializable, CharSequence, Comparable 인터페이스가 상속되어 있고 public final class로 되어 있다. 해석해보면 serialize가 가능하며 문자열이고 비교가능한 값이라는 것을 알 수 있다. 또한 final class이기 때문에 String class를 상속받을 수는 없다. 여기까지는 널리 알려진 사실이다.\n하지만 String타입에 공부하다보면 String을 직접 더하는 것보다는 StringBuffer나 StringBuilder를 사용하라는 말이 있다. 이유에 대해서 살펴보자.\nString stringValue1 = \u0026#34;TEST 1\u0026#34;; String stringValue2 = \u0026#34;TEST 2\u0026#34;; System.out.println(\u0026#34;stringValue1: \u0026#34; + stringValue1.hashCode()); System.out.println(\u0026#34;stringValue2: \u0026#34; + stringValue2.hashCode()); stringValue1 = stringValue1 + stringValue2; System.out.println(\u0026#34;stringValue1: \u0026#34; + stringValue1.hashCode()); StringBuffer sb = new StringBuffer(); System.out.println(\u0026#34;sb: \u0026#34; + sb.hashCode()); sb.append(\u0026#34;TEST StringBuffer\u0026#34;); System.out.println(\u0026#34;sb: \u0026#34; + sb.hashCode()); 결과: stringValue1: -1823841245 stringValue2: -1823841244 stringValue1: 833872391 sb: 1956725890 sb: 1956725890 위에서 보는바와 같이 생성된 클래스의 주소값이 다른 것을 볼 수 있다. String은 새로운 값을 할당할 때마다 새로 생성되기 때문이다. 이와 달리 StringBuffer는 값은 memory에 append하는 방식으로 클래스를 직접생성하지 않는다. 논리적으로 따져보면 클래스가 생성될 때 method들과 variable도 같이 생성되는데, StringBuffer는 이런 시간을 사용하지 않는다.\n또한 지금은 한 번만 생성되었지만 수십번 String이 더해지는 경우에는 각 String의 주소값이 stack에 쌓이고 클래스들은 Garbage Collector가 호출되기 전까지 heap에 지속적으로 쌓이게 된다. 메모리 관리적인 측면에서는 치명적이라고 볼 수 있다.\n그럼 String class의 내부는 어떤 구조로 되어 있기에 새로 생성될까.\n아래 이미지를 보면 value[]라는 char형의 배열이 보인다. 여기서 힌트를 찾을 수 있다. private final char형이라는 것을 눈여겨 보아야 한다.\nString에서 저장되는 문자열은 알고보면 char의 배열형태로 저장되며 이 값들은 외부에서 접근할 수 없도록 private으로 보호된다. 또한 final형이기 때문에 초기값으로 주어진 String의 값은 불변으로 바뀔 수가 없게 되는 것이다.\nString의 특징을 알아봤으니 memory에 값을 append하는 StringBuilder와 StringBuffer에 대해서 알아보자. api는 아래와 같다.\n해석해보면 StringBuilder는 변경가능한 문자열이지만 synchronization이 적용되지 않았다. 하지만 StringBuffer는 thread-safe라는 말에서처럼 변경가능하지만 multiple thread환경에서 안전한 클래스라고 한다. 이것이 StringBuilder와 StringBuffer의 가장 큰 차이점이다.\nStringBuilder와 StringBuffer를 테스트 해보자. 아래의 결과를 보면 다른 값이 나온 것을 볼 수 있다. StringBuilder의 값이 더 작은 것을 볼 수 있는데 이는 쓰레드들이 동시에 StringBuilder클래스에 접근할 수 있기 때문에 일어난 결과다. 이와 달리 StringBuffer는 multi thread환경에서 다른 값을 변경하지 못하도록 하므로 web이나 소켓환경과 같이 비동기로 동작하는 경우가 많을 때는 StringBuffer를 사용하는 것이 안전할 것이다.\nStringBuffer stringBuffer = new StringBuffer(); StringBuilder stringBuilder = new StringBuilder(); new Thread(() -\u0026gt; { for(int i=0; i\u0026lt;10000; i++) { stringBuffer.append(i); stringBuilder.append(i); } }).start(); new Thread(() -\u0026gt; { for(int i=0; i\u0026lt;10000; i++) { stringBuffer.append(i); stringBuilder.append(i); } }).start(); new Thread(() -\u0026gt; { try { Thread.sleep(5000); System.out.println(\u0026#34;StringBuffer.length: \u0026#34;+ stringBuffer.length()); System.out.println(\u0026#34;StringBuilder.length: \u0026#34;+ stringBuilder.length()); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); 결과: StringBuffer.length: 77780 StringBuilder.length: 76412 References http://docs.oracle.com/javase/8/docs/api/ http://javahungry.blogspot.com/2013/06/difference-between-string-stringbuilder.html ","permalink":"https://novemberde.github.io/post/2017/04/15/String_0/","summary":"Summary Java를 개발하다보면 String에 대해서 별다른 고민없이 (\u0026ldquo;Some text\u0026rdquo; + \u0026quot; added text\u0026quot;)와 같이 \u0026lsquo;+\u0026lsquo;기호를 통해 스트링을 더하곤 한다. 하지만 Java 개발자라면 고민을 더 해보고 Class를 선택해야한다. String과 StringBuilder, 그리고 StringBuffer를 어떤 경우에 사용하는지 확인해보자.\n각 클래스의 특징 설명에 들어가기에 앞서서 java api와 친숙해져야 된다고 생각한다.\njava api에 접속해서 java.lang 패키지를 들어가보자. java.lang은 별도로 import를 해주지 않아도 사용할 수 있는 class들이 모여있다. Classes항목을 보면 자주 기본적인 클래스들이 있는 것을 볼 수 있다.","title":"Java에서 String, StringBuilder, StringBuffer의 차이"},{"content":"Summary Docker hub에 private image를 올리는 것은 제한이 있다. 개인 사용자의 경우 하나의 이미지만 private이 가능하고 organization의 경우에는 비용을 지불해야만 사용이 가능하다. 이런점에 비추어 볼 때 우리는 private registry환경을 구축하고 싶다는 생각이 들 것이다.\nEC2에 개인 registry를 구축하고 local 또는 다른 서버에서 접근하는 방법에 대해서 진행해보겠다. 그리고 Amazon S3 를 이미지 저장소로 사용하겠다.\nDocker registry 구축하기 docker가 설치되어 있는 EC2에 접근하여 registry 이미지를 pull 해보자.\ndocker registry의 기본포트는 5000번이다. # registry 이미지를 가져오기 $ docker pull registry # registry를 실행하기 $ docker run -dit --name docker-registry -p 5000:5000 registry Docker image를 push하기 도커허브를 사용할 때는 \u0026lt;계정아이디\u0026gt;/registry:latest 처럼 tag명에 내 아이디가 들어가는 모양이었다. 하지만 private registry를 사용할 때는 \u0026lt;계정아이디\u0026gt;부분에 내 registry의 url주소를 사용하여야 한다.\nlocalhost에서 테스트를 진행할테니 localhost:5000/hello-world:latest 이미지를 만들어보자.\n# hello-world 이미지가 없으니 docker hub에서 pull하자. $ docker pull hello-world # localhost/hello-world 이미지를 만들어보자. $ docker tag hello-world localhost:5000/hello-world 이미지를 만들었으니 내 registry에 push하자.\n# 이미지 push하기 $ docker push localhost:5000/hello-world # 이미지 확인하기 $ curl -X GET http://localhost:5000/v2/_catalog # 출력 {\u0026#34;repositories\u0026#34;:[\u0026#34;hello-world\u0026#34;]} # 태그 정보 확인하기 $ curl -X GET http://localhost:5000/v2/hello-world/tags/list # 출력 {\u0026#34;name\u0026#34;:\u0026#34;hello-world\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;latest\u0026#34;]} 원격지에서 Docker image를 push하기 지금 이미지의 태그명을 보면 localhost/~ 로 되어 있는 것을 볼 수 있다. 하지만 원격지에서는 특정도메인 또는 IP로 접근하기 때문에 localhost, 127.0.0.1을 사용할 수 없다. gabia, godaddy 또는 AWS 53을 사용하여 DNS설정을 하는 방법과 직접 아이피로 접근해서 등록하는 방법 2가지가 있다.\n이번에는 테스트용 도메인 docker-registry.kh-developer.info 로 DNS를 설정하여 docker registry를 사용하겠다.\ngabia \u0026gt; 네임플러스 \u0026gt; 호스트(IP) 추가/관리 페이지에서 docker-registry를 추가하고 내 EC2 아이피를 할당한다. 아이피를 할당한 후에 현재 pc에서 docker에 push를 해보자.(로컬에도 docker가 설치되어 있어야 한다.) 포트를 5000번으로 registry를 생성했으니 5000번으로 접속하자 EC2에 security group에서 inbound rule에서 5000번으로 설정해주자. my ip를 선택하여 다른 사람이 접근하지 못하도록 하자. # 현재 이미지 목록 보기. $ docker images # 아직 hello-world가 없으므로 docker pull하기 $ docker pull hello-world # docker-registry.kh-developer.info:5000/hello-world 이미지를 만들어보자. $ docker tag hello-world docker-registry.kh-developer.info:5000/hello-world # 이미지가 생성되었는지 확인해보자. $ docker images # push 해보자. 실패할 것이다. $ docker push docker-registry.kh-developer.info:5000/hello-world 아래와 같은 메시지가 나오면서 실패할 것이다.\nGet https://docker-registry.kh-developer.info:5000/v1/_ping: http: server gave HTTP response to HTTPS client 실패한 이유는 docker registry는 로컬머신에서 사용하는 것이 아니라면 https만 지원을 하기 때문이다. 그럼 원격지에서 접속하기 위해서는 docker registry 설정을 해주어야 한다.\n현재의 docker registry 컨테이너를 내리고 다시 registry를 올려보자.\n# docker registry 컨테이너 내리기 $ docker stop docker-registry \u0026amp;\u0026amp; docker rm docker-registry SSL 사설 인증서를 발급하자. 종잣돈이 많다면 인증서를 구입해도 괜찮다.\n이번에는 개인 서명 SSL 인증서를 생성하겠다. openssl이 EC2 인스턴스에 설치되어 있을 것이다.\n# openssl 버전 확인하기 $ openssl version # cert.d 폴더에 개인키 생성하기. 비밀번호를 입력하자. 테스트를 위해 개인키 비밀번호는 test로 하겠다. $ mkdir certs \u0026amp;\u0026amp; cd certs \u0026amp;\u0026amp; openssl genrsa -des3 -out server.key 2048 # 인증 요청서 생성 $ openssl req -new -key server.key -out server.csr Country Name (2 letter code) [XX]:KR State or Province Name (full name) []:Seoul Locality Name (eg, city) [Default City]:Seongdonggu Organization Name (eg, company) [Default Company Ltd]:NOVEMBERDE Organizational Unit Name (eg, section) []:TEST Common Name (eg, your name or your server\\\u0026#39;s hostname) []:docker-registry.kh-developer.info Email Address []: # 생성된 파일 확인하기 $ ll # 개인키에서 패스워드 제거하기 $ cp server.key server.key.origin \u0026amp;\u0026amp; openssl rsa -in server.key.origin -out server.key \u0026amp;\u0026amp; rm server.key.origin # 인증서 생성하기. 1년으로 사용하겠다. 2년 3년할 수도 있다. server.crt파일이 생길 것이다. $ openssl x509 -req -days 730 -in server.csr -signkey server.key -out server.crt 인증서를 발급했으니 registry를 다시 가동해보자.\n$ docker run -d -p 5000:5000 --restart=always --name docker-registry \\ -v /home/\u0026lt;username\u0026gt;/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/server.key \\ registry 가동을 성공적으로 마쳤으면 다시 로컬에서 push를 해보자\n# 다시 로컬환경으로 돌아와서 push하기 $ docker push docker-registry.kh-developer.info:5000/hello-world The push refers to a repository [docker-registry.kh-developer.info:5000/hello-world] Get https://docker-registry.kh-developer.info:5000/v1/_ping: x509: certificate signed by unknown authority 위와 같은 메시지가 나오면서 push가 되지 않을 것이다.\n사설인증서이기 때문에 현재 사용하는 PC의 docker가 push하지 못하는 것이다.\nwindows 환경이라면 하단의 상태표시창에서 docker \u0026gt; setting \u0026gt; insecure-registry에서 docker-registry.kh-developer.info 를 설정해주어야 한다.\nkitematic을 사용하고 있다면 아래와 같은 virtual box를 더블클릭하면 콘솔화면이 나타나는데 여기서 /var/lib/boot2docker/profile 파일을 수정해주어야 한다.\nEXTRA_ARGS 에 \u0026ndash;insecure-registry를 아래와 같이 추가한다.\n추가 후에 docker를 restart하자.\n이제 다시 docker push를 해보자. 성공적으로 push가 될 것이다.\n# 다시 로컬환경으로 돌아와서 push하기 $ docker push docker-registry.kh-developer.info:5000/hello-world S3를 저장소로 사용하기 사용하기에 앞서서 AWS에 user를 생성하도록 하자.\nAWS Menu \u0026gt; Security, Identity \u0026amp; Compliance \u0026gt; IAM 에서 user를 생성한다. username은 docker-registry로 하고, Access type은 Programmatic access로 하자.\nPermission은 Attach existing policies directly로 하여 S3 FullAccess를 선택하여 주자.(FullAccess가 불안하다면 여기를 참고하여 Policy를 생성하길 바란다.)\nCreate를 하면 Access Key와 Secret access key를 부여받는다. 잘 보관하도록 하자.\ndocker registry에서 S3에 접근할 수 있도록 설정하자.\n# 기존의 registry를 내려주고, 새로 올리자. $ docker stop docker-registry \u0026amp;\u0026amp; docker rm docker-registry # 새로 올리기 $ docker run -d -p 5000:5000 --restart=always --name docker-registry \\ -v /home/docker/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/server.key \\ -e REGISTRY_STORAGE=s3 \\ -e REGISTRY_STORAGE_S3_BUCKET=docker-registry.kh-developer \\ -e REGISTRY_STORAGE_S3_ACCESSKEY=ASEFWAF1232REWE \\ -e REGISTRY_STORAGE_S3_SECRETKEY=ASERWER1234WERFASER354SFDSDF1234 \\ -e REGISTRY_STORAGE_S3_REGION=ap-northeast-1 \\ registry # 다시 로컬환경으로 돌아와서 push 해보기 $ docker push docker-registry.kh-developer.info:5000/hello-world S3 bucket을 가면 storage가 형성될 것이다.\nAuthentification 추가하기 여기까지 S3를 이미지 저장소로 사용하는 docker registry를 구성하였다면, 지금부터는 docker registry 접근에 대한 인증절차를 두려고 한다.\n# ~/auth라는 디렉터리에 testuser를 아이디로 갖고 testpassword를 비밀번호로 갖게 해보자. $ mkdir auth \u0026amp;\u0026amp; docker run --entrypoint htpasswd registry:2 -Bbn testuser testpassword \u0026gt; auth/htpasswd # docker registry container를 다시 실행해보자. $ docker run -d -p 5000:5000 --restart=always --name docker-registry \\ -v /home/docker/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/server.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/server.key \\ -e REGISTRY_STORAGE=s3 \\ -e REGISTRY_STORAGE_S3_BUCKET=docker-registry.kh-developer \\ -e REGISTRY_STORAGE_S3_ACCESSKEY=ASEFWAF1232REWE \\ -e REGISTRY_STORAGE_S3_SECRETKEY=ASERWER1234WERFASER354SFDSDF1234 \\ -e REGISTRY_STORAGE_S3_REGION=ap-northeast-1 \\ -v /home/docker/auth:/auth \\ -e \u0026#34;REGISTRY_AUTH=htpasswd\u0026#34; \\ -e \u0026#34;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\u0026#34; \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ registry # 다시 로컬환경으로 돌아와서 docker push를 해보자 $ docker push docker-registry.kh-developer.info:5000/hello-world 98c944e98de8: Preparing no basic auth credentials 위처럼 auth credentials이 없다고 나온다. docker login을 해주자.\n$ docker login docker-registry.kh-developer.info:5000 Username: testuser Password: Login Succeeded # 로그인이 됐다면 다시 push를 해주자 $ docker push docker-registry.kh-developer.info:5000/hello-world 2018-05-29 추가사항 위에 글을 보면 어렵사리 Docker registry 를 구축하였다. 하지만 살펴보면 곳곳에 문제점이 보일 것이다. 이글을 다시 살펴보면서 정리한 의문점은 다음과 같다.\n동시에 수십 수백대의 서버가 업데이트를 하는 경우에는 단일 registry 서버로 감당할 수 있을 것인가? 만약 그럴 수 없다면 어떻게 설계해야할까? 이걸 구축하지 않고 편하게 사용할 수 있는 다른 Managed Service는 없을까? 먼저 첫번째 질문에 답을 하자면, docker registry 관련 문서에 다음과 같이 잘 나와 있다.\nLoad balancing considerations\nOne may want to use a load balancer to distribute load, terminate TLS or provide high availability. While a full load balancing setup is outside the scope of this document, there are a few considerations that can make the process smoother.\nThe most important aspect is that a load balanced cluster of registries must share the same resources. For the current version of the registry, this means the following must be the same:\nStorage Driver\nHTTP Secret\nRedis Cache (if configured)\nDifferences in any of the above cause problems serving requests. As an example, if you’re using the filesystem driver, all registry instances must have access to the same filesystem root, on the same machine. For other drivers, such as S3 or Azure, they should be accessing the same resource and share an identical configuration. The HTTP Secret coordinates uploads, so also must be the same across instances. Configuring different redis instances works (at the time of writing), but is not optimal if the instances are not shared, because more requests are directed to the backend.\n출처: https://docs.docker.com/registry/deploying/#load-balancing-considerations\n이 내용을 간단하게 요약하면 다음과 같다. Load balancing을 고려한 설계를 한 경우이다. 웹어플리케이션 설계와 비슷한 방법으로 공통 스토리지는 Storage Driver를 통해 동일 Storage에 접근하도록 하고 Caching을 위해 Redis를 올려놓늗다. 또한 HTTP Secret을 통해 업로드하므로 모든 인스턴스는 동일한 HTTP Secret을 가져야한다.\nCluster를 인스턴스 Auto-scaling하듯이 여러 인스턴스를 배포하고 공통된 Storage에 접근하도록 설정한 다음 배포하면 되는 것이다. 그렇다면 동시에 많은 요청을 감당할 수 있다.\n두번째로 Managed Service를 찾아보았다. docker hub에 Billing plan을 변경하여 private repository를 생성하는 방법이 있다. 또한 AWS ECR을 사용하여 사용하는 저장공간과 네트워크 비용만 지출할 수 있다. 만약 이렇게 비용을 지불하기 싫다면, 배포할 Artifact를 tar로 압축하여 사용할 서버에 던진 다음에 image를 압축해제해서 사용하면 된다. 이러한 방식은 docker save / load 명령어를 통해 사용해볼 수 있다.\n요즘에는 AWS를 기본으로 사용하다보니 docker registry를 올려본지 오래되었다. 그렇지만 처음 내용을 참고하시는 분들이 계신 것 같아, 처음에 글을 쓴 목적과 달리 다른 방법을 사용하는 것을 추천하고 싶다.\ntar로 git hash를 이용하여 versioning하고, 그 다음에 이 tar에 대해서 artifact를 관리하던지, 아니면 Managed service를 활용하여 운영리소스를 줄이는 방법이다. 피치 못할 사정으로 자체 IDC에 docker registry를 올려야 한다면 docker registry를 단일 컨테이너로 올리는 것이 아닌, k8s나 swarm으로 해당 docker registry를 autoscaling group으로 묶어서 배포하면 될 것이다.\nReferences http://zetawiki.com/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4_%EA%B0%9C%EC%9D%B8%EC%84%9C%EB%AA%85_SSL_%EC%9D%B8%EC%A6%9D%EC%84%9C_%EC%83%9D%EC%84%B1 https://docs.docker.com/registry/deploying/#lets-encrypt https://docs.docker.com/registry/deploying/#native-basic-auth http://www.notrudebuthonest.com/2016/02/kitematic-enable-insecure-registry/ 별도로 arn에 따라 policy를 주고 싶은 경우는 아래와 같은 policy를 넣어준다. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::S3_BUCKET_NAME/*\u0026#34; } ] } ","permalink":"https://novemberde.github.io/post/2017/04/09/Docker_Registry_0/","summary":"Summary Docker hub에 private image를 올리는 것은 제한이 있다. 개인 사용자의 경우 하나의 이미지만 private이 가능하고 organization의 경우에는 비용을 지불해야만 사용이 가능하다. 이런점에 비추어 볼 때 우리는 private registry환경을 구축하고 싶다는 생각이 들 것이다.\nEC2에 개인 registry를 구축하고 local 또는 다른 서버에서 접근하는 방법에 대해서 진행해보겠다. 그리고 Amazon S3 를 이미지 저장소로 사용하겠다.\nDocker registry 구축하기 docker가 설치되어 있는 EC2에 접근하여 registry 이미지를 pull 해보자.\ndocker registry의 기본포트는 5000번이다. # registry 이미지를 가져오기 $ docker pull registry # registry를 실행하기 $ docker run -dit --name docker-registry -p 5000:5000 registry Docker image를 push하기 도커허브를 사용할 때는 \u0026lt;계정아이디\u0026gt;/registry:latest 처럼 tag명에 내 아이디가 들어가는 모양이었다.","title":"나만의 private docker registry 구성하기."},{"content":"Summary 이제 모든 준비는 끝났다. Docker image를 EC2 인스턴스에 배포하자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Docker image를 받아오기 EC2 인스턴스에 SSH로 접속하자. 리눅스 계정은 이전에 만들었던 docker 로 로그인하자.\n로그인 후 docker에 이미지 리스트를 확인하자.\n# docker image의 목록 보기 $ docker images 아직 이미지를 pull한 적이 없으면 아무 리스트도 나오지 않을 것이다.\n이제 내 docker hub에서 image를 pull해보자\nimage를 pull하기에 앞서서 docker hub에 내 이미지가 private인지 public인지 확인해볼 필요가 있다. 만약 private으로 되어 있다면 pull을 해도 이미지를 찾을 수 없다고 나올것이다. 이럴 때는 아래와 같이 로그인을 시도한다.\n# 이와 같이 커맨드를 실행하면 id와 password를 입력하는 커맨드를 만날 것이다. $ docker login 로그인을 마쳤으면 이제 내 계정에 있는 image를 가져오자.\n# username에는 나의 docker hub의 name을 적자. 이는 오른쪽 위에서 내 설정에 들어가면 볼 수 있다. $ docker pull username:docker_node_server 이미지를 성공적으로 pull하였으면 이제 run할 차례만 남았다.\n80포트로 동작하게 할 것. 우리 패키지는 3000번의 포트로 동작하니 포워딩시켜주어야 한다. 컨테이너명은 my_first_server 로 해보자 $ docker run --name my_first_server -p 80:3000 docker_node_server 잘 따라와 주었다. AWS에서 EC2 instance를 보면 public dns를 볼 수 있다.\n크롬브라우져를 켜고 복사/붙여넣기를 하면 우리의 사이트를 볼 수 있을 것이다.\n","permalink":"https://novemberde.github.io/post/2017/04/03/Docker_9/","summary":"Summary 이제 모든 준비는 끝났다. Docker image를 EC2 인스턴스에 배포하자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Docker image를 받아오기 EC2 인스턴스에 SSH로 접속하자.","title":"만들어진 Docker image를 EC2 인스턴스에 배포하기"},{"content":"Summary 이전에는 Dockerfile을 만들었다. 하지만 매번 build하는 것은 소모적인 시간이라고 생각한다. 그럼 만들어진 Dockerfile을 git repository에 push하면 Dockerfile이 빌드되는지 확인하는 것은 어떨까. docker hub의 automated_build기능을 사용하면 간단히 구현된다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Automated_build Docker hub에서 지원해주는 이미지 빌딩시스템이다. docker hub와 github나 bitbucket 계정은 단 하나만 연동이 가능하며 다른 계정과는 연동할 수 없다. 또한 만능으로 항상 build를 해주는 것이 아닌 역시 limit 이 존재한다. 이 링크를 참고하길 바란다. https://forums.docker.com/t/automated-build-resource-restrictions/1413\nCreate Automated_build docker hub의 메인페이지에서 로그인을 하면 오른쪽 위에 Create \u0026gt; Create Automated build 가 있다.\n이것을 누르면 github나 bitbucket을 선택하라는 창이 나온다.\n우린 bitbucket respository를 사용하니 bitbucket을 선택하도록 하자.\n계정을 연동하면 내가 생성한 git respository list를 볼 수 있다.\ndocker_node_server를 선택하면 아래와 같은 창을 볼 수 있을 것이다.\n내 이미지를 공유하고 싶다면 Visibility \u0026gt; public 으로 하면 되고 default는 private이다. 하지만 private의 갯수도 제한이 있다.\n여기까지 왔으면 거의 끝났다.\nBuild Settings 에 들어가면 내 Branch목록을 볼 수 있다. 우린 master로 작업하고 있으니 별다른 설정은 필요없다.\nTrigger 버튼을 누르고 Build Details를 들어가면 우리의 이미지가 생성되고 있는 것을 볼 수 있다.\n빌드가 성공하면 Status가 Success로 바뀌고, Build 내용은 상세화면에서 볼 수 있다.\n","permalink":"https://novemberde.github.io/post/2017/04/02/Docker_8/","summary":"Summary 이전에는 Dockerfile을 만들었다. 하지만 매번 build하는 것은 소모적인 시간이라고 생각한다. 그럼 만들어진 Dockerfile을 git repository에 push하면 Dockerfile이 빌드되는지 확인하는 것은 어떨까. docker hub의 automated_build기능을 사용하면 간단히 구현된다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Automated_build Docker hub에서 지원해주는 이미지 빌딩시스템이다.","title":"Docker Hub의 automated build를 사용하여 Docker image를 만들기"},{"content":"Summary Dockerfile로 이미지로 관리하면 배포 및 관리가 간편하게 가능하다. 여기서는 node를 베이스 이미지로하여 노드 서버를 배포할 수 있도록 준비한다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Dockerfile 이란? Docker image의 설정 정보를 담고 있는 파일이다. 실제 운영 소프트웨어를 배포할 경우 node 베이스 이미지를 올린 다음 패키지를 설치하고 volume을 할당할 수도 있다. 현재 이미지를 주기적으로 commit하여 백업하고 직접 docker exec를 하여 컨테이너 내에 실행명령어를 보내야하는 단점이 있었다. 하지만 Dockerfile은 docker image를 생성할 때 source file을 가져와서 컨테이너 구동과 동시에 서버를 가동시킬 수 있다. 이러한 docker container를 관리하는 방법으로는 docker-compose가 있는데 추후에 살펴볼 것이다.\nDockerfile 작성하기 https://hub.docker.com/에서 여러 베이스 이미지를 검색해볼 수 있다. 예를 들어 node 를 검색한다고 하자. 아래와 같은 화면을 볼 수 있을 것이다.\n맨 위의 node를 들어가면 Full Description에서 \u0026ldquo;7.8.0, 7.8, 7, latest (7.8/Dockerfile)\u0026ldquo;과 같은 글이 보일 것이다.\n여기에 들어가면 Dockerfile이 어떻게 구성되어 있는지 확인할 수 있다.\nFROM : 베이스 이미지 RUN : 실행 커맨드 라인 ENV : 설정할 환경변수 CMD : 데몬으로 실행할 명령어 VOLUME : 호스트와 컨테이너의 디렉터리 공유 COPY : 호스트에서 가져올 디렉터리 또는 파일 EXPOSE : 노출할 포트 설정 간단히 Dockerfile의 구성에 대해서 살펴봤으니 Dockerfile을 만들어보자.\n우리가 만들 이미지의 구성은 아래와 같다\n베이스이미지 : node 실행할 커맨드라인 : npm install -g pm2 환경변수 : NODE_ENV=production 데몬으로 실행할 명령어 : node app.js 호스트에서 가져올 디렉터리 또는 파일 : /home/docker/docker_node_server 노출할 포트: 80 만든 Dockerfile을 배포할 node js 서버 패키지에 만들자.\nDockerfile은 별도의 확장자가 없다.\n파일 트리 구조는 아래와 같다.\n├ docker_node_server ├ app.js ├ Dockerfile └ package.json Dockerfile은 아래와 같다.\n{% gist novemberde/ff49bcb8cbe9f1bab15220ae68b92a69 %}\n만들어진 Dockerfile을 빌드해보자\n# 현재 폴더를 중심으로 한다. docker build -t my-node ./ build가 성공하면 git 에 push해주자. References https://hub.docker.com/ ","permalink":"https://novemberde.github.io/post/2017/04/02/Docker_7/","summary":"Summary Dockerfile로 이미지로 관리하면 배포 및 관리가 간편하게 가능하다. 여기서는 node를 베이스 이미지로하여 노드 서버를 배포할 수 있도록 준비한다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Dockerfile 이란?","title":"Node 서버를 바탕으로 Dockerfile로 만들기"},{"content":"Summary node js 패키지 중에서 PM2를 사용하여 웹서버를 배포하자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 웹서버에 node js를 설치하고 PM2를 설치하기 이전에 생성한 EC2 인스턴스에 ubuntu계정으로 SSH 접속한 후 Node js를 설치하자.\napt-get을 통해 설치하면 간단하게 node 서버 및 npm 패키지를 설치할 수 있다.\n# node 7.x대 버전으로 받자. $ curl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash - $ sudo apt-get install -y nodejs # node-gyp 패키지와 같이 native addon을 컴파일하고 실행하려면 build-essential이 필요하다. $ sudo apt-get install -y build-essential # PM2를 전역적으로 사용하기 위해 -g 옵션을 붙여 설치하자. $ sudo npm install -g pm2 docker 계정으로 File zilla를 사용하여 접속하자\n/home/docker/ 디렉터리에 현재까지 작업한 node 서버를 node_modules를 제외하고 전송한다.\ndocker 계정으로 SSH접속을 한 후에 pm2로 서버를 실행시키자. PM2에 대한 자세한 사용법은 PM2 공식사이트 를 참고하면 된다.\n# 천천히 명령어 한줄씩 실행하는 방법. $ cd docker_node_server $ npm install $ pm2 start app.js # 디렉터리 이동없이 실행. $ npm install --prefix /home/docker/docker_node_server \u0026amp;\u0026amp; pm2 start /home/docker/docker_node_server References https://nodejs.org/ko/download/package-manager/ http://pm2.keymetrics.io/ ","permalink":"https://novemberde.github.io/post/2017/04/02/Docker_6/","summary":"Summary node js 패키지 중에서 PM2를 사용하여 웹서버를 배포하자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 웹서버에 node js를 설치하고 PM2를 설치하기 이전에 생성한 EC2 인스턴스에 ubuntu계정으로 SSH 접속한 후 Node js를 설치하자.","title":"PM2를 사용하여 EC2에 Node 서버 배포하기"},{"content":"Summary Bitbucket을 사용하여 git respository를 생성한다. 보통은 github로 관리하지만 github는 private한 repository를 사용하기 위해서는 사용료를 내야한다. 하지만 Bitbucket은 무제한적인 repository를 생성할 수 있으며 repository의 크기만 제한되어 있다. 2GB까지 사용이 가능한데 보통 코드로만 200MB도 사용하기 어려운 관계로 사실상 무제한이라고 볼 수 있다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Bitbucket Repository 생성하기 먼저 bitbucket.org/에 접속하여 회원가입을 진행하고 로그인한다.\n로그인을 하면 아래와 같은 대시보드 화면이 나타난다.\n왼쪽위에서 Repositories \u0026gt; Create repository 를 클릭하면 생성화면으로 넘어갈 수 있다.\n생성은 Default로 private repository로 되어 있으며 Repository name만 입력하면 손쉽게 생성할 수 있다.\n최종 목적은 docker_node_server 이므로 이렇게 Repository name을 선정하겠다.\nSource Tree 설치하기 만들어진 Respository를 효과적으로 관리하기 위해서는 GUI로 버전정보를 확인할 수 있는 Source Tree가 사용하기 적합하다.\nGit repository를 Github로 사용하면 Github desktop을 사용하는 것도 좋다.\nSource Tree를 설치하고 계정정보를 입력하여 로그인을 하면 기본 준비는 끝난다.\n메인화면에서 왼쪽 상단의 복제/생성 버튼을 누르면 아래와 같은 화면을 볼 수 있다. 소스 경로 / URL 은 Bitbucket에서 docker_node_server의 상세페이지로 넘어가면 볼 수 있다. 오른쪽 맨 위에 https를 선택하면 해당 url을 복사할 수 있다. 이값을 붙여넣도록 하자.\n목적지 경로는 로컬 PC에 저장할 위치를 선택하면 된다.\n","permalink":"https://novemberde.github.io/post/2017/04/01/Docker_4/","summary":"Summary Bitbucket을 사용하여 git respository를 생성한다. 보통은 github로 관리하지만 github는 private한 repository를 사용하기 위해서는 사용료를 내야한다. 하지만 Bitbucket은 무제한적인 repository를 생성할 수 있으며 repository의 크기만 제한되어 있다. 2GB까지 사용이 가능한데 보통 코드로만 200MB도 사용하기 어려운 관계로 사실상 무제한이라고 볼 수 있다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Bitbucket Repository 생성하기 먼저 bitbucket.","title":"Bitbucket을 사용하여 git repository 생성하기"},{"content":"Summary Docker의 개념을 간단히 살펴보고 EC2 ubuntu instance에 Docker를 설치해보자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Docker 란? 공식사이트의 소개를 보면 이렇게 말한다.\nPackage software into standardized units for development, shipment and deployment 패키지 소프트웨어를 개발 및 구축, 배포를 위한 표준화된 단위로.\n이말은 도커는 하나의 패키징된 소프트웨어로 만들어 배포를 하는 도구로 활용할 수 있고 도커는 이러한 단위라고 말하고 있다. 이전까지는 VMware, Microsoft Hyper-V(Virtual PC), Virtual Box와 같은 가상머신(Virtual Machine)에 리눅스를 올려 작업하였다.\n이미지를 백업하고 관리상의 이점은 분명히 있었지만 성능적인 이슈가 문제였다. 가상머신에는 OS이미지가 포함되어 있기 때문에 무겁고 네트워크적으로 가상화이미지에 데이터를 주고 받는 것도 부담된다. 또한, CPU가상화를 위한 기능이 아직까지는 실제 머신의 성능까지 이끌지는 못한다.\n하지만 이러한 문제를 해결하기 위해 나타난 것이 반가상화(Paravirtualization) 방식이다. OS자원은 호스트와 공유하여 이미지 용량의 감소된다. 가상화 레이어가 없기 때문에 커널과 직접적으로 사용하기 때문에 빠른 네트워크 응답과 하드웨어 성능을 이끌어낼 수 있다. 아래 이미지는 Docker의 성능분석 자료이다. Native와 동일한 성능을 내고 있음을 알 수 있다.\n출처: https://blogs.vmware.com/performance/2014/10/docker-containers-performance-vmware-vsphere.html 아래의 사진을 보면 각 컨테이너는 운영체제의 Kernel 즉 핵심을 공유하고 있고 그 안에서 경량화되고 독립적인, 실행가능한 패키지의 한 조각으로 존재한다.\n이러한 컨테이너는 이것들을 실행하기 위한 모든 것을 포함하고 있으며 code, system tools, system libraries와 같은 기능과 정보를 갖고 있다.\n이 개념을 사용하면 리눅스, 윈도우 베이스의 어플리케이션까지 환경에 상관없이 사용가능한 앱을 구축할 수 있다고 한다. (하지만 경험해본 결과 안되는 경우도 있다. 라즈베리파이와 같은 ARM 기반의 하드웨어에는 docker container가 정상적으로 동작하지 않을 때도 있고, MongoDB의 wiredtiger 같은 DB엔진은 windows에서 filesystem이 호환되지 않아 동작하지 않는다. 하지만 보편적으로는 문제없이 가동된다.)\nDocker 설치하기 도커에 대해 기본적인 개념을 알아봤다. 상세한 내용은 아래 References를 참고하면 좋은 내용을 얻을 수 있을 것이다.\n먼저 이전에 만든 EC2 인스턴스에 ubuntu 계정으로 SSH로 접속한다.\n# 먼저 Package Database를 update한다. $ sudo apt-get update # Docker 공식페이지의 keyserver에서 GPG key를 추가한다. $ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D # Docker repository를 APT sources에 추가한다. $ sudo apt-add-repository \u0026#39;deb https://apt.dockerproject.org/repo ubuntu-xenial main\u0026#39; # 새로 추가된 Docker package를 업데이트한다. $ sudo apt-get update # Default Ubuntu 16.04 repository 대신에 Docker repository로 부터 install하는 것을 확인한다. $ apt-cache policy docker-engine # docker-engine을 설치한다. $ sudo apt-get install -y docker-engine # Daemon에서 docker가 실행되고 있는지 확인한다. CentOS의 경우에는 별도로 Daemon으로 실행해주어야 한다. $ sudo systemctl status docker # 현재 접속한 ubuntu 계정을 docker 실행 그룹에 포함시켜준다. 이전에 생성한 docker 계정도 포함시켜주자. $ sudo usermod -aG docker $(whoami) $ sudo usermod -aG docker docker Docker 실행해보기 # Docker의 images를 pull해서 확인해보자. $ docker pull hello-world $ docker images # Docker container를 생성해보자. $ docker run hello-world # Docker container의 상태를 확인해보자. $ docker ps 여기서 docker ps를 할 경우에 아무것도 나타나지 않는 것을 볼 수 있다. container가 Daemon에서 동작하는 것이 아닌 한번 실행하고 종료되었기 때문에 실행되고 있는 컨테이너 목록에 나타나지 않는 것이다. 모든 컨테이너의 상태를 보려면 아래와 같이 확인한다.\n# 모든 Docker container의 상태를 확인해보자. $ docker ps -a 컨테이너의 STATUS를 보면 Exited (0) ~~~ ago 라는 문구를 볼 수 있다. 이미 종료되었다는 의미이다.\n컨테이너를 삭제해보자. CONTAINER_ID 부분에 삭제하고자 하는 docker container의 아이디를 입력한다. 전부 입력할 필요 없이 첫 글자 또는 두글자만 입력해도 삭제된다. 만약에 여러 컨테이너일 경우에는 구분되는 값까지만 입력하면 삭제된다.\n# Docker container를 삭제하기 $ docker rm CONTAINER_ID References https://www.docker.com/what-docker http://pyrasis.com/Docker/Docker-HOWTO https://www.slideshare.net/pyrasis/docker-docker-38286477 https://subicura.com/2017/01/19/docker-guide-for-beginners-1.html https://docs.docker.com/engine/installation/linux/ubuntu/ https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04 ","permalink":"https://novemberde.github.io/post/2017/04/01/Docker_3/","summary":"Summary Docker의 개념을 간단히 살펴보고 EC2 ubuntu instance에 Docker를 설치해보자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Docker 란?","title":"EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기"},{"content":"Summary Node JS의 Express framework를 사용하여 Node JS 서버를 구축해본다. 기본적으로는 http모듈을 사용하여 서버 리스너를 구동하는 것이 있다. http 모듈을 사용하여 서버를 가동하면 exception이 발생하는 동시에 서버가 정지하게 된다. 하지만 Express framework를 사용하면 error처리가 가능하다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Express JS 시작하기 편집기는 아무거나 사용해도 상관없다. 손에 익은 VS code를 사용하여 편집하겠다.\nMS에서 만든 걸작중에 하나라고 생각된다. 보통은 Sublime text, Atom 과 같은 에디터를 많이 사용한다.\nVS code를 사용하는 이유는 아래 사진에서 보이는 것과 같이 터미널을 폴더를 기준으로 사용하기 때문이다.\nCtrl + `(~) 단축키를 누르면 터미널이 열린다.\n혹시나 아직 Node JS를 설치하지 않으신 분이 있다면 공식 사이트에서 설치하고 진행하길 바란다.\n노드가 설치되어 있다면 아래 커맨드를 따라주면 된다.\n# 패키지 초기화 하기. 모두 enter를 치고 default로 사용하자. $ npm init 이제 작업 디렉터리에 package.json이 생성되었을 것이다.\n{ \u0026#34;name\u0026#34;: \u0026#34;docker_node_server\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;git+https://kyuhyun@bitbucket.org/kyuhyun/docker_node_server.git\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;homepage\u0026#34;: \u0026#34;https://bitbucket.org/kyuhyun/docker_node_server#readme\u0026#34; } Express JS를 사용하기 위해 npm 명령어를 실행하자.\n# express 라이브러리 추가하기. $ npm install --save express 이제 서버를 만들어보자.\napp.js라는 파일을 만들고 아래의 코드를 삽입한다.\nconst express = require(\u0026#39;express\u0026#39;); const app = express(); const port = 3000; app.get(\u0026#39;/\u0026#39;, (req, res, next) =\u0026gt; { res.send(\u0026#39;hello world!\u0026#39;); }); app.listen(port, () =\u0026gt; { console.log(`Server is running at ${port}`); }); Express JS의 프로젝트를 생성하는 방법은 http://webframeworks.kr/에 잘 설명되어 있다.\nNode JS의 Express Framework에 대한 깊은 이해가 필요한 분들은 참고하길 바란다.\n서버가 만들어졌다.\n브라우저를 키고 http://localhost:3000에 접속해보자.\nHello world! 라는 문구를 봤으면 순조롭게 진행된 것이다.\n다음은 지금 만든 프로젝트의 버전관리를 하기 위해 git repository에 push할 예정이다.\nSource Tree를 보면 스테이지에 올라가지 않은 파일 목록이 많은 것을 볼 수 있다.\nnpm으로 설치한 모듈 버전 정보는 package.json에 담겨있기 때문에 실제로 모듈이 git으로 관리될 필요가 없다.\n루트 디렉토리에 .gitignore파일을 만들고 아래 코드를 넣은 다음에 다시 확인하면 node_modules가 전부 사라진 것을 확인할 수 있다. Source Tree는 동기화가 조금 걸리니 나중에 확인하면 사라질 것이다.\n# node_modules 제외하기 node_modules 최소화된 정보만 갖고 있으니 repository에 push하자\nSourceTree에서 Stage All 버튼을 눌러 모든 파일을 저장소에 올릴 준비를 하고 아래에 커밋 메시지를 작성한다.\nCommit 메시지는 코드를 추후에 추적하기 편하게 하기 위해 상세히 내용을 담도록하자.\n커밋한 후에 상단의 푸시 버튼을 눌러 repository에 현재 버전 정보를 올리자.\nReferences http://webframeworks.kr/ ","permalink":"https://novemberde.github.io/post/2017/04/01/Docker_5/","summary":"Summary Node JS의 Express framework를 사용하여 Node JS 서버를 구축해본다. 기본적으로는 http모듈을 사용하여 서버 리스너를 구동하는 것이 있다. http 모듈을 사용하여 서버를 가동하면 exception이 발생하는 동시에 서버가 정지하게 된다. 하지만 Express framework를 사용하면 error처리가 가능하다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 Express JS 시작하기 편집기는 아무거나 사용해도 상관없다.","title":"Express JS를 사용하여 Node 서버 구축하기"},{"content":"Summary 생성한 EC2 인스턴스에 docker라는 계정을 생성해 보려고 한다.\n또한 Security Group을 응용하여 접속포트는 80을 열어 사이트를 접근할 수 있도록 설정해주자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 docker 라는 linux 계정을 생성해본다. 먼저 docker 계정에서 사용할 Key pair를 생성해보자.\n아래와 같은 EC2 \u0026gt; Network \u0026amp; Security \u0026gt; Key Pairs항목에서 Key Pair를 생성하여 준다. 이번엔 ubuntu가 아닌 docker로 생성하여주자\n이전과 마찬가지로 자동으로 다운받은 파일을 간직하도록 하자.(Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 참고)\n생성된 Key pair를 PuTTY Key Generator를 사용하여 docker.ppk파일을 생성한다.\nSave private key를 눌러 docker.ppk로 비밀번호를 설정하여 저장하도록 한다.(Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 참고)\n기본준비가 완료되었다. ubuntu라는 계정으로 SSH접속을 먼저 시작한다.(Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 참고)\n이제 linux 계정을 설치해보겠다. 여기서 \u0026ndash;disabled-password를 사용하는 이유는 SSH로 비밀키의 비밀번호로 접속하기 때문이다. 키파일을 중요하게 관리해야 한다는 점을 잊지말자.\n# 유저 추가하기 $ sudo adduser docker --disabled-password # Docker 계정으로 전환하기 $ sudo su - docker # /home/docker 에 .ssh 디렉터리를 생성하기 $ mkdir .ssh # 자신을 제외한 계정이 .ssh폴더에 접근하지 못하도록 한다. $ chmod 700 .ssh # /home/docker/.ssh 디렉터리에 authorized_keys라는 파일을 생성과 동시에 편집하기. $ vi .ssh/authorized_keys vi 편집기는 linux에서 편리하게 문서를 관리할 수 있는 편집기이다. \u0026lsquo;a\u0026rsquo;를 누르면 INSERT모드가 된다. PuttyGen으로 docker.pem 파일을 열고 맨위에 ssh-rsa로 시작하는 부분을 전체 복사한다. 이것을 Public Key 공개키라고 한다. 현재 켜져있는 ssh접속화면에 마우스 오른버튼을 눌러 붙여넣기를 해주면 된다. 마지막으로 ESC를 누르고 \u0026lsquo;:wq\u0026rsquo;를 입력하면 docker계정은 SSH 접속정보가 담긴 유저가 된다. .ssh/authorized_keys값은 아무나 변경할 수 없어야 하기 때문에 권한설정을 해준다. # /home/docker/.ssh/authorized_keys값은 아무나 변경할 수 없어야 하기 때문에 권한설정을 해준다. $ chmod 600 .ssh/authorized_keys Docker 계정이 생성되었다. 이제 docker라는 계정으로 SSH접속을 해보자.(Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 참고)\nHost Name 은 ubuntu 계정과 동일하고 SSH 키파일은 docker.ppk로 접속하면 된다.\nSecurity Group에서 80 포트를 열어주자 아래와 같은 화면에서 Add Rule을 눌러 Type은 HTTP를 고르고 Source는 Anywhere로 하던가 로컬에서 작성자만 접속하게 하고 싶다면 My IP로 진행한다.\n간단하게 80포트를 열어주었다. AWS가 나오기 이전에는 직접 ufw를 사용하여 방화벽 설정을 할 수 있었다. 하지만 Security Group을 사용하면 간단하게 방화벽을 구현할 수 있다.\nReferences http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/managing-users.html ","permalink":"https://novemberde.github.io/post/2017/04/01/Docker_2/","summary":"Summary 생성한 EC2 인스턴스에 docker라는 계정을 생성해 보려고 한다.\n또한 Security Group을 응용하여 접속포트는 80을 열어 사이트를 접근할 수 있도록 설정해주자.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 docker 라는 linux 계정을 생성해본다.","title":"접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기"},{"content":"Summary 요즘에는 직접 IDC를 통해 서버를 운영하는 경우가 사라지고 있다. Amazon에서 지원하는 IaaS인 EC2를 사용하면 간단하게 서버 인프라를 구축할 수 있다. 가입은 간단하니 생략하고, EC2를 생성하고 SSH로 접속하는 과정을 진행해보겠다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 EC2 생성하기 처음에 접속하면 아래와 같은 콘솔화면이 나타난다.\n여기서 왼쪽 위에 Services라는 것을 누르면 AWS에서 지원하는 서비스 목록을 확인할 수 있다.\nCompute에서 EC2를 선택하면 아래와 같은 화면으로 넘어간다.\n메인화면으로 EC2 인스턴스의 목록을 확인해 볼 수 있는 창이다.\nResources라는 가운데 카테고리는 아래와 같은 의미이다.\nRunning Instances :현재 가동하고 있는 인스턴스의 수 Elastic IPs : 고정적으로 사용하는 아이피의 수(Elastic IP를 할당하지 않으면 인스턴스가 stop/start를 할 때 아이피가 바뀌게 된다.) Dedicated Hosts : 전용 호스트. 예를 들어, 기존의 서버의 환경에서 라이센스가 있었을 경우 이전할 때 별도의 물리적 서버를 할당 받을 수 있다 Snapshot : EBS 볼륨에 기록된 데이터를 캡쳐하는 기능 Volumes : 현재 사용하고 있는 볼륨. 서버들의 하드디스크라고 보면 간단하다. Load Balancer : 로드밸런서. AWS를 사용하는 주된 이유중에 하나이다. 부하를 여러 서버에 분담하게 하는 기능 Key Pairs : 공개키 암호화 기법을 사용하여 EC2 유저의 정보를 암호화 및 해독하는 키 쌍 Security Groups : 트래픽을 제어하는 가상 방화벽의 역할. 모든 인스턴스는 하나 이상의 Security Group에 속해있다. Placement Groups : 배치그룹. 단일 가용 영역 내에 있는 인스턴스의 논리적 그룹. 이제 각 항목에 대해 살펴봤으니 인스턴스를 생성하기 전에 필요한 것이 무엇인지 알아보자.\nKey Pairs: 인스턴스에 접속할 유저의 비밀키를 가지고 있어야 하기 때문에 생성하여야 한다. Security Groups: 인스턴스를 생성한 다음 SSH로 접속하기 위해 Port를 설정해주어야 한다. Key Pair는 왼쪽의 사이드 메뉴에서 Network \u0026amp; Security에 보면 Key Pairs에서 생성할 수 있다.\nCreate Key Pair를 선택하면 키를 생성할 수 있다.\nubuntu라는 키를 create하면 ubuntu.pem이라는 파일을 자동적으로 다운로드 한다.\n이 키는 내 인스턴스를 마음대로 접근할 수 있도록 하기 때문에 절대 유출되지 않도록 조심히 다루어야 한다.\n이 키가 유출되더라도 사용할 수 없도록 만들기 위해 비밀번호를 걸어주어야 한다.\nubuntu.pem 에 패스워드를 걸어 별도의 개인키로 관리하려고 한다.\nPuTTY Key Generator 는 이 링크에서 다운받으면 된다.\n다운 받고 실행하면 아래와 같은 화면을 볼 수 있다.\nLoad버튼을 눌러 ubuntu.pem을 열어보자. 파일 목록이 보이지 않을 시에는 All Files로 모든 형식의 파일이 보이게 하자.\nKey passphrase에 개인키에 사용할 비밀번호를 쓰고 Confirm passphrase로 확인하도록 한다.\n마지막으로 Save private key를 통해 ubuntu.ppk파일을 생성하자\n이제 Security Group을 생성하여 SSH포트를 열어주도록 하자.\nNetwork \u0026amp; Security에 Security Groups에서 생성할 수 있다.\nVPC는 default로 사용하도록 하자.\nNetwork 개념을 확장시키면 VPC도 별도로 생성하여 프로젝트마다 네트워크 가상 공간을 분리할 수 있다는 것만 대충 알아두자.\ngroup name을 지정하고 간단한 description을 작성하고 Inbound rule에 SSH를 선택하고 Source는 My IP만 입력하여 다른 사람이 내 인스턴스에 접근하지 못하도록 하자. 마지막 단계만 남았다.\n생성한 Key Pair와 Security Group으로 인스턴스를 생성한다.\nInstances를 선택한다. Launch Instance로 인스턴스 생성화면으로 넘어간다. 여기서는 AWS Marketplace로 넘어가서 ubuntu를 검색하면 된다.\nUbuntu 16.04 LTS - Xenial (HVM) 을 select 하면 다음 화면으로 넘어간다.\n다음화면에서는 인스턴스 타입을 선택하는데 무료로 사용할 수 있는 t2.micro를 선택한다.\n선택한 다음에 Configure Instance는 별도의 Subnet을 사용하지 않기 때문에 디폴트 설정으로 수정없이 넘어가자.\nAdd Storage는 많은 용량을 사용하지 않기 때문에 Size는 8 GiB로 하고 Volume Type은 GP2로 선택하자.\nAdd Tags는 인스턴스를 간단히 구분하기 위해 좋은 제도이다. 하지만 우린 하나만 운영하기 때문에 따로 설정하지 않겠다.\nConfigure Security Group에서 우리가 방금 만든 Security Group에 속해야 한다. Select an existing security group을 선택하고, ubuntu로 사용하자.\nlaunch를 누르면 Key pair를 등록하는 화면이 나온다. Choose an existing key pair가 디폴트로 나올 것이다. 여기서 ubuntu를 key pair로 사용하도록 하자.\n이제 접속하자.\n아래 이미지을 보면 오른쪽 밑에 Public DNS라는 란이 보일 것이다. 이부분을 복사한다.\nPuTTY를 열어 SSH로 접속을 시도한다.\nHost Name에는 public DNS값을 붙여넣고 왼쪽 카테고리에서 Connection \u0026gt; SSH \u0026gt; Auth 에 들어가면 아래쪽에 파일 첨부하는 란이 있다. 여기에 아까 만든 ubuntu.ppk를 넣는다. 이제 open을 눌러 접속을 시도해보자. login as: ubuntu 를 입력하고, 비밀번호는 ubuntu.ppk의 비밀번호를 사용한다. References http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.html ","permalink":"https://novemberde.github.io/post/2017/03/31/Docker_1/","summary":"Summary 요즘에는 직접 IDC를 통해 서버를 운영하는 경우가 사라지고 있다. Amazon에서 지원하는 IaaS인 EC2를 사용하면 간단하게 서버 인프라를 구축할 수 있다. 가입은 간단하니 생략하고, EC2를 생성하고 SSH로 접속하는 과정을 진행해보겠다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 EC2 생성하기 처음에 접속하면 아래와 같은 콘솔화면이 나타난다.","title":"AWS에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기"},{"content":"소개 Node JS 서버를 배포하려고 한다. 매일 같이 하던 방식이지만 방법을 잊을 수도 있다는 생각이 들었다. 이것을 보고 사람들이 노드 서버를 간결하게 배포하였으면 한다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 ","permalink":"https://novemberde.github.io/post/2017/03/31/Docker_0/","summary":"소개 Node JS 서버를 배포하려고 한다. 매일 같이 하던 방식이지만 방법을 잊을 수도 있다는 생각이 들었다. 이것을 보고 사람들이 노드 서버를 간결하게 배포하였으면 한다.\n순서 Amazon web service에 Ubuntu OS를 사용하는 EC2 인스턴스 생성하기 접속 포트를 열어주고 별도의 Ubuntu 유저를 생성하기 EC2에 Docker를 설치하고 Ubuntu 유저에게 권한주기 Bitbucket을 사용하여 git repository 생성하기 Express JS를 사용하여 Node 서버 구축하기 테스트로 PM2를 사용하여 EC2에 Node 서버 배포하기 Node 서버를 바탕으로 Dockerfile로 만들기 Docker Hub의 automated build를 사용하여 Docker image를 만들기 만들어진 Docker image를 EC2 인스턴스에 배포하기 ","title":"Docker로 EC2에 Node 배포하기"},{"content":"","permalink":"https://novemberde.github.io/rss/","summary":"","title":"RSS Feeds"}]